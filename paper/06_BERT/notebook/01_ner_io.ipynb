{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## char단위 bio태그를 tokenizer 사용하여 token단위 bio태그로 바꾸기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## klue data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../file/klue-ner-v1_train.tsv', 'r') as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## klue-ner-v1_train_00001_nsmc\\t<한군데:QT>서 필름을 너무 낭비한 작품입니다.\\n한\\tB-QT\\n군\\tI-QT\\n데\\tI-QT\\n서\\tO\\n \\tO\\n필\\tO\\n름\\tO\\n을\\tO\\n \\tO\\n너\\tO\\n무\\tO\\n \\tO\\n낭\\tO\\n비\\tO\\n한\\tO\\n \\tO\\n작\\tO\\n품\\tO\\n입\\tO\\n니\\tO\\n다\\tO\\n.\\tO'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_corpus = [[sen.split('\\t') for sen in sentence.split('\\n')] for sentence in corpus if '\\t' in sentence]\n",
    "splitted_corpus = [[sen for sen in sentence if len(sen) > 1] for sentence in splitted_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_pair = [[[char, bio] for char, bio in corpus if bio[0] in ['B', 'I', 'O']] for corpus in splitted_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_char = [''.join([char for char, bio in corpus]) for corpus in corpus_pair]\n",
    "corpus_bio = [[bio for char, bio in corpus] for corpus in corpus_pair]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path =  '/home/long8v/torch_study/paper/file/bert/vocab.json'\n",
    "tokenizer = Tokenizer.from_file(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_token = ['[UNK]', '[SEP]', '[CLS]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_labels(text, label, tokenizer):\n",
    "    def decode_spm(tokens):\n",
    "        return ''.join(\n",
    "            [token.replace('##', '')\n",
    "             if token.startswith('##') else f' {token}'\n",
    "             for token in tokens\n",
    "             if token not in [',', '.', '?']])\n",
    "    token_word = tokenizer.encode(text).tokens\n",
    "    index = 0\n",
    "    token_labels = []\n",
    "    label_clean = [lbl for txt, lbl in list(zip(text, label)) if txt.strip()]\n",
    "    for token_idx, token in enumerate(token_word):\n",
    "        if token not in special_token:\n",
    "            token_clean = token.replace('##', '')\n",
    "            len_token_clean = len(token_clean)\n",
    "        else: # [UNK] 토큰 일 때, 원래 토큰 길이를 찾아야 함\n",
    "            token_clean = decode_spm(token_word[token_idx + 1:])\n",
    "            token_clean_before = decode_spm(token_word[:token_idx])\n",
    "            len_token_clean = text.find(''.join(token_clean)) - len(token_clean_before)\n",
    "        token_labels.append(label_clean[index:index+len_token_clean][0]) # 가장 첫번째 bio 태그를 태그로 사용\n",
    "        index += len_token_clean\n",
    "    return token_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['특히', '영동', '##고속도로', '강', '##릉', '방향', '문', '##막', '##휴', '##게']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_char[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'특히 영동고속도로 강릉 방향 문막휴게소에서 만종분기점까지 5㎞ 구간에는 승용차 전용 임시 갓길차로제를 운영하기로 했다.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_char[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_token_labels(corpus_char[0], corpus_bio[0], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'B-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'O']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bio[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('특', 'O'),\n",
       " ('히', 'O'),\n",
       " (' ', 'O'),\n",
       " ('영', 'B-LC'),\n",
       " ('동', 'I-LC'),\n",
       " ('고', 'I-LC'),\n",
       " ('속', 'I-LC'),\n",
       " ('도', 'I-LC'),\n",
       " ('로', 'I-LC'),\n",
       " (' ', 'O'),\n",
       " ('강', 'B-LC'),\n",
       " ('릉', 'I-LC'),\n",
       " (' ', 'O'),\n",
       " ('방', 'O'),\n",
       " ('향', 'O'),\n",
       " (' ', 'O'),\n",
       " ('문', 'B-LC'),\n",
       " ('막', 'I-LC'),\n",
       " ('휴', 'I-LC'),\n",
       " ('게', 'I-LC'),\n",
       " ('소', 'I-LC'),\n",
       " ('에', 'O'),\n",
       " ('서', 'O'),\n",
       " (' ', 'O'),\n",
       " ('만', 'B-LC'),\n",
       " ('종', 'I-LC'),\n",
       " ('분', 'I-LC'),\n",
       " ('기', 'I-LC'),\n",
       " ('점', 'I-LC'),\n",
       " ('까', 'O'),\n",
       " ('지', 'O'),\n",
       " (' ', 'O'),\n",
       " ('5', 'B-QT'),\n",
       " ('㎞', 'I-QT'),\n",
       " (' ', 'O'),\n",
       " ('구', 'O'),\n",
       " ('간', 'O'),\n",
       " ('에', 'O'),\n",
       " ('는', 'O'),\n",
       " (' ', 'O'),\n",
       " ('승', 'O'),\n",
       " ('용', 'O'),\n",
       " ('차', 'O'),\n",
       " (' ', 'O'),\n",
       " ('전', 'O'),\n",
       " ('용', 'O'),\n",
       " (' ', 'O'),\n",
       " ('임', 'O'),\n",
       " ('시', 'O'),\n",
       " (' ', 'O'),\n",
       " ('갓', 'O'),\n",
       " ('길', 'O'),\n",
       " ('차', 'O'),\n",
       " ('로', 'O'),\n",
       " ('제', 'O'),\n",
       " ('를', 'O'),\n",
       " (' ', 'O'),\n",
       " ('운', 'O'),\n",
       " ('영', 'O'),\n",
       " ('하', 'O'),\n",
       " ('기', 'O'),\n",
       " ('로', 'O'),\n",
       " (' ', 'O'),\n",
       " ('했', 'O'),\n",
       " ('다', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(corpus_char[0], corpus_bio[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('특히', 'O'),\n",
       " ('영동', 'B-LC'),\n",
       " ('##고속도로', 'I-LC'),\n",
       " ('강', 'B-LC'),\n",
       " ('##릉', 'I-LC'),\n",
       " ('방향', 'O'),\n",
       " ('문', 'B-LC'),\n",
       " ('##막', 'I-LC'),\n",
       " ('##휴', 'I-LC'),\n",
       " ('##게', 'I-LC'),\n",
       " ('##소', 'I-LC'),\n",
       " ('##에', 'O'),\n",
       " ('##서', 'O'),\n",
       " ('만', 'B-LC'),\n",
       " ('##종', 'I-LC'),\n",
       " ('##분', 'I-LC'),\n",
       " ('##기', 'I-LC'),\n",
       " ('##점', 'I-LC'),\n",
       " ('##까', 'O'),\n",
       " ('##지', 'O'),\n",
       " ('[UNK]', 'B-QT'),\n",
       " ('구', 'O'),\n",
       " ('##간', 'O'),\n",
       " ('##에', 'O'),\n",
       " ('##는', 'O'),\n",
       " ('승', 'O'),\n",
       " ('##용', 'O'),\n",
       " ('##차', 'O'),\n",
       " ('전용', 'O'),\n",
       " ('임시', 'O'),\n",
       " ('갓', 'O'),\n",
       " ('##길', 'O'),\n",
       " ('##차', 'O'),\n",
       " ('##로', 'O'),\n",
       " ('##제', 'O'),\n",
       " ('##를', 'O'),\n",
       " ('운영', 'O'),\n",
       " ('##하', 'O'),\n",
       " ('##기', 'O'),\n",
       " ('##로', 'O'),\n",
       " ('했', 'O'),\n",
       " ('##다', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip_longest(tokenized_char[0], labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "long36v",
   "language": "python",
   "name": "long36v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
