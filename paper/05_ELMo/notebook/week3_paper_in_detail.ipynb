{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Korpora import Korpora\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korpora.fetch('namuwikitext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = Korpora.load('namuwikitext')\n",
    "# with open('kor.p', 'wb') as f:\n",
    "#     pickle.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kor.p', 'rb') as f:\n",
    "    corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import mecab\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "import sys\n",
    "sys.path.append('../source')\n",
    "from txt_cleaner.clean.master import MasterCleaner\n",
    "from txt_cleaner.utils import *\n",
    "from torch8text.data import Vocab, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안녕하세요?', '반갑습니다.', '오늘은 엘모를 구현보겠습니다?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize('안녕하세요? 반갑습니다. 오늘은 엘모를 구현보겠습니다?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## field 1: mecab 사용 field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = mecab.MeCab()\n",
    "\n",
    "def tokenize_pos(inp):\n",
    "    if type(inp) == str:\n",
    "        return pos.morphs(inp)\n",
    "    if type(inp) == list:\n",
    "        return [tokenize_pos(i) for i in inp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['안녕', '하', '세요'],\n",
       " [['안녕', '하', '세요'], ['안녕', '?']],\n",
       " [[['안녕', '하', '세요']], [['안녕', '?']]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_pos('안녕하세요'), tokenize_pos(['안녕하세요', '안녕?']), tokenize_pos([['안녕하세요'], ['안녕?']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수인님 cleaner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size 1 dictionary is read from ../source/txt_cleaner/cleaner_config.json\n"
     ]
    }
   ],
   "source": [
    "config = json_reader('../source/txt_cleaner/cleaner_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'minimum_space_count': 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['minimum_space_count'] = 2\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요? 반갑습니다! 행복하세요'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner = MasterCleaner(config)\n",
    "cleaner.cleaning('안녕하세요? 반갑습니다! 행복하세요~**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['안녕', '하', '세요'], ['안녕']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_pos(['안녕하세요', '안녕'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(S):\n",
    "    if S == []:\n",
    "        return S\n",
    "    if isinstance(S[0], list):\n",
    "        return flatten(S[0]) + flatten(S[1:])\n",
    "    return S[:1] + flatten(S[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_field = Field(tokenize = tokenize_pos, \n",
    "                    preprocessing = lambda e: cleaner.cleaning(e),\n",
    "                    init_token = False,\n",
    "                    eos_token = False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dks', 'df']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten([[['dks','df']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['REOL의 앨범 Σ의 일곱번째 트랙으로, 작곡의 원안을 레오루가 담당했다.',\n",
       "  '기가P는 후렴구의 멜로디를 위주로 작업했다고 하는데 가사와 잘 어울리는 우울하면서도 침착한 멜로디가 어우러져 깊은 여운을 남긴다.',\n",
       "  '이번 앨범 내에서도 1, 2위를 다툴 정도로 어두운 가사로, 음악의 주제는 사별 ( 死別 ) .',\n",
       "  '신님이 된 날이라는 제목과 연관지어 생각해보면 꽤나 의미심장하다.',\n",
       "  '전 소절을 남겨진 사람과 떠난 사람 양쪽의 시점으로 해석 가능하다는 것도 특필할만한 점.'],\n",
       " ['羽衣小町\\n《아이돌 마스터 신데렐라 걸즈》에 등장하는 코바야카와 사에, 시오미 슈코로 이루어진 2인 유닛.',\n",
       "  \"통칭 '슈사에'.\",\n",
       "  '둘 다 교토가 고향이고 일본 전통 컨셉 아이돌이라는 공통점이 있다.',\n",
       "  '또한 이 둘은 아이돌을 하는데 있어서 집안과의 갈등을 포함하고 있다는 공통점도 있다.',\n",
       "  \"사에는 엄격한 부모님의 반대를 무릅쓰고 상경, 슈코는 화과자 집 가업을 잇기 싫어서 가출 ( ... )\\n모바마스에서 둘의 상호 아이돌 토크가 있고 '하고로모코마치'라는 유닛명을 달고 나와 여러 이벤트에서 출연하고 있다.\",\n",
       "  \"유닛명은 '날개옷 미녀'라는 뜻이다.\",\n",
       "  'MAGIC HOUR SP 9화에서 슈코와 사에 단 둘이서만 나와서 직접 유닛명을 언급했다.# 신데메이션 25화에서 사에, 슈코, 아즈키, 카코가 함께 행사를 꾸리는 장면이 스치듯 지나갔다.',\n",
       "  '신데렐라 걸즈 극장 애니 5화에서 사에, 슈코가 카오루를 데리고 꽃구경을 갔다.',\n",
       "  '2016년 10월 15일에 열린 신데마스 4thLIVE SSA 공연에서 사에와 슈코의 성우가 青の一番星를 듀엣으로 부르는 무대가 있었다.']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = [sent_tokenize(text) for text in corpus.train.texts if cleaner.cleaning(text)]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안녕', '하', '세요', '?', '룰루랄라']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_field.build_vocab(train)\n",
    "mecab_field.preprocess('안녕하세요? 룰루랄라 ㅇㅇㄹ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['REOL의 앨범 Σ의 일곱번째 트랙으로, 작곡의 원안을 레오루가 담당했다. 기가P는 후렴구의 멜로디를 위주로 작업했다고 하는데 가사와 잘 어울리는 우울하면서도 침착한 멜로디가 어우러져 깊은 여운을 남긴다.\\n이번 앨범 내에서도 1, 2위를 다툴 정도로 어두운 가사로, 음악의 주제는 사별 ( 死別 ) . 신님이 된 날이라는 제목과 연관지어 생각해보면 꽤나 의미심장하다. 전 소절을 남겨진 사람과 떠난 사람 양쪽의 시점으로 해석 가능하다는 것도 특필할만한 점.',\n",
       " \"羽衣小町\\n《아이돌 마스터 신데렐라 걸즈》에 등장하는 코바야카와 사에, 시오미 슈코로 이루어진 2인 유닛. 통칭 '슈사에'. 둘 다 교토가 고향이고 일본 전통 컨셉 아이돌이라는 공통점이 있다. 또한 이 둘은 아이돌을 하는데 있어서 집안과의 갈등을 포함하고 있다는 공통점도 있다. 사에는 엄격한 부모님의 반대를 무릅쓰고 상경, 슈코는 화과자 집 가업을 잇기 싫어서 가출 ( ... )\\n모바마스에서 둘의 상호 아이돌 토크가 있고 '하고로모코마치'라는 유닛명을 달고 나와 여러 이벤트에서 출연하고 있다. 유닛명은 '날개옷 미녀'라는 뜻이다.\\nMAGIC HOUR SP 9화에서 슈코와 사에 단 둘이서만 나와서 직접 유닛명을 언급했다.# 신데메이션 25화에서 사에, 슈코, 아즈키, 카코가 함께 행사를 꾸리는 장면이 스치듯 지나갔다. 신데렐라 걸즈 극장 애니 5화에서 사에, 슈코가 카오루를 데리고 꽃구경을 갔다.\\n2016년 10월 15일에 열린 신데마스 4thLIVE SSA 공연에서 사에와 슈코의 성우가 青の一番星를 듀엣으로 부르는 무대가 있었다.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## field 2:  chr-level field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner.cleaning('아')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = MasterCleaner({'minimum_space_count':0})\n",
    "chr_field = Field(tokenize = list, \n",
    "                 preprocessing = lambda e: cleaner.cleaning(e) if len(e) > 1 else e,\n",
    "                  init_token = False,\n",
    "                  eos_token = False,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_field.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72, 1, 18, 1, 1]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_chr = chr_field.preprocess('안녕하세요')\n",
    "chr_field.process(token_chr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset, dataloader\n",
    "## 헷갈리는 부분\n",
    "bi-directional LSTM을 쓸건데 이게 다음 단어 예측하는 LM만 데이터를 구성하면 되나? 아니면 뒤에서부터 앞의 단어를 예측하는 LM도 구성해서 concat해야 하나? -> 일단 전자라고 생각하고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ELMoDataset(Dataset):\n",
    "    def __init__(self, src, mecab_field, chr_field):\n",
    "        self.src = src\n",
    "        self.mecab_field = mecab_field\n",
    "        self.chr_field = chr_field\n",
    "        self.named_tuple = namedtuple('data', ['src', 'trg', 'src_chr'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.named_tuple(self.getitem(idx), self.getitem(idx)[1:], self.getitem(idx, is_char=True))\n",
    "    \n",
    "    def getitem(self, idx, is_char=False):\n",
    "        data = self.src[idx]\n",
    "        tokenize_data = self.mecab_field.preprocess(data)\n",
    "        if is_char:\n",
    "            chrs = chr_field.preprocess(tokenize_data)\n",
    "            pad_chrs = self.chr_field.pad_process(tokenize_data)\n",
    "            return pad_chrs\n",
    "        return torch.Tensor(self.mecab_field.vocab.stoi(tokenize_data)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ELMoDataset(train, mecab_field, chr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(_) for _ in mecab_field.vocab.stoi_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = [torch.tensor([[72,  0,  0,  0,  0]]), torch.tensor([[0, 0, 0, 0, 0]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[72,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr_field.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['안녕', '하', '세요', '반갑', '습니', 'ek', 'edd']]\n",
      "[[['안', '녕'], ['하'], ['세', '요'], ['반', '갑'], ['습', '니'], [], []]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-9d22d6b48064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtoken_chr_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchr_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_chr_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprocess_chr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchr_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_chr_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_chr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch_study/paper/05_ELMo/source/torch8text/data.py\u001b[0m in \u001b[0;36mpad_process\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0md_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mprocess_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mpad_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0md_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch_study/paper/05_ELMo/source/torch8text/data.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpad_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch_study/paper/05_ELMo/source/torch8text/data.py\u001b[0m in \u001b[0;36mstoi\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mitos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torch_study/paper/05_ELMo/source/torch8text/data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mitos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "data = '안녕하세요 반갑습니ek edd'\n",
    "token_data = mecab_field.preprocess(data)\n",
    "print(token_data)\n",
    "token_chr_data = chr_field.preprocess(token_data)\n",
    "print(token_chr_data)\n",
    "process_chr = chr_field.pad_process(token_chr_data)\n",
    "print(process_chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_chr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in ds:\n",
    "    print(_.src_chr)\n",
    "    print(_.src)\n",
    "    print(_.trg)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (src, trg, src_chr) = zip(*batch)\n",
    "    named_tuple = namedtuple('data', ['src', 'trg', 'src_chr'])\n",
    "    src_pad = pad_sequence(src, batch_first=True, padding_value=0)\n",
    "    trg_pad = pad_sequence(trg, batch_first=True, padding_value=0)\n",
    "    src_chr_pad = pad_sequence(src_chr, batch_first=True, padding_value=0)\n",
    "    return named_tuple(src_pad, trg_pad, src_chr_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pack_pad_collate(batch):\n",
    "#     (src, trg) = zip(*batch)\n",
    "#     src_len = torch.Tensor([len(s) for s in src])\n",
    "#     trg_len = torch.Tensor([len(t) for t in trg])\n",
    "#     named_tuple = namedtuple('data', ['src', 'trg'])\n",
    "#     src_pad = pad_sequence(src, batch_first=True, padding_value=0)\n",
    "#     trg_pad = pad_sequence(trg, batch_first=True, padding_value=0)\n",
    "#     src_pack = pack_padded_sequence(src_pad, lengths=src_len, batch_first=True, enforce_sorted=False)\n",
    "#     trg_pack = pack_padded_sequence(trg_pad, lengths=trg_len, batch_first=True, enforce_sorted=False)\n",
    "#     return named_tuple(src_pack, trg_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size = 16, collate_fn = pad_collate)\n",
    "for _ in dl:\n",
    "    print(_.src.data.shape)\n",
    "    print(_.trg.data.shape)\n",
    "    print(_.src_chr.data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[0], embedding_dim)) \n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[1], embedding_dim))\n",
    "\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        # torch.Size([2, 243, 5, 1024])\n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "\n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "#         print(pooled_0.shape)\n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1), dim = -1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(chr_field.vocab)\n",
    "EMBEDDING_DIM = 1024\n",
    "N_FILTERS = 1\n",
    "FILTER_SIZES = (1, 2)\n",
    "PAD_IDX = chr_field.vocab.stoi_dict['<PAD>']\n",
    "SPECIAL_TOKENS = chr_field.vocab.special_tokens\n",
    "SPECIAL_TOKENS_INDEX = chr_field.vocab.special_tokens_idx\n",
    "CHR_DICT = chr_dict\n",
    "OUTPUT_DIM = 1024\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_LM(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hid_dim, n_layers, dropout, bidirectional):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.num_dircetions = 2 if bidirectional else 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hid_dim, n_layers, dropout = dropout, bidirectional = bidirectional)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim * self.num_dircetions, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # (num_layers * num_directions, batch, hidden_size)\n",
    "        return torch.zeros(self.n_layers * self.num_dircetions, 1, self.hid_dim)\n",
    "    \n",
    "    def forward(self, input):\n",
    "#         print(f'input shape : {input.shape}') # seqlen, batch, hid_dim(output_dim of cnn)\n",
    "        output, (hidden, cell) = self.lstm(input)\n",
    "#         print(f'output shape : {output.shape}') # ouput shape :(seq_len, batch, num_directions * hidden_size)  \n",
    "        \n",
    "        prediction = self.fc_out(output)\n",
    "#         print(f'prediction shape {prediction.shape}') # seq len, batchsize, trg_dim\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = OUTPUT_DIM\n",
    "PREDICT_DIM = len(mecab_field.vocab)\n",
    "HID_DIM = 1024\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "BIDIRECTIONAL = True\n",
    "TRG_PAD_IDX = mecab_field.vocab.stoi_dict['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = LSTM_LM(INPUT_DIM, PREDICT_DIM, HID_DIM, N_LAYERS, DROPOUT, BIDIRECTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<sos>`토큰이랑 `<eos>` 토큰은 어떻게 CNN처리 해야하지?  -> 일단 빼는걸로 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글이랑 영어랑 다른점 : 영어는 3char이하인 단어가 별로 없는데 한글은 1~2개로 많이 끊겨서 conv연산 하기가 애매함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.apply(initialize_weights);\n",
    "rnn.apply(initialize_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = []\n",
    "n_pass = 0\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    for src, trg, src_chr in dl:\n",
    "        src_chr = src_chr.permute(1, 0, 2) # 토큰 별 캐릭터가 먼저 나오도록\n",
    "\n",
    "        for idx, src_c in enumerate(src_chr):\n",
    "            output, hidden, cell = rnn(features.unsqueeze(1))\n",
    "            try:\n",
    "                loss = criterion(output.squeeze(1), trg[:, idx])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "    epoch_loss += [loss.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 해야 할 일 : 1) init hidden 2) CNN + RNN 감싸기\n",
    "1) 배치별로 토큰 내에 있는 캐릭터 글자에 따라 CNN길이가 다른데 어떻게 처리하지? -> 패딩으로 처리함..근데 이게 맞는지 모르겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "long36v",
   "language": "python",
   "name": "long36v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
