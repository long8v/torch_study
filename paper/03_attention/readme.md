## ğŸ§ run
.en, .frì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ëª» ë¶ˆëŸ¬ì™€ì„œ [í™ˆí˜ì´ì§€](https://github.com/multi30k/dataset/tree/master/data/task1/raw) ë“¤ì–´ê°€ì„œ<br>
train.en, train.fr, val.en, val.fr ë‹¤ìš´ ë°›ì•„ì„œ ì‹¤í–‰ ê²½ë¡œì— ìƒê¸°ëŠ” .data(ìˆ¨ê¹€í´ë”)ì— ë“¤ì–´ê°€ì„œ ë„£ì–´ì¤˜ì•¼ í•¨

- script
```
python main.py
```
- notebook
ã„´ 01_reference_code.ipynb : ë°ì´í„°ì…‹ ë°”ê¿”ì„œ ì˜ì–´ íŠœí† ë¦¬ì˜¬ í•œê¸€ë¡œ ë²ˆì—­í•´ ë´„
ã„´ 02_reference_code_paper_detail.ipynb : ë…¼ë¬¸ê³¼ ë¹„êµí•´ë³´ê³  ì¶”ê°€ë¡œ ë””í…Œì¼ êµ¬í˜„í•´ ë´„

## ğŸ¤— Result
ğŸš© ë°ì´í„°ì…‹ì´ ë…¼ë¬¸ê³¼ ë‹¤ë¦„(Multi 30k en-fr)
|model|maxout|# of parameters|test PPL|test BLEU|training time for one epoch|
|----|----|----|----|----|----|
|reference code ê·¸ëŒ€ë¡œ|x|21,196,869|13.162|39.637|3m 15s~3m 20s|
|referecne code w/o maxout|o|14,631,921|12.380|40.204|3m 2s~4m 40s|
|ë…¼ë¬¸ íŒŒë¼ë¯¸í„° w/ maxout|o|40,127,409|12.747|40.328|4m 12s~4m 16s|

maxoutì„ ì‚¬ìš©í•˜ë©´ íŒŒë¼ë¯¸í„° í¬ê¸° ëŒ€ë¹„ ì„±ëŠ¥ì´ ì¢‹ìœ¼ë‚˜, maxì—°ì‚° ë•Œë¬¸ì¸ì§€ ì†ë„ëŠ” ì˜¤íˆë ¤ ëŠë ¤ì¡Œë‹¤

## ğŸ¤” Paper review
**1) PPT í•œ ì¥ ë¶„ëŸ‰ìœ¼ë¡œ ììœ ë¡­ê²Œ ë…¼ë¬¸ ì •ë¦¬ ë’¤ ì´ë¯¸ì§€ë¡œ ì²¨ë¶€**
![image](https://user-images.githubusercontent.com/46675408/112748663-3348c300-8ff8-11eb-860a-dbdc3e0dbad5.png)

**2) (ìŠ¬ë™ìœ¼ë¡œ ì´ë¯¸ í† ë¡ ì„ í–ˆì§€ë§Œ ê·¸ë˜ë„) ì´í•´ê°€ ì•ˆ ê°€ëŠ” ë¶€ë¶„, ì´í•´ê°€ ì•ˆ ê°€ëŠ” ì´ìœ (ë…¼ë¬¸ ë³¸ë¬¸ ë³µë¶™)**

1) ![image](https://user-images.githubusercontent.com/46675408/112748684-596e6300-8ff8-11eb-8f76-40a94163583a.png)

2) alignmentì˜ FCNë¶€ë¶„ + decoder ë¶€ë¶„ <br>
  a) encoderì˜ hidden stateì— Wë²¡í„°ë¥¼ ê³±í•˜ê³ , decoderì˜ hidden stateì— Uë²¡í„°ë¥¼ ê³±í•´ì„œ ë”í•œ ë’¤(concatí›„ FCNí•œê±°ë‘ ê°™ìŒ) tanë¥¼ êµ¬í•˜ê³  ì´ë¥¼ ë‹¤ì‹œ vë¡œ ê³±í•œê±¸ softmaxì·¨í•œê²Œ attention score..ì–´ë§ˆì–´ë§ˆí•˜êµ°<br>
  b) ì´ attention scoreë¥¼ encoderì˜  hidden stateì™€ ê³±í•´ì„œ contextë²¡í„°ë¥¼ êµ¬í•œë‹¤<br>
  c) context ë²¡í„°ì™€ ì´ì „ ì‹œì ì˜ output vectorë¥¼ ì„ë² ë”©í•œê±°ë‘ decoderì˜ íˆë“ ë²¡í„°ë‘ì„ weighted sumí•´ì„œ targetì´ ë‚˜ì˜¤ê²Œ ëœë‹¤ 

**3) ì¬ë°Œì—ˆë˜ ë¶€ë¶„**

ì„±ëŠ¥ ê·¸ë˜í”„ 
![image](https://user-images.githubusercontent.com/46675408/112748689-625f3480-8ff8-11eb-85d5-9f67c0bdcf05.png)
1) ì „ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ë” ì¢‹ì€ ê²ƒ â†’ì´ê±´ íŒŒë¼ë¯¸í„°ê°€ ë” ë§ì•„ì„œ ê·¸ëŸ´ ìˆ˜ ìˆìŒ
2) ë‹¨ì–´ 30ê°œê¹Œì§€ í•™ìŠµí•œ ê²ƒê³¼ 50ê°œê¹Œì§€ í•™ìŠµí•˜ëŠ”ê±¸ ë³¸ ë‹¤ìŒì— ì´ê±¸ testì…‹ì„ ë˜ sentence lentghë¡œ í‰ê°€í•œ ì  â†’ì°¸ í›Œë¥­í•˜ê²Œ ì„±ëŠ¥í‰ê°€ë¥¼ í–ˆë‹¤..ë…¼ë¬¸ ì“°ë ¤ë©´ ì´ë ‡ê²Œ í•´ì•¼ë˜ëŠ”êµ¬ë‚˜
3) RNNsearch-50ì˜ ìš°ìˆ˜í•¨.. ì™œ rnn-30ì€ ê¸¸ì´ 30 ê°€ê¹Œì´ì„œ ë–¨ì–´ì§€ëŠ” ì¶”ì„¸ê°€ ë³´ì´ëŠ”ë° 50ì€ ì €ë ‡ê²Œ í›Œë¥­í• ê¹Œ

alignment functionê³¼ RNN functionì„ ë³¸ë¬¸ì—ì„  ì•„ì£¼ ì¼ë°˜ì ìœ¼ë¡œ ì‘ì„±í•˜ê³  í›„ì— ìš°ë¦¬ëŠ” ììœ ë¡­ê²Œ ì„ íƒí•˜ê¸° ìœ„í•´ ì œë„ˆëŸ´í•˜ê²Œ ì‘ì„±í–ˆë‹¤ê³  í–ˆë‹¤ëŠ” ì 
â†’ í›„ì— scaled-dot attention ë“± ë‚˜ì˜¤ê²Œëœ ì´ˆì„..?..ì—­ì‹œ ìƒìƒë ¥ì„ í’ë¶€í•˜ê²Œ í•˜ëŠ”ê²Œ ì¤‘ìš”í•˜êµ°

**4) ë…¼ë¬¸ êµ¬í˜„ ì‹œ ì£¼ì˜í•´ì•¼í•  ê²ƒ ê°™ì€ ë¶€ë¶„(ë…¼ë¬¸ ë³¸ë¬¸ ë³µë¶™)**

. Alignment model
. decoder..
. bi-directional RNN
. attention scoreë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ scaled-dot productê°€ ì•„ë‹Œ ë³„ë„ì˜ FCN 
. maxout 
. ë‹¨ì–´ì˜ max len ê°€ì§€ê³  model 4ê°œ ë§Œë“œëŠ”ê±° 
. ê°ì¢… initialize

**5) ì†Œê°œí•˜ê³  ì‹¶ì€ ê°œë… í•˜ë‚˜ (ë°œí‘œ 5ë¶„ ë¶„ëŸ‰, ì„ íƒ)**

[maxout](https://arxiv.org/pdf/1302.4389.pdf)
Dropoutì˜ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”ì‹œí‚¤ê¸° ìœ„í•œ í™œì„±í™” í•¨ìˆ˜

## ğŸ¤« ë…¼ë¬¸ê³¼ ë‹¤ë¥´ê²Œ êµ¬í˜„í•œ ë¶€ë¶„
- dataset : Multi30k english-french
- optimizer : Adam
- initialize ì¼ë¶€
  - $W_a$ì™€ $U_a$ëŠ” N(0, 0.001^2)ì´ê³  biasëŠ” 0 -> ì½”ë“œì—ì„œ concatë˜ì–´ ìˆëŠ”ë° ê·¸ëƒ¥...í•˜ë‚˜ë¡œ..
  - $V_a$ëŠ” ë‹¤ 0ìœ¼ë¡œ ì´ˆê¸°í™” -> $v_a$ë¼ê³  ì¼ë‹¨ ìƒê°í•¨
- ë…¼ë¬¸ì—ì„œ Maxout hidden layerë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ì˜ë¯¸ë‹¤..ë¼ê³  ì“´ê±¸ Maxoutìœ¼ë¡œ êµ¬í˜„í•¨ 

## ğŸ¤­ ë…¼ë¬¸ êµ¬í˜„í•˜ë©´ì„œ ë°°ìš´ ì  / ëŠë‚€ ì 
- aligningì´ë¼ëŠ” ìš©ì–´
- Baddhanau attention
- [maxout](https://m.blog.naver.com/PostView.nhn?blogId=laonple&logNo=220836305907&proxyReferer=https:%2F%2Fwww.google.com%2F) ê°œë…ê³¼ ì´ì°¨í•¨ìˆ˜ ê·¼ì‚¬ ê²½í—˜
- [orthgonal initialization](https://smerity.com/articles/2016/orthogonal_init.html) 
- torchtext Fieldì˜ `.preprocess`ì™€ `.process`ì˜ ì¡´ì¬
- `predict`ë¥¼ ì§€ë‚œ ë‹¬ë³´ë‹¤ ë” ê¹”ë”í•˜ê²Œ êµ¬í˜„í•¨
- RNNì˜ ouputs ì¤‘ outputê³¼ hiddenì—ì„œ outputì´ ëª¨ë“  tì‹œì ì˜ ë§ˆì§€ë§‰ ì¸µì˜ hidden state ë¥¼ ëª¨ì•„ë†“ì€ ê²ƒì´ë¼ëŠ” ê²ƒ[.](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) 
- bi-directional LSTMì˜ outputì˜ í˜•íƒœ(hidden[-1, :, :]ì´ ë§ˆì§€ë§‰ ë‹¨ì–´ë¥¼ ë³¸ forward hidden stateì´ê³  hidden[-2, :, :]ì´ ì²«ë²ˆì§¸ ë‹¨ì–´ë¥¼ ë³¸ backward hidden state
- seq2seqì—ì„œ encoderë¥¼ bi-LSTMì„ ì¼ì„ ê²½ìš° forard, backwardì˜ hidden stateë¥¼ concatí•´ì„œ ë„£ì–´ì£¼ëŠ” ê²ƒì´ [ì •ì„](https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66)
- v ë²¡í„° ë”°ë¡œ x ë²¡í„° ë”°ë¡œ í•´ì„œ + í•˜ëŠ” ê²ƒ ëŒ€ì‹  vë²¡í„° xë¥¼ concatí•´ì„œ FCNí•˜ëŠ” trick
- torchì—ì„œ ì—¬ëŸ¬ ëª¨ë¸ì„ ì¡°ë¦½í–ˆì„ ë•Œ `model.named_parameters()`ê°€ ì–¼ë§ˆë‚˜ ì•„ë¦„ë‹µê²Œ ë‚˜ì˜¤ëŠ”ì§€ 
![image](https://user-images.githubusercontent.com/46675408/113498443-e446e480-9547-11eb-9be0-a910635c61c7.png)  
