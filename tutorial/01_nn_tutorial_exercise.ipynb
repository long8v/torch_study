{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 데이터셋을 가지고 연습해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f54ddea57b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = trainset.data[1201]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.targets[17865]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test  = map(torch.Tensor, (trainset.data, trainset.targets,\n",
    "                                     testset.data, testset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing의 자료형은 int형이여야 함. (when doing code from scratch)\n",
    "# y_label의 nll loss를 구할 때 category가 int형이여야 함. (when using functional)\n",
    "y_train = y_train.type(torch.int64)\n",
    "y_test = y_test.type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n : number of data set\n",
    "# h : height of image\n",
    "# w : weight of image\n",
    "# c : channel of image\n",
    "n, h, w, c = x_train.shape\n",
    "n_categories = int(y_train.max() - y_train.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 32, 32, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "nodes = h * w * c\n",
    "weights = torch.randn(nodes, n_categories) / math.sqrt(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0290, -0.0001,  0.0098,  ..., -0.0135, -0.0066, -0.0076],\n",
       "        [-0.0178,  0.0219,  0.0081,  ..., -0.0060, -0.0057,  0.0149],\n",
       "        [-0.0145,  0.0069,  0.0160,  ..., -0.0272,  0.0128,  0.0326],\n",
       "        ...,\n",
       "        [-0.0215,  0.0019,  0.0050,  ..., -0.0031, -0.0101,  0.0208],\n",
       "        [ 0.0224,  0.0041, -0.0009,  ..., -0.0190, -0.0289, -0.0248],\n",
       "        [ 0.0079,  0.0188,  0.0101,  ...,  0.0542, -0.0120, -0.0004]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(weights.requires_grad)\n",
    "weights.requires_grad_()\n",
    "print(weights.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.zeros(n_categories, requires_grad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ LogSoftmax(x)_i = log(\\frac{e^{x_i}}{\\sum_{j=1}^{K}{e^{x_j}}}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1) # broadcasting\n",
    "# berfore unsqueeze shape : (n, )\n",
    "# after unsqueeze shape   : (n, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.exp().sum(-1).log().unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mnist data set과 달리 3차원이기 때문에 1차원으로 바꿔줌 : torch.flatten 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(xb):\n",
    "    return torch.flatten(xb, start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    xb = preprocess(xb)\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NegBackward>) tensor(0.0870)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. torch.nn.functional 사용하기\n",
    "loss function을 functional에서 가져와서 써줌. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    xb = preprocess(xb)\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        yb = yb.type(torch.int64) # indexing의 자료형은 int64여야함.\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<NllLossBackward>) tensor(0.0870)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. nn.Module을 사용해보기 \n",
    "nn.Module을 상속하여 클래스를 만든다<br>\n",
    "forward 단계에서 가중치, 절편, method를 유지하고, ``.parameters()``와 ``.zero_grad()`` 등을 가지고 있음<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(nodes, n_categories) / math.sqrt(nodes))\n",
    "        self.bias = nn.Parameter(torch.zeros(n_categories))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = preprocess(xb)\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수를 사용하는 대신에, 오브젝트를 사용함<br>\n",
    "``nn.Module``오브젝트들은 마치 함수처럼 사용할 수 있다. 배후에서 PyTorch는 우리의 ``forward``함수를 자동으로 호출함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "\n",
    "                \n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4124707.5000, grad_fn=<NllLossBackward>) tensor(0.1740)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. nn.Linear를 사용해보기\n",
    "weight, bias를 정의 및 초기화하고, ``xb @ weights + bias``를 계산하는 대신에 미리 정의된 선형 레이어로 ``nn.Linear``를 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(nodes, n_categories)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.linear(preprocess(xb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5978771.5000, grad_fn=<NllLossBackward>) tensor(0.1810)\n"
     ]
    }
   ],
   "source": [
    "model = CIFAR_Logistic()\n",
    "fit()\n",
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. optim을 사용해보기 \n",
    "매개변수를 수동으로 업데이트 하는 대신 옵티마이저의 ``step``메서드를 통해 업데이트 가능<br>\n",
    "``optim.zero_grad()``는 기울기를 0으로 재설정해주어 다음 미니 배치의 기울기 계산 전에 호출해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = CIFAR_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(76.9773, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset을 사용해보기\n",
    "x와 y를 묶어서 코드 한 줄에서 사용하기 용이<br>\n",
    "이 전에는 x의 배치와 y와 배치를 따로 작성했다면 이번엔 한번에 인덱싱할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4439417.5000, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DataLoader를 사용해보기\n",
    "``DataLoader``는 배치 관리를 담당하여 반복하기 쉽게 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4667869., grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. test data추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_test, y_test)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(4965318.)\n",
      "1 tensor(4535693.5000)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "\n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. refactoring : fit(), get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6814374.0\n",
      "1 3717927.9\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. CNN\n",
    "사전에 정의된 ``nn.Conv2d``를 사용함<br>\n",
    "Conv2D + ReLU + average pooling을 진행함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. nn.Module + nn.Conv2d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # nn.Conv2d(in_channels, out_channels)\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1) # RGB channel 개수가 1->3 이어서 변경해줌\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, n_categories, kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, c, w, h) # [1000, 32, 32, 3] -> [1000, 3, 32, 32]\n",
    "        xb = F.relu(self.conv1(xb)) # [1000, 3, 32, 32] -> [1000, 16, 16, 16]\n",
    "        xb = F.relu(self.conv2(xb)) # [1000, 16, 16, 16] -> [1000, 16, 8, 8]\n",
    "        xb = F.relu(self.conv3(xb)) # [1000, 16, 8, 8] -> [1000, 10, 4, 4] \n",
    "        xb = F.avg_pool2d(xb, 4) # [1000, 10, 4, 4] -> [1000, 10, 1, 1]\n",
    "        return xb.view(-1, xb.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.302568197250366\n",
      "1 2.302568197250366\n"
     ]
    }
   ],
   "source": [
    "model = CIFAR_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. nn.Sequential 사용해보기\n",
    "``Sequential``을 사용하면 해당 객체에 포함된 각 모듈을 순차적으로 실행함<br>\n",
    "이를 활용하려면 사용자정의 레이어를 정의해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, c, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.302568197250366\n",
      "1 2.302568197250366\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(c, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, n_categories, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4), # 입력 텐서 크기 \n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DataLoader 감싸기\n",
    "preprocess를 모델에서 dataloader로 옮길 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, c, w, h), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(c, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1), # AdaptiveAvgPool2d는 출력텐서의 크기를 정의할 수 있음\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.302568197250366\n",
      "1 2.302568197250366\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "long36v",
   "language": "python",
   "name": "long36v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
