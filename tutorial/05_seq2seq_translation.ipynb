{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역\n",
    "**Author**: `Sean Robertson`\n",
    "**번역**: `황성수`\n",
    "\n",
    "이 튜토리얼은 \"기초부터 시작하는 NLP\"의 세번째이자 마지막 편으로, NLP 모델링 작업을\n",
    "위한 데이터 전처리에 사용할 자체 클래스와 함수들을 작성해보겠습니다.\n",
    "이 튜토리얼을 마친 뒤에는 `torchtext` 가 어떻게 지금까지의 튜토리얼들에서의\n",
    "전처리 과정을 다루는지를 이후 튜토리얼들에서 배울 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 프로젝트에서는 신경망이 불어를 영어로 번역하도록 가르칠 예정입니다.\n",
    "\n",
    "\n",
    "    [KEY: > input, = target, < output]\n",
    "\n",
    "    > il est en train de peindre un tableau .\n",
    "    = he is painting a picture .\n",
    "    < he is painting a picture .\n",
    "\n",
    "    > pourquoi ne pas essayer ce vin delicieux ?\n",
    "    = why not try that delicious wine ?\n",
    "    < why not try that delicious wine ?\n",
    "\n",
    "    > elle n est pas poete mais romanciere .\n",
    "    = she is not a poet but a novelist .\n",
    "    < she not not a poet but a novelist .\n",
    "\n",
    "    > vous etes trop maigre .\n",
    "    = you re too skinny .\n",
    "    < you re all alone ."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성공율은 변할 수 있습니다.\n",
    "\n",
    "하나의 시퀀스를 다른 시퀀스로 바꾸는 두개의 RNN이 함께 동작하는\n",
    "`sequence to sequence network <https://arxiv.org/abs/1409.3215>`__ 의 간단하지만 강력한 아이디어가\n",
    "이것(번역)을 가능하게 합니다. 인코더 네트워크는 입력 시퀀스를 벡터로 압축하고,\n",
    "디코더 네트워크는 해당 벡터를 새로운 시퀀스로 펼칩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델을 개선하기 위해 `Attention Mechanism` 을\n",
    "사용하면 디코더가 입력 시퀀스의 특정 범위에 집중할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 파일 로딩\n",
    "==================\n",
    "\n",
    "이 프로젝트의 데이터는 수천 개의 영어-프랑스어 번역 쌍입니다.\n",
    "\n",
    "`Open Data Stack Exchange`에 관한 이 질문은 https://tatoeba.org/eng/downloads 에서 다운 로드가 가능한\n",
    "공개 번역 사이트 https://tatoeba.org/ 를 알려 주었습니다. 더 나은 방법으로\n",
    "언어 쌍을 개별 텍스트 파일로 분할하는 추가 작업을 수행한\n",
    "https://www.manythings.org/anki/ 가 있습니다:\n",
    "\n",
    "영어-프랑스어 쌍이 너무 커서 저장소에 포함 할 수 없기 때문에\n",
    "계속하기 전에 ``data/eng-fra.txt`` 로 다운로드하십시오.\n",
    "이 파일은 탭으로 구분된 번역 쌍 목록입니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자 단위 RNN 튜토리얼에서 사용된 문자 인코딩과 유사하게, 언어의 각\n",
    "단어들을 One-Hot 벡터 또는 그 단어의 주소에만 단 하나의 1을 제외하고\n",
    "모두 0인 큰 벡터로 표현합니다. 한 가지 언어에 있는 수십 개의 문자와\n",
    "달리 번역에는 아주 많은 단어들이 있기 때문에 인코딩 벡터는 매우 더 큽니다.\n",
    "그러나 우리는 약간의 트릭를 써서 언어 당 수천 단어 만\n",
    "사용하도록 데이터를 다듬을 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나중에 네트워크의 입력 및 목표로 사용하려면 단어 당 고유 번호가\n",
    "필요합니다. 이 모든 것을 추적하기 위해 우리는\n",
    "단어→색인(``word2index``)과 색인→단어(``index2word``) 사전,\n",
    "그리고 나중에 희귀 단어를 대체하는데 사용할 각 단어의 빈도\n",
    "``word2count`` 를 가진 ``Lang`` 이라는 헬퍼 클래스를 사용합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # SOS 와 EOS 포함\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일은 모두 유니 코드로 되어있어 간단하게하기 위해 유니 코드 문자를\n",
    "ASCII로 변환하고, 모든 문자를 소문자로 만들고, 대부분의 구두점을\n",
    "지워줍니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니 코드 문자열을 일반 ASCII로 변환하십시오.\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 소문자, 다듬기, 그리고 문자가 아닌 문자 제거\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split\n",
    "lines into pairs. The files are all English → Other Language, so if we\n",
    "want to translate from Other Language → English I added the ``reverse``\n",
    "flag to reverse the pairs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # 파일을 읽고 줄로 분리\n",
    "    lines = open('data/data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # 모든 줄을 쌍으로 분리하고 정규화\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # 쌍을 뒤집고, Lang 인스턴스 생성\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*많은* 예제 문장이 있고 신속하게 학습하기를 원하기 때문에\n",
    "비교적 짧고 간단한 문장으로만 데이터 셋을 정리할 것입니다. 여기서\n",
    "최대 길이는 10 단어 (종료 문장 부호 포함)이며 \"I am\" 또는\n",
    "\"He is\" 등의 형태로 번역되는 문장으로 필터링됩니다.(이전에\n",
    "아포스트로피는 대체 됨)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 준비를 위한 전체 과정:\n",
    "\n",
    "-  텍스트 파일을 읽고 줄로 분리하고, 줄을 쌍으로 분리합니다.\n",
    "-  텍스트를 정규화 하고 길이와 내용으로 필터링 합니다.\n",
    "-  쌍을 이룬 문장들로 단어 리스트를 생성합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\tfra 4345 eng 2803\n",
      "['elle fait partie du personnel enseignant .', 'she is on the teaching staff .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\", end='\\t')\n",
    "    print(input_lang.name, input_lang.n_words, end=' ')\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "Recurrent Neural Network(RNN)는 시퀀스에서 작동하고 다음 단계의\n",
    "입력으로 자신의 출력을 사용하는 네트워크입니다.\n",
    "\n",
    "`Sequence to Sequence network`, 또는\n",
    "Seq2Seq 네트워크, 또는 `Encoder Decoder network`는 인코더 및\n",
    "디코더라고 하는 두 개의 RNN으로 구성된 모델입니다.\n",
    "인코더는 입력 시퀀스를 읽고 단일 벡터를 출력하고,\n",
    "디코더는 해당 벡터를 읽어 출력 시퀀스를 생성합니다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 입력에 해당하는 출력이 있는 단일 RNN의 시퀀스 예측과 달리\n",
    "Seq2Seq 모델은 시퀀스 길이와 순서를 자유롭게하기 때문에\n",
    "두 언어 사이의 번역에 이상적입니다.\n",
    "\n",
    "다음 문장 \"Je ne suis pas le chat noir\" → \"I am not the black cat\"\n",
    "를 살펴 봅시다. 입력 문장의 단어 대부분은 출력 문장에서\n",
    "직역(\"chat noir\" 와 \"black cat\")되지만 약간 다른 순서도 있습니다. \n",
    "\"ne/pas\" 구조로 인해 입력 문장에 단어가 하나 더 있습니다.\n",
    "입력 단어의 시퀀스를 직역해서 정확한 번역을 만드는\n",
    "것은 어려울 것입니다.\n",
    "\n",
    "Seq2Seq 모델을 사용하면 인코더는 하나의 벡터를 생성합니다.\n",
    "이상적인 경우에 입력 시퀀스의 \"의미\"를 문장의 N 차원 공간에 있는\n",
    "단일 지점인 단일 벡터으로 인코딩합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코더\n",
    "\n",
    "Seq2Seq 네트워크의 인코더는 입력 문장의 모든 단어에 대해 어떤 값을\n",
    "출력하는 RNN입니다. 모든 입력 단어에 대해 인코더는 벡터와\n",
    "은닉 상태를 출력하고 다음 입력 단어를 위해 그 은닉 상태를 사용합니다."
   ]
  },
  {
   "attachments": {
    "image-3.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-3.png](attachment:image-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size) # input_size, hidden_size\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1) \n",
    "        # 1(seq_len) by 1(batch_size) by -1(hidden_size)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 디코더\n",
    "\n",
    "디코더는 인코더 출력 벡터를 받아서 번역을 생성하기 위한 단어 시퀀스를\n",
    "출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 디코더\n",
    "\n",
    "가장 간단한 Seq2Seq 디코더는 인코더의 마지막 출력만을 이용합니다.\n",
    "이 마지막 출력은 전체 시퀀스에서 문맥을 인코드하기 때문에\n",
    "*문맥 벡터(context vector)* 로 불립니다. 이 문맥 벡터는 디코더의 초기 은닉 상태로\n",
    "사용 됩니다.\n",
    "\n",
    "디코딩의 매 단계에서 디코더에게 입력 토큰과 은닉 상태가 주어집니다.\n",
    "초기 입력 토큰은 문자열-시작 (start-of-string) ``<SOS>`` 토큰이고,\n",
    "첫 은닉 상태는 문맥 벡터(인코더의 마지막 은닉 상태) 입니다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPIAAAEqCAYAAAAvcg1SAAAABHNCSVQICAgIfAhkiAAAIABJREFUeF7tXQl8VNXV/89M9n1PSCAJIayBsMgmVFygCgUVq7grLlVb236tdlGrdam2VbFSK/XrZ1Vc6oaKGyKKqBQVUYysIUAgCdnJvq8z893zJpNMwkxmezPz5uUcf/nhvHvfXf7n/t89dztXYxQCFkaAEfBrBLR+XXouPCPACEgIMJG5ITACKkCAiawCJXIVGAEmMrcBRkAFCDCRVaBErgIjwETmNsAIqAABJrIKlMhVYASYyNwGGAEVIMBEVoESuQqMABOZ2wAjoAIEmMgqUCJXgREI8AQEvU3HPZGs36epCQiHLjzZJ/Xoba0E9B0+yZszPRUBbWgCNAFh0GjloaDGE4cmyp+ccmrJ+QmCs+YgYfkLPkGiZuNF6C4/7JO8OdNTEYg663ZE5KwWRA48NdCFJ2xauwAav8IIKA0BJrLSNMLlYQRcQICJ7AJo/AojoDQEmMhK0wiXhxFwAQEmsgug8SuMgNIQ8Asiv5PXjK0HW72KXUuHwav5cWa2ESD9fzKM/g9VdOGpT+tsJlDTrMfjH9WirdO6Tu2F20xYQQF+QeTN++rw2aEmr8F2z1sVeG5Hvdfy44yGR+C97+vw6TD6L6jswvodNTYTOdnSi8c/qEFbl3Ui2wu3mbCCAuRZjfZwhZ6+bqyHcxic/L6yNiyeHOTVPDkz1xG46LQo0N9IFr8g8vNfNCAyRIuLZ0fju+IOfHm0HWdODMdLX9WgprUHC8ZF46ZF8dDqIIXvONKG2ZmheHVXLQJ1WiydFiP+IiU9d3Ybce/b5bj1nGRkJpoW4ysberH24yrcc36qeKcBFfV6bDvUAK1Wg18uiR9R7cMeft09RtyzsRxXzk/A/35ehfS4UNy1PFlgBbzxbZPoORvR3WvAvKxo3HhGHHRCJ+t3NCAoQIOrTo/px/KI6EWf+6IGD1yYhuAgjV2MydXrq1834pN8agsBWDUnHgvHh0nv5Qmdv/t9Ix64aJT0u0eU8T8i7hdHG5EUFSQ+ytGD0rcXTpEPlHXixS9rUdHYhXFJYfjZ2YlIiTHRheozNjEIVU09UnmCA7S4bG4CFok26SvxC9N6x5FG7C4yjZGLarrxomgAv3ntBEbFhGLGmCis2XQST3xSK2FI4c9/XovfbyjF9DGRSIwMwm0vlYPGWSTdvUa88mWL+AD09mNe366XnrV3G4TSghEarBENIADjk0der2wPvx69Cb/bXi1BkE6D5o4eicT3vV2JRzZVIjM+FDMzosTQ5CRuebFIwjg4UIO1W6rQOwA5Xv66HiW1XQ6RmNLYtLsFm/bWCbLEoKWzF9f9qwT0MSApruvGpryBodfd4kPzr8+rMUuUo0d8VH73SpkUzyz2wr8QHcHFfy8W7UGPZbnx2FfWihVrC1HVaKoAtcc/bizDW7trsSA7BgISXPO/J3C4rzyDMvPSD7/okYdiUdVgxEu3ZGByarAUVN3ciS8LG3HbeQnS79pWI164egwWT4mQfms1Gjz0bgVWzrJvfi3JicA/PtFiWlpkfy8uJTKCxBH8zp0ai7tWJEmoHD8pPp7bG/HEtWn9GC/PjcQZDx7DzjPaccH0KDy4sQqfFrTi3KkR0OuBD/c34ffLTD2oI9Amx2nxwo3jECBa7GVzYjDjD4fxXUkHJowytQFzGvnlXXhVfJS33ZXVFxaPp1Pq8aeN1VIUe+EU568flOPMqcFYd02G9A5ZEsvXHsG6bSfx0MWp0rNQYUW8/rNs6SN23cJYzD1WICyANkwcUh4pshfEL4kcIUA0k5gwShU98/6y9n64QoXFvGDcgJmzaGIE/vlxHSqECR0R7BdGiBdUbzuL4fCLDjXhNzMjtD+BvaWdMIh5pL2l7civ6Ox/Hhumwb7SDpyeHYalM8KF+VsnEfkzQehuEW15rv0PqzmxKWkhEolJQoT+x4/RiQ+4RRffF/GgyD8tUTOI4GcJk/dPDobT0OFAiV5YcgH4i7D0zKITw6wD5W39v3NSQyUSk9C/idFa0YP77q4Hv2zVEUOGIqLDheV9GUlxGsk8NktMmBioCbGctbSM30u2EUs/Ao7gF9uHKb3U1KEXcxEQprZWWD9kAZn+rhJj5AkpIVK6NKbdtrcDrWJZ7+08QejpEYN0ZA/+iGCTDs3xSLvW7khpFmUxCHVahgWIIYBZ7IW3iCUqvfgohQXpBtVlQXY0zpsa159OaNBg6lCdfSl+2SPbA6yk2iiZe1lJpjHuF0daES16h3HiN42RSWg8bJbS+h57SY6o8OHw67DAzQzK2ASBqzCXl+REYs5YU09tEL837G5ElpgUIqFeOTlBg3f2NEuEfunnJrNVbmCnjQ5FRa0RB8s7MXW06SOyQ5i8ZrEXHh+pQ0IEzZEE487lpqEDvbu9oA2WHwS5y+1uen7ZIztS6Se2VqFWbASgGc03d9fhojlRkglEZllGshjffFMr9Q4ltT1iM4E4q2shMcJ8LDzZjuqmU003R/JWQxxb+Fmr28LscEwarcPajyqkCZ8uYWL+7eNaPLa5SlptICGr6aJZ8fi7mPQi09dMeGvpufNsuiBvTroOT2ytBK1G0Jh4wzcDa8z2winvSxfEYZOYBf/oQCvog/R1YTtufqYU9W3ih0JFlT1yYqRG9BBGnP7AEehEC1o6KxwPrDRNUpAe7l85Gne+Voapdx1GnIh794Wj8Kviin4VLcmJE5MjVcgrKcSXd09SqOo8Vyx7+A3Nmcau/7c6E7/bUIIlfz2OKGH9TEzTYc3lYxAXMWASrxLLh2s31+C6RYlDk5DtNy1lPXP9WPzy5WIseuiolO5PzonH3iLTzi974RT/9nMT0d7Vi589WyrNzCfFa3DT4gScP8O0hClbYWVMSHWOBd4Ua5kPi2WQ3Q9MQkOrXswuaqVeeKjQ5EyV6HFTogP6Jy0s49Bao1i5cGocNzSPob/9wbGAo/gNrZv5d3M7jTGNiLUgsK24nn5e16KXJjdtrVPbC6flshqxK2xUrPz9ndyOBeQvoae140T6wzUmMrNTh1FQoFj7lMd3gxMFVljU4fCzVdSoMOdGa2S6DjfVSCa5eXbYVp62ntN4dzixF06WhidIPFyZXA1THZGDA7WICXeuMbkKnhrf8zZ+K544Ino963ugCV/aC/DwqtFqhFrWOqmOyDSOUfJYRlbteSAxb+O3+fYJHqjFyEuSu66Rp3OusQoRYCKrUKlcpZGHABN55Omca6xCBJjIKlQqV2nkIeCRya7QqUtHHpIO1DgoMdeBWJ6JEpJ1LnSxYz2TOKfqNAKBcfJe4iD7hhCjQexbtrab3emqyv9CR0cHamvrMGaMD5czNFrZrglxFCGjQexsMNpe4nE0HW/G6+npwZGjxzA+OwtBQeo8Fy5dFyPagxwie48s1xUYclRuaBqd3a04XnwCyaOEV4rgwedYh8ZV02+57hfyJibVFdVobGpGYDDdjyRPY/dm+b2d14hCKDY2VpxpDRC9ssmbiLfB5vwcR6C6uhpJSUliV9eIaqKOAzQk5ohCSSP2+xGZ6+psu051GUl+UTYEWltbQX8pKSmypan2hEYUkUmZ8fHxaGxsFO5mlHskTe2Nzl79KisrERYWhqgoxz2I2EtT7eEjjsgJCQliLs6I+nr2W63Exk26OXnyJPfGTipnxBGZxsjR0dFsXjvZULwVneYvesX5QTarnUN8xBGZ4CHzmsbJZF7T15+WpViUgUBVVZU0j6HWJSdPoTziiNzZ2SkcmPdIJN6xYwfy8/NRUTHgHcRTQHO69hHo7u6WhjzcG9vHamgM2deRh2agpN/U8+7atUv4j9JI42QS+n9e4lCGlmjJSSeupkhM9JwrIGXUVP5SjKgeOTQ0VDLbiLxmof+nxsPiewTIrKa1Y0v9+L5U/lGCEUVkUsmUKVOkHtjcWKhnZiL7vrG2tLSgra0No0Y5fvuE70utnBKMOCIHBgZi6tSp/aY1qYJNa983SFo7Dg8PR2Skcj1V+h4l2yUYcUQmKGJiYpCent4/VuYe2XYD8UYIrx27j/KIJDLBlpWVhYiIvkveeD+v+y3JjRRqamqkVQSerXYdxBFLZIKMTGyaAKPtgCy+Q4AmueLi4kDDHhbXEPDI8lN+pRF/fsMf9jLTbPVpwC4Cz7+vhwkXVy49fZNH1Olay3LwLVo7bmhokCYhWVxHwCOapyVaPpPgulJcebPXH76bVipGvTFtm6U98CyuIzCiTWvXYeM35UKA147lQZKJLA+OnIoLCDQ3N6O9vZ3Xjl3AbugrTOShiPBvryFAvTGtHJhXD7yWsQozYiKrUKn+UCWDuA6TTp4lJyf7Q3EVX0ZVEnnmBHE/b8apV6m6o42xaeJy7sm207QMp63cy+ZqEM2blGxCzmvHNqFxKUCVRF40SYOZY22TzhWkcsZo8MMc23BZhhORrzpdh7goecvgSrmV+g6Z1XQunNeO5dGQR5af5Cma/6ZCl6hf/YR/r0t7Ev2uri7JbxqvHcuHsmKIfNpEYbqO0yBI7NHYW2rEf/caJT/3tHvyyrO1+GC3AWdN1SJDLDceKjfi4++MmJCuwdk5GtS1AdsPiDGXhXNM6hUXTdfgtEwNTrYAH35nQH3TAHDJ8cAPZ2iRLMzfE8J912aRflv7QHiMeH6G6IGzkoADZeKE1JDOdbhwqUc+Ryvl2dBsKv+mb0T5p2kxTqRX3gi8v0vkZ+GYJFv0+PPFkCBabOzYUWBERAhQ3woUFA93Dbh8DcGbKfHasfxo27YV5c/LZoqrztTiprN0KBeEyq8w4tI5Wvx8ualoRIoVuVr88cc6UE93WOwau3SeDr9ZqcOVC7XIF6ROjQbuvGDwmeKlgvRLBBG/PmbEmFgN1lwdgJg+p4w0nn30ygCEih2BXxwxYtIoDR6/JgDhfTs1yXf9vZfoMEOMs789bsSC8VpcdNoAVPbCzWWOjtCIgxmm8v9BlD8mHFJ5ZooP0N0XD5SXxvP3ivoEiCzoI3WjwOOGRTqMS1anaU5EpkkuPndskxJOB/i8R44TJLxophaPfqDHnqOm3mf3UT3+dWMANqUaUVpterZd9FLv7jRdezI6zoDFkwX5n+5Fi+iNdwsyPvfTACTGATV9zjG7xU6n+17VS736zgN6/P0GHZbP1uLlTw24XhBl13ED/r3FlN6ufD3+dKUO58/V4rXPDfihKE+HuPnmwddN26W+Eu/fe/kA8eyFW9MClf8D0QuTVDUY8OdVOtC2SuqVbxYWx+b9Bilvkn3Feqy7zueqsVYNt5/R2jF5auFzx25DOSgBn7eWDNHrUL8zLkWDzMSBHqi9GxgrViZKq03lPXZywMSsFKbp8RqjRGKSjk7Tv1HhGkFkU7xviwyDrqDKOyFMcZEHOQPJThLmeKsRKxcM9LIG8RqFk2QJTzNk3lvKt4L4M9NN8e2FD3qx78exvg8S/WxoMaVNZwSCBXfThMXw9GcDdzPVNgCVTYPzt5amPz6jc8e0bkxnj1nkQ8DnRA4TZmyvaMPCAyosm+47eQaUWYx52/rIaq46Ed0s1u6MqxFjU0tpFKSn8XeQII9W8LVT9LhEXrPkibFoa6fpQUSw8OOlGUwk/QDPYC98cM6mX10iP7OY8yWzO7TvCqoG8WGxlJYh9bWWpr89o7VjWnbKzMz0t6Irvrw+J3K16F0DBcHyioQZXWVqzNTAZ4slpJoG13ulcaLXtRSa9CoVvTX13q1dkCbI3usz1SkeTTaZyXpU9PbzxmrwmkUCM/p6Y3pkL9wZrTeJiTgy49OFNXKyzlTfMGFyjxfl3yXG02oSIjGRmc8dy69Vn092HReTOycEwS47XYuEWEim7/J5WtwoJns6LXpdZ6s+bbRGIifNes+bosEEYcJvETPhJJv2iHGwGGNPEuSmj0aGmOz6o5hsihQEItkpxrPJYg2YZr2pPLnZGlB6ZrEX3h/Rgf8ha2KjmDG/7gytVM7Ropw/WUI+xRx42c+imNeO6bQTi7wI+BxRmol++B09bj1PhydXB6BTmNg0Hv7bh3p0ip7TVQeXnx824KeLtUiMJNe3wLptehwXy0gktPQTIq7cvVvMdJOZW99mxAaxPLSv0BReJsazj2/R43pBrpvO1EjhHx00IF2MZUnshTurok2iPBpxT+4V87UIFhr56IARKdFG9OjV0yOb145zcnKchYfjO4CA7BedU54HxRKSecbXgTL0R6H7rKXxqyCwXBIp5lRaxfqwtXE09dY0c2yeNLOWZ4RYkqL3bYm9cFvvWT4fJ3r7cmHOW9Z73U90ePErA77Jd4zMZI7TzL1Spbi4WLoIYMGCBUotol+XS1GaF84iZJfhSErWwHDhVJjhSOxIuCMVulT0xJ09RqwXS2M9wiKh5a3gIA0OlThGYkfy8HUccj7PByQ8pwVFEdlz1VR2yv+3VY+LxRzBw7RJRVglh8Wk331v6u1+ZJRdq4HSNTU18dqxh5XFRPYwwI4kT1tHaXPKv2GQJufIUlCT0Nox+atmJ4ee06rPZ609VzX/TFltJDavHfOSk2fbIxPZs/iO+NTJeQA5oOfxsWebAhPZs/iO+NR57dg7TYCJ7B2cR2QudBc1TXSxWe159XtksotmXmmHEov3EAgX55eVJjTJFSQ2B5AnEBbPIuCRDSGeLbL3Uu8VJzno2B1dZ8LiPAJff/21dN8x3bPF4lkE2LQeBt/6+nrs379fnMxitz3DwGQ1iFz5kGnNZrVVeGR/yEQeBlIyCcmLRV2dxXnKYeJz0AACZFZHRUXx2rGXGgUTeRig6d7k6OhoJvIwGFkLoitSa2truTe2Bo6HnjGR7QBLl4uRiU1roSyOIcBrx47hJGcsJrIdNInINEamZRQWxxCgtWPCjSwaFu8gwES2g3OwcJlJPqbIuwWLfQTIsR6vHdvHSe4YTGQHEKVJL/OEF83E0hiQxToC1BvTx4+X7Kzj46mnHtkQ4qnC+ipdaphE4J07d4I8XaSnp/PaqA1lmH1W2wjmxx5CgIk8DLBE2t27d6Onp0dahqLf9C87VrcOGk0KEkbss9o6Pp58yqb1MOjS9kJyFEfEtZy11tKhYZZTEKDemJbrQkP7vBieEoMfeAoBbpHDIEsEnjZt2qAemJ7xbOypoPHa8amYePMJE9kO2uTVIjs7uz8W9cxM5FNBI59c9JGjvdUs3keAiewA5qmpqdK6qNnEZtP6VNB47fhUTLz5hInsINqTJ0/uv5Sbe+TBoNHaMZ0S40kuBxuTB6IxkR0Elcg7depUqVemSTClirhV2utFowMSISEhiImJ8XrenKEJAb9cftrV9b5v9CcuXAueLfxNB2wHZHSiL1dlYrWjMCFwtlzJOZwOjY/5uKLDcHkkol8SudnYd9eqRyCxkyhtH/Z+p2enUKbgIKP3l31oxxuvHTukHo9GYtPao/CqP3HqjcmkJtOaxXcIMJF9h73f50ynwujcMbu69b0qmci+14HfloDXjpWjOiaycnThdyWhtePExETeIKMAzTGRZVBCd1cPXnpwE06eqJchNf9Ior29HS0tLTxbrRB1MZFlUESPuJ39pb+8i5qyBhlS848keO1YWXpiIitLH35TGl47VpaqmMhD9EFm8t9v/Q8KvinGQ1c8jWf+sFFcc2pAW3MHnr/vPdxz4To8esN6fP9pgU1NbvzHNmx/Y/eg8Bfuf2/Yd2wmpsAAWjumM9q8CUQ5ymEiD9FFb48em9dvx+M3v4DAoAC0NXWgq6MHty16VBAxH/OWTRNnlHW4d9WT+OQ/X1vV5Hdb83Hom6JBYV+9twfFB8utxve3h+Zzx7x2rBzN+eXOLm/AN3/FdNzw0Eopq1cf+RC1VfV4afvDCI827Z4aNS4RLzzwHhZfNc8bxVFMHrR2TD3yhAkTFFMmLgjARLbRCibOyewPOZp3AvHJsXjt0S39z+oqG1FdVoOa0oZ+cttISlWPqTfmc8fKUykT2YZOIuPC+0PIvA4SV0xankNOTIvDFb9dAY3Wxq2TQ/Zjk8muBqFJLlo75jPZytImE9kBfYwam4C92w9j9QPn9zfgisIaHNxZiJikSHSLMbSl0Ni6s23geJS+V4/KYh8e9HCgjo5EaWtrk9aOLT2mOPIex/E8AjzZ5QDGS6//AcqLqvDyQ5vR0tCGusomPHbT8/j2o4PShNhQSc1OxHef5KP86ElptvvpO94St1XohQO/oTH96zetHZNjPXKwx6IsBJjIDuhj0txM3Ln+Jnz84le4Mvv3+Om8BxCXEo2f/e1Sq2//+H+WIDEtFtfn3o0rsn4LvTCr5yzJFWNLq9H94iH5KqM7nXjJSZnq8suLzrd2PuMzNGn3FpnT1nrioYVqqG5GaGQIQsK841EkQZuJmUFLhhZDlt90yungwYOYP3++dJMEi7IQONUuVFb5FFeaxNGxDpcpNjnK4bhKj0iz1XTumEmsTE2xaa1MvSiqVLSLi26RYLNaUWoZVBgmsnJ1o5iS0ZITLTfRshOLMhFgIitTL4oqlfncMa8dK0otgwrDRFaubhRRstbWVtAf+6xWhDpsFoKJbBMaDiAEaO2Yrs2JilLPxJ0aNctEVqNWZaoTrx3LBKQXkvHL5ScN+PtjrW2Im5utPXb5Ga0d02knnq12GUKvveiXG0K8ho4HMyKCkN8ruU1WujJGLkLv379fuhc6NzfXg0hw0nIgwF2bHCi6kEZZWRn27NkDWtqRU+QiMa8dy6kVz6fll6a152HxfA6ZmZmgy8ELCgqkK1fS09M9n6kTOdCSE11cx2vHToDmw6hMZB+CP27cOOmqlcLCQtDVpBMnTvRhaQZnTUSmS8vJiQCL8hFg09rHOkpLS0NOTo50smjfvn2Soz9fC505prPHvHbsa004nj8T2XGsPBYzISEBM2bMkDZe5OXlobu722N5OZIw9cbh4eGIjIx0JDrHUQACTGQFKIGKQKSZNWuW1CMTmWlG2xdiXjvmi9l8gb7reTKRXcdO9jdpvExkpn+JzI2NjbLnYS/BmpoaXju2B5ICw3kdWYFKoV7x0KFD0pWl5HbWvCGDntOf3IcXOjs7sWvXLsTFxUkz6ZQ+rx0rsGEMUyTukYcBx1dBNFM8ZcoUjB49WlqeKi4ulgi8d+9eqaeWW2hMTunTmWOyApqamqSZdF+P1eWup5rT4+UnBWs3KytLMrOPHj0KMnlp3EyEo4MMcs4oU5ok5n+pV6YNKxEREbw9U8Htw7Jo3CMrXFGpqanSpgxaDjIT7dixY5IJLJcMTYssAsqT91jLhbDn02Eiex5jt3KgLZy0xmwpRLySkhK30rV82fyBoGdEYlp6mjx5smzpc0KeR4CJ7HmM3cqBSEZbJS13WNGz0tJS0CSVHGLehEJ5BAQESBNdck+oyVFOTsM2Akxk29goIoTM24ULF0rbN80npYhwRGaakJJDzD0ypTt9+nQEBXnHfa8cZec0TAjwZJcXWkKv2HXZN5/kYm5axCemSH804VVVWYHqqkppeaq5rROhYkLMHenVmya7xk+YjODQCHj7mirazh3AXYo7KgSvI7sFn+MvbzlgwPGT8t0Zo4EBoWhCOxz3s22rtFqRVjBa0QHfuPO59RydraLxcwcR4B7ZQaDcjZZXZMS+QvmILKalRJFixJ8caVJatK9ajrScR+rWc5x/h98YjAAbNNwiGAEVIMBEVoESuQqMABOZ2wAjoAIEmMgqUCJXgRFgInMbYARUgAATWQVK5CowAkxkbgOMgAoQYCKrQImWVRDbsrFwmga/WKHFtUvEjjCx1Hz1Yi0iwiD2bJv+PzVJg1uXa3HRQm3/sxiLvSCR4aZ4wbxT029aBxPZb1TlWEGvOluLK+drUVBpRK846fjQpTqsyNWKbZwQByEg/f/tP9JK2zDDxTMiNz2LDBtwexsmntMzcX6CxU8QYFX5iaIcKWZKAvCjaVrc+boexRW0S8uIhjYNVi8cvAVyx2Ej3t1pcrvL5yMcQVb5cbhHVr6OHC5hZrIGrV1AieiNzbJHbA0dKkerTn02NA7/9i8EmMj+pa9hSxshTOL6NnLQNxCtQxB7qLTaOcZMJjiLfyHAKvMvfQ1b2rI6ICVKg+DggWg5GcNf+WL2GBQcOPBOgkiDxb8QYCL7l76GLe3hEiMqmoy4bYUOmakazBivwcWzh1cxEflksxFLxEx3oCBzjDgEdZmYLGPxLwRYY/6lr2FLSyb1g2/q0d5txN0rdbj8dC3e/d40qdXTa/vVp7YZMCtdi+dvDcCaqwOwcbfv75+yXVoOsYYAz1pbQ8VPn9ESU1KsBv94n4hoImP6KHILBLSLcXFPD3D52lMZXVBsxM3/6gWtH7e0mSp/+eFT4/kpLCOi2Nwjq0jNNEn10CU6nDNTjJPFZo6keGD1Ii2+KTIIZ/P2K2omsf2YHENpCHCPrDSNuFGeNnHv2yMf6HGe2Mxx3Q80aOsyIu+EEc8L05lF3QgwkVWmX3IntK9QL+3YktGHvcpQUl912LRWn06lGjGJVapYG9ViItsAhh8zAv6EABPZn7TFZWUEbCDARLYBDD9mBPwJASayP2mLy8oI2ECAb5qwAYzcj+tajWLHldypAr093QgIdN8DAN3/ZND3Qhdgsela/uJaTXFMHO/ttgqMEw+ZyE6ApbSodPn5oUOHMGPGjP4L3lwt4759+8Re60C+TtVVAH38HpvWPlaAq9kTifPz8zFq1Ci3SUxloIvNKc3eXt6a6apOfPkeE9mX6LuYN118TiROTU3F+PHjXUxl8GvJycnSncgVFRWypMeJeBcBJrJ38XY7NyIxmdNpaWmykZgKRSSmu5grKyvdLiMn4H0EmMjex9zlHKurqyUSjx49GtnZ2S6nY+tF6uE7OjpQX19vKwo/VygCTGSFKmZosYjEBQUFEonHjRs3NFiW32FhYYiJiWHzWhY0vZsIE9m7eLuUW1VVlUTiMWPGeIzE5oJRr1xXVyeOPXpgrcyl2vNLjiDARHbKpWQRAAAYXklEQVQEJS/H0VuceKAx6+HDh5Geno6srCyPl4Rmr2kZiie9PA61rBkwkWWF0/3EioqKsHPnTrS1tUkTT0eOHEFGRgbGjh3rfuIOpKDRaHjSywGclBaFiawgjdAabllZmbSWm5eXh8LCQonEmZmZXi0lzYiTaU3ryiz+gQATWUF6IhIbDCZvHvQv9Y5JSUleL2Gw8KcbFxfH5rXXkXc9Qyay69jJ+iaNi4nItOeZhP6lnvn7778XTgKEz1ovC016NTY2SstRLMpHgImsEB0RiS0JS72xuUfWkd8eL0t8fLxwdB/MvbKXcXc1O/bZ5SpyMr5HZvSJEyekXpjIS7usaJxKy000g+wroX3c9IGh2XIqF4tyEVAFkaV7B/34XrLyikqpNw4Q95imjR4j/kYjoK8XNshUL60LPCTzuqSkBLQZhbZvsigXAdUcY9xbakSVuPrEH0XT2wpNTwsMIcmARv7Rznk5rqdJhzM6Ozsxa9Ysf4R2xJRZFT0yaeuDPQbhBtY/iQyEiRrQH4n8PqjdITL1ynv27JHWtcPDxVUULIpEwPVPtSKrw4WSGwHae017sMvLy+VOmtOTEQEmsoxgqjUp6pVpnOyLZTC1Yip3vZjIciOqwvRo9pqEyMyiTASYyMrUi6JKRevYdJiCD1IoSi2DCsNE9oFu6NZEH+zxcKumtK7d2tqK5uZmt9Lhlz2DABPZM7jaTFVslsLD1+gQHWEziiIDIiMjQX886aVI9YCJ7GW9hAgX1Ol+6seZJr3Y06aXG4yD2TGRHQTKMtqYFA2uP1eL316kw6oztYi0WF5dNF2D3OzB26hWzNcia7RG7NwCLvuBCfJLF2oxbowL261cKK9cr5g9bbKDPrkQlS8dJrKTWE7K1OCRy3UIFz3rl0cNmJqqwdrVAYiJNCU0Z6wGE8QzS1k0UYPR8aZtpEUnTZtWimuMaG7zrw0stAecyMyTXk42Gi9EZyI7CfIt52jxSb4B6zYZsPOAEfe9qkdLpxGrRA9rT+g04jdHTOSlf2v80FklTXqxp017mvZ+uP3W5/0yKTZHmqgaFa1BXtHgnvTrY0ZMSPYvM9lVkNnTpqvIefY9JrIT+NJEFUlD6+CXGoWJrLNAciilA71/nNiJWjkflT1tOo+Zp99gIjuBcLMgcI8wj6eLcbKlnJapRWHf2JfCQyyOENMx3sTIgfj+fNzSXGf2tOlEo/FSVCayE0ATCTftNWDxFA0mZmikTR3zxP9PSdPgy76xb3kjMD9Lg5goIEj04Jcs0kJnwfvOPnfRGcIUp3B/FPa0qTytqeYYo7eg3fiVAcGBWty7Uge9OHHY2G7EP7fpsfeoady85TsDctJ0+NeNAegSFxtuOWDA7uKBo4nk933XcQPuWK7DG7sNeGuH/McWvYEFmdelpaXSujL10Cy+RUA1jgX+8r7eq+eRqTcOCwFa2qwrMCwU6O4RF5HbuKWUPPhQmDdM7ddu88z3ev/+/ZJ7otzcXOsg8FOvIcCmtYtQ01KSLRJTku3C+aQtElN4jyC5N0jsYvUceo1ORTU0NEgeRFh8iwAT2bf4+3XuCQkJkqdN3n/tezUykX2vA78uAfXKdMmc2R+3X1fGjwvPRPZj5Smh6DTpRZ5D6AJ2Ft8hwET2HfaqyJn8bpMze95/7Vt1MpF9i78qcqf9101NTZKnTRbfIMBE9g3uqsqVPW36Xp1MZN/rQBUloLEyjZPNt0mqolJ+VAnP7BTwAQA/mq7FrLH+db7XBzB5LEu6UoYuaacZbCI1i3cRUMXOLtpYIdcdSe7AX1xchNCQUCQr7J4kOrjhyt1PzmJRUFAgOeibPXu2s69yfDcRUEWPTA3V8mCCm5i4/HpdbY10MbnlkUaXE/PDF2nS67vvvpM8bUZFiVMjLF5DgMfIMkJNWxVDQ8Um6xEq7GnTd4pnIsuEfVdXlzTRM5KJTFCyp02ZGpSTyTCRnQTMVnTyY0Uy0onMnjZttRDPPmciy4QvEZmuVqGdTiNZ2NOmb7TPRJYJdyLySO+NzVCyp02ZGpUTyahi1tqJ+soetaysTOqJW1pahOseP/XdIzMq5GkzOjoa5Mg+Li5O5tQ5OWsIMJGtoeLgM5rcKiwsHBR7+/btoHO6OTk5Dqaizmg06UXryt3CtxF/4DyvYzat3cCYxoNDzWk6l8sNF9J6Os0X8KkoNxqYE68ykZ0Ay1pUMiHJq6RZ6P8zMjKsRR1Rz9jTpnfVzUR2E2/aBGEW6qFpood7ZBMiZF6TaV1bW+smyvy6PQSYyPYQshNOWxEt3dxwbzwAWEhICGJjY9m8ttOG5AhmIruJYkRERL9pTb3xSF9HHgon9crsaXMoKvL/ZiK7iSmNBWm5hcxq7o1PBZNm8GmowZ42T8VGzid+ufzUZmiSEwO300pMM62Vdmnb0OXDiyPEvjKEaMPcro/cCVCvTOvtWVlZgyYG5c5nJKfnd0Q2GA34qvsNZemsb8/D0b57nXxVuHhtOmYFneur7G3mSy5zi4uLJQ8itBebRX4E2LSWH1NOcQgCZFqTic1ryp5rGkxkz2HLKVsgwJ42PdscmMiexZdT70PA7GmTe2XPNAkmsmdw5VStIEBj5erqava0aQUbdx8xkd1FkN93GAEiMh00IU+bLPIiwEQeBs/uzh68vuYjPHrDenz13h4pZluzyRPIMK9xkA0EAgICpMMUbF7bAMiNx0zkYcB7+c+bsXHdVkTEhIm/cPzz16/h3XWfDfMGB9lDgCa9yGUund9mkQ8BJvIwWBYfLMe8pbm49fHLkLtoPI7mlQwTm4McQYAOmdC2Vt7p5Qhajsfxuw0hjlcNaG1sxxuPb0Xh9ycQER2GGWdPxNIbFvbvLmqobsZbf/8ERQfKEZ0YgbMvn4s555ocAqy/912U5FcgXLz391v/g9SsRNSU1eObLfuhEU60V91+Ltb96lVc8usfYsvzX+JEfiUmzR2Ly+9Yim8/Oohtr+xCbHIUzr12AcZNH91f7J2b9mHn+3tQU9qAuFHROHPVbMxdOlUKf+Uvm6ERnuSvuHOZ9JvM+PX3vIN5y3Mx5zz1OCqgnV7kkCE7OxtkbrO4j4Cqe+Q1NzyPA18exaJLTkP2rDF4/k/v4LVHt0iotTS04deLHkXeJ4ckIhnFVRX3rXoS7/9ruxQ+dmoawiJDJYJPmJWBMZNSEBwWjLiUGGRMFpM2egM2r9+O+y95StpnPf60DLz11Fbcc+E6vPLXDyRSVx2vxV+v+Xe/lt576nM8dvN6pGQk4Jwr5qK7owf3XPQECr4pluLkLMzGCw++gy/e+V76/dRtr+PgzmOYdsb4/jTU8D90vQxhRq6AWORBQNWfwyN5RbjqD+fjvNULJLTGTEyRCEhCk1it4hrQZ/bfj8CgAFyIsxGfGoMX//Iuzl19Os66dDY++c9OQeBR+NFPzjC9Iz4C2TPGYMEFM0ATYSQLLpiJGx5aKf1/ReFJbNuwEy8feRSJY2Jx9mVzcFnmb3B8XzmycsXVo7WtuOGBH2P5Tab0iMz7xh0WRC4SxM/E9DMnYNWvl+LpO95EU00rdrz7LdZuuwshYeryBWb2tElEHjNmjIQdi3sIqJrIZ66ai3W3vYztb+zGrMWTcfqK6cicarpg7NjeUsz4wWSJxGaZu2waNqz9EKUF1cie6VgDGz8rvf/9lLEJGJ87ViIxSXRChPRvw0k65JGGa+5dgbrKJnzx9vcoPVyF4gMVaG/tQE+X6aNAca+973zs3X4YT/zPi/jl2qsHmeVSYioRMq9pnNzY2AjaLMLiHgKqNq1/umYV7t/wc6SOS8TmZ3fg5jn34dm735YQ62jpRLwYo1pKbJLpviJzr+0ItJFx4YOihURY9J4DHoCkOBv/sQ3XTf0D3lz7sdQ7L1w5AwnJg71M6gK0ogcOluL39uodKYJfxgkPD5c8bfKklzzqU22P3Nneje0bdouJommYLyaLaCMCLSe9+tgmXPPHFUjJTMSezwoGobh760Ex+aJD5jT5rwXt6ujGc/e9hZ88uAorf3G2lC99MNbc8pwo28B1sBse+xgVx07i549diWfvexMzz5rUb0XIo3LlpMKeNuXThWp75ODQQHz43A6s/+M70ux1l5hYaq5rxaj0ZASFBGLZjT9A8eEyvPG3j9Eueud9/z2KrS/sxIIVsxAUbP22iIjYcJQeqZLMY2dFJz4QcUmxwsxulj4q9KH539s3oEv8ax5vH807gRf//A5ufuQSXPjzszFnyXT87ZYX0NPd62x2fhGfNofQrDVPermvLtUSmTx33LLmUlQV1+HqiXdg1ejbsH/HUdz5/I0SajSxdPtT12Hjk1ulCan7L12HjJxR+P36622iOv9HuWICajd+c84am3FsBQQE6rD63gvwpZiRvmbcXbhqwh0IiQjGOatOR9H+cvGh6cbjt7yIhStmS7PsJL944nLUVTTghfvfs5WsXz9nT5vyqc/vLjonxwLbup5zCoH21k5pqScmccDjpTkBcpxnXtMlstkT6h31vQa3ZpJN+UWBemk5RamOBYarI11Fu2vXLsmhP51ZZnENAdX2yJZwhEWEWCUxxaFeISk9Do6QmOLTLLe7y0E0qy03iV1Tv+/fYk+b8uhgRBBZHqg4FU8hwJ423UeWiew+hpyCmwiYPW3yqSjXgWQiu44dvykjAnRWmc4pWzr7lzF51SfFRFa9iv2jgmRe9/T0SJ42WZxHgInsPGb8hgcQMHva5DVl18BlIruGG7/lAQTIvKa91+3t7R5IXd1J+t0WTQ00SNNOUbdWXKxdpHbwvm0Xk/HZa3FxcdJ907T/evx4dR3d9DSofrchxAgDjOI/XwpNyJSVliE5RWz3FM7XlST0odPAfw2t0tJSlJSUYMGCBdKZZRbHEPDDHlkrGqpvpaOzA0XHi5EQnwhtkLy7s3xbM9/nTuZ1UVGR5DaX/p/FMQT4k+cYToNimcdwtCuJRV4E6BBFYmIie9p0ElYmspOAUXTaH0z3IOt03Bu7AJ/dV8jTJnnZZE+bdqHqj8BEdhyr/pgdHR3SpAyLZxCIiopiT5tOQstEdhIwik49MpvVLgDnxCu0QaSmpkZ4SVHnWWwnoHAoKhPZIZgGR+Ie2QXQnHyF7lGmk2l8vYxjwDGRHcNJ8upBmxWIxNQjs2ntIHAuRqP5B8vrZerq6nijyDBY+t068jB18WgQ9QwFBQM+vmiyixzIZWZmshdIDyFPH85jx45JH07ah03+sCdNmuSh3Pw7Wb9bR/YV3ERaS6GGRQ2tu7vbV0VSdb75+fnSAQoyr80novR69XoVdVeZbFo7iCDdV0SNyiz0/2Rek/nHIj8C1AuTWB5rpI8ni3UEmMjWcTnlKRE3LCys/zk1sKysrFPi8QN5EMjNzZVWBiw/njyDbRtbJrJtbE4JIYfq1LDMpKYdSCyeQYB2eM2YMUPadGMmM5vWtrFmItvG5pQQuhKUhHvjU6DxyAPqkYnMTGT78DKR7WPUH4N2HBGJabzMrludAM6NqIQ1ucol4R7ZNpBMZNvYnBJCM9f0R/f6sngPgfj4eGnZyS/W7sWH3hei6HXk9qNvo/Hje32Bi+LzjDn3Twgbf5FPylnxz2k+yVfpmQZnzUX8smd9UkxFryMbDXpxATmvHVprGb7ExZd5W8NCKc+MBt/tC2fTWimtgMvBCLiBABPZDfD4VUZAKQgwkZWiCS4HI+AGAkxkN8DjVxkBpSDARLajiZ4eI7q65V1SaOkw2MlVfcF03uHxj2pRWmd7v/Q7ec3YerDVZuW/ONKG13Y1uhxu80UVBDCRh1FiU5sBy9YeRXmj7cY3zOtWg+55qwLP7ai3Gqbmh716Ix7/oAYn6m1juXlfHT471GQThq8K2/Hm7lqXw22+qIIARS8/+Rrfpg49CsrkXf7aV9aGxZOV5Qvb1zib83/6urFKKYrflUP1RP62qAOv7KzFyZZuZCeF4ZazEpEaa6r2rmPt+CS/BXefn9yvuC37W3DsZDeuXxiLRz6skJ6v2VKJK+YlYMG4cPzhrTJcf0YiXt5Zh4rGLpyeHY0r58UgPESLTmGC3/t2OW49JxmZiYHSu5UNvVj7cRXuOT8Vr+5qQEW9HtsONQjn6xr8ckm83zUYdwvc0qnHn9+vRkFlK7KTw/GzsxKQFG3Sx/NfNCBS4Hjx7Ggpm5LaHmFKN+CQiDs3Kxp6w+Ahjr1wSuONb5vw6SFxbrzXgHkijRvPiBMHMSB8gUHS5c8XJ+Plr0UeFS3IiA8VOklCcl953K2rN99XtWn98YFWXPJEMVq6enHe1DjknWjF8scKpQZCUigI+8HehkF47yvtxKf59QjQaTBpVIQUNjElHImRAVJDeuXLFlz3bBE6e/RYPCVWELoGt79+QuzBhmgspvCa1oGNAfXteumd9m4DxiUFIzRYg6SoAIxPHpm98p2vlqNHmNlnTIjFfwuacMP6on78dxxpxO4i0xi5UQxrrv33cXx9vAlnT44VY+d6vPjfgSGJvXBK9L63K/HIpkpkCoLOzIgSQ5qTuOVFU35mXd74XBHqWrqELuPw9bFWrH7m+KD24C8/VN0jP/R+OVbOCccTV6VL+rhW9LKL/noYj22pwJNXZwyro6BADS6cEYVH3juJC8S/WUlB/ZNeC7PD8djlY6T3c0eHYNmaIuxc0I6pacM7rF+SE4F/fKLFtLRILJ1mOkk1bCFUGHjZgjjctcLkjCE1JhA/fa4MNPkXGTq4T/m3IG1okAYbfzFenH4CVgvdrfzH0X5E7IUfFx/p57c34olr07ByVpT03vLcSJzx4DHsPKMds9JN7oyXTovDb5clSOFZiUG48p8nUN3U63e9smqJTBNVxysNuP28mEF0OHNiJL482jLombM/zpxkMv3ovamCyKPiNThQ3mmXyM7mo8b4MzMG/IHTR5CkurlXEHmwhUKm7tyx5JVlAAXqxXceM81a2wvfKywr4S8Re0vbkV9h8jZCKcWGabCvtKOfyNPTBz6+o2NNwyGynvxN1EtkMVFFkiLMWEtJiAiCsOz6ZejCUo/evhLNCqdEqKFFhmjQ1jXwnuUBGJqtZRlAIDJk4HYOM0mtHRhqFmPpodAFiuGOWeyF00RloMgqSCfuCrP4GFwlxsgTUgbIGxY0YAkMVx6l61C1RCayhYgP7OeHWzE/e8BFz46jjWLsGyzpJShAg44hV/GWNQx8vW0plpZBTss09SzlYjnlSLkBU1eESOmRWH7RS4dZblF64/Bl+XJSw/Hfw82DirCzcGAN2V742IQgdItv+ZKcSMwZa9IVnb/ZsLtRMqHVJqqd7NKKr/EVC6OxaU89tuW3SjPKL+9sxHeFPVgmxkUkpNDaViM2fNMkzWJ+JCbHPtvX0a/jmDBT77GvrBPN7QM97rt5dfi+pBM1zXox3q7C+FQt5meFIUSM6TKSNXj9m1q0inEfTao99WnloDYTI8aChSfbpXEYi20ELpgZg9IaA54RY2XS3XvfN+PbwgGPpfbCaR5j0mgd1n5UgcOVXdL8xt8+rsVjm6ukmXG1iWp7ZFLUnT9KQYf4LN/4dKlkZiXFafDAJSn9kx/Uq95wVjR+/0qF9Dc1MwC3/DABXxwxzWTTBMw504LxyxfKcfPiWNyxzLRMlSMmta54sliYfkZMSg/AszeM7Z+suX/laNz5Whmm3nUYcZEa3H3hKPyq2LSMRWVakhOHP22sQl5JIb68m3002yIU6WbNlWnSxOTD71YjRejux3MjcbzWZDHZCxcuv/B/qzPxuw0lWPLX44gSY+OJaTqsEZOUcRE62Xfr2aqHt54r2rFA2+E3ZXEs0C22Wda16jGqb/14KLgdXUa0ijFuYpT12xWpd6WxFC2bjPttAV7/ZQbmiobW3GlAfOSp79AkS5XocVPEeqS1u7pp26dY1pSWolwVciwQPvESV193673yJ6e49b6zL1c1mmaRLce6lmnYCydripabYgWBPSnBWXOQsPwFT2ZhM21V98jmWtNSki0SUxwiVGiwbSVHmJdGLDZ5BYo046mbtyJEXvOmEyvB4kpWDUzzo9ZC+dlQBFJihm+m9sKjwtRnSg/FSP01HFpjN35Tj0BLTZazp24kx68yArIhMPynTrZs1JEQ9ezf3sfjWnVoU1214B5ZXfrk2oxQBJjII1TxXG11IcBEVpc+uTYjFAEm8ghVPFdbXQgoerJLG5qAwORMdSEuU20IG18J68Q68gExWdYDvPBU0RtCvFB/zoIRkBcBo9hsoLG+v0DejAanxkT2JLqcNiPgJQR4jOwloDkbRsCTCDCRPYkup80IeAkBJrKXgOZsGAFPIsBE9iS6nDYj4CUE/h/wx8Ld+u7RaAAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        # decoder이기 때문에 input_size 대신 hidden_size\n",
    "        # hidden_size 대신에 output_size\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size) \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size) # input_size, hidden_size\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden) \n",
    "        output = self.softmax(self.out(output[0])) # output으로 나가는 layer가 따로 있음\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델의 결과를 학습하고 관찰하는 것을 권장하지만, 공간을 절약하기 위해 최종 목적지로 바로 이동해서 Attention 메카니즘을 소개 할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention 디코더\n",
    "\n",
    "문맥 벡터만 인코더와 디코더 사이로 전달 된다면, 단일 벡터가 전체 문장을\n",
    "인코딩 해야하는 부담을 가지게 됩니다.\n",
    "\n",
    "Attention은 디코더 네트워크가 자기 출력의 모든 단계에서 인코더 출력의\n",
    "다른 부분에 \"집중\" 할 수 있게 합니다. 첫째 *Attention 가중치* 의 세트를\n",
    "계산합니다. 이것은 가중치 조합을 만들기 위해서 인코더 출력 벡터와\n",
    "곱해집니다. 그 결과(코드에서 ``attn_applied``)는 입력 시퀀스의\n",
    "특정 부분에 관한 정보를 포함해야하고 따라서 디코더가 알맞은 출력\n",
    "단어를 선택하는 것을 도와줍니다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFKCAYAAADmJB+NAAAABHNCSVQICAgIfAhkiAAAIABJREFUeF7tnQmQFdXZ/l9mhhl2GPZhHZZBQNnXII5REEQ0oqLRSkw0JmpKKY0mlXzqZ6jExJgySVlaxmxASjFiiRIMRgTEBdmRZQBR9nXY920Ghvvv5/Xr+79zl5nby723u+/zVt2a293nvOc9v9Pz9Lmnu8+pEzJMaCRAAiRAAoEikBOo2rAyJEACJEACSoDizhOBBEiABAJIgOIewEZllUiABEiA4s5zgARIgAQCSIDiHsBGZZVIgARIgOLOc4AESIAEAkiA4h7ARmWVSIAESIDiznOABEiABAJIgOIewEZllUiABEiA4s5zgARIgAQCSIDiHsBGZZVIgARIgOLOc4AESIAEAkiA4h7ARmWVSIAESIDiznOABEiABAJIgOIewEZllUiABEiA4s5zgARIgAQCSIDiHsBGZZVIgARIgOLOc4AESIAEAkiA4h7ARmWVSIAESIDiznOABEiABAJIgOIewEZllUiABEiA4s5zgARIgAQCSCAvgHVilbKIwI033ihz5szJohqzql4kMH78ePnPf/7jqdDqhAzzVEQMhgQsEKhTp47wFLYAjElTQsCL5yGHZVLS1HRKAiRAApklQHHPLH+WTgIkQAIpIUBxTwlWOiUBEiCBzBKguGeWP0snARIggZQQoLinBCudkgAJkEBmCVDcM8ufpZMACZBASghQ3FOClU5JgARIILME+BJTZvmzdBKIS6CqqkouXboUPla3bt246TKx04wtLy9P8Hw3zZsE2HP3ZrswqiwncPfdd0t+fn74U79+fSkpKZFf/OIXcuLEiYzSefjhhzWut956K6NxsPCaCbDnXjMfHiWBjBL4wQ9+IMOGDZOKigpZsmSJPPfcc/L+++/Lp59+Ko0bN85obCzc2wTYc/d2+zC6LCdQWloq999/v0yaNElef/11ufnmm2Xt2rXyyiuvKBlMvfDMM89or759+/Zy5513ysGDB6tRmzp1qvTv31/atGkjt956a8xcPLhgjBgxQo9fc801snTp0mr5cTFB/rZt28p9990n586dq3b8wIEDcvvtt+vx3r17y29/+9vwlBDHjx+XAQMGyEMPPaT1QIxTpkzJ8lZNU/UxtwyNBPxK4Gt982v0ieO+6667MOdTaNq0adUSPfvss7r/xz/+se7/9a9/rdsdOnQIGcKs3wcNGhTO8+qrr+o+Y3w8NGrUqFDDhg1DTZo0Ce3atUvTPPHEE+Hjl19+uX7Pzc0NLVu2TI9v3rxZt7F/5MiRIUOc9Ts+b775Zsi4L6DlYXv48OEh4yKj340LjuY/dOiQbqNc/G3QoEFo3rx5eixIhrp5zbwXkdcIMR5PE/DiP5UbwBKJu9ELV5E0ZiEMXbx4MdSqVatQTk5OyOg9a7Fmvg8++EC3+/btq+nnzp2r20avOTR69OjQrFmzQvv379djxvBOaPv27Xr8N7/5je7DhQD205/+VLeNHrtunzp1KtSsWTPdB3E3ZkLU79ddd50eN3r1erxdu3YanynuSIOYTp48qfuDZqif14xj7kar0EjALwQwzAEzBFR27twphnjqcMrvfvc73Y9t2Pr163WIZcOGDVKvXj3B8A7s3nvv1Q/s7bff1r84VlxcrN/vueceefLJJ2XVqlU6tLJ161bdP27cOP3bqFEjGTJkiBi9b91GObAzZ87IY489pt8LCwvFuFhIeXm5lg1r3bq1GBcA/U5LDwGKe3o4sxQScIXAjh071E+XLl3C/vDI5MaNG3XbGEKRsWPHStOmTeXChQuCxxZbtGgRFtlwJuNLZWWlbkKMTcNNWvg4e/asPooJHzA8HWOaMawT/o4LAOzYsWPhGHr06CH4nD9/Plwu4qGllwDFPb28WRoJ2CaA3vAbb7yh+W+55Rbp2rWrdOvWTXvr77zzjuBxSTxFgydrhg4dqtvokeOCsGXLFunevbv8+9//lqeeekoefPBBuf7669XXwoUL9SIAUUePHN9xAxXbZo9+9erVctNNN2lvHk/tmHbttdfqV2P4JxwbYkRciO/o0aN63EvP6YeDD/oXr40TMR4SsELA+P+0ktw3ac2xc+Ppk5AxbBIynjgJGUMcOr79/e9/P1yPH/7wh7rvhhtuCL300ks61m0MgYSMIRtN88tf/lKP44brI488EjJEV7fXrFmjxw1x1m3cTH3ggQd0/B3bM2bM0OPLly/Xbex/+umnQ1dddZVu44Mxd+NCEDKektHYfvazn4XH6BEPzBxzh/8gG3h4zbwXkdcIMR5PE/DiP5UbwExxN4UU4nrFFVeE8LSMMdwRLsIYgw9NmDAh/ERLnz59QjNnzgwfxw1Oo5cePg4fzz//fPj46dOnQ8ZjjPoEDcqCUL/88svVqvDCCy/oUy44jidmHn/88bC4I6Hx6GSoV69eus8YvtEbtnv27FEfFPdqKNO6wWX2jDOS5l8CXlzeLBM0MRSDm624uRrPML5+5MgRKSoqindYjCdYxHh6Rp9DjzelAPJjiAXPsieyw4cP61CQ8dhjoiSB3e/F85DiHtjTLTsq5sV/quwgz1pGEvDiecg3VHmOkgAJkEAACVDcA9iorBIJkAAJUNx5DpAACZBAAAlQ3APYqKwSCZAACVDceQ6QAAmQQAAJUNwD2KisEgmQAAlQ3HkOkAAJkEAACVDcA9iorBIJkAAJUNx5DpAACZBAAAlQ3APYqKwSCZAACVDceQ6QAAmQQAAJUNwD2KhmlYwp6HT+bRoJkED2EaC4B7jNjTUr5e9//7su1pBOw+yCZWVl6SySZZEACUQRoLjzlHCVwMGDB+Xdd9/V9TNpJEACmSPAZfYyxz7tJRuLOOh6mh07dhQsm2Ys5KBLoX3jG9+QnJwc7eFjYWQsmbZv3z7ZtWuXLoh85ZVX6gLHsMWLF6twY/Hl5s2b67APFlrGQshYcg1LtsGQBuXddtttaa8nCyQBEhBhzz2LzgIstmAsv6YC3axZM10rEwsrb968WSlgwQekwXEIOxZewAIM7733ni52DDt16pSmweIOpmEbC0VA6LGoMizyezghv5AACaSNAMU9bai9URBW1Bk7dqwYS6HJwIEDNSisXB9peXl5cuedd8rEiROlc+fOcuHCBdm0aVOtFTCWYtMePcxYy1OM5dtqzcMEJEACqSHAYZnUcPWsV6xCbw6xGOtyapwQ70iDMJur1WMIB739EydOpKVOK1eutFTOTTfdJFbzWCogTYm99lQThtlwnrRq1UqH7Gj+I0Bx91+bOYoYvXLTkvmnNUXeHG4x85rbGNqhOScQb91S517te8CvuS+//FKH6nABNRbQtu+MOTNCgOKeEezeLjTySZcDBw5osGYv3xR7DO/Aonv0TkVq8ODBluDgyZzZs2dbysPEyRPYsmWLTJ8+XSZMmJBwce3kvTFlOglQ3NNJ2ydlnTlzRgUTT9ag94YefklJiUbftGlT/fv555/rzVWMxUcKuin+hw4dkiVLlsjw4cOrHfcJAob5fwS6d+8uubm58uGHH8q3v/1tifzlR0jeJsDBNG+3T0ai69Kliz4NgydpIOwjR44Mi/oVV1whLVu2FIj3ihUrpEePHtKwYcNwnIWFhXr87Nmzmt98yiYjFWGhrhDA+YBfbng8luYfAnWMGzl8P90/7ZXSSNFL/+STT6Rfv34ydOhQFWg8DhlvqAXPyOOmW7xjCBK9f+RNZlzfSaVQPk9hJwSTy4tfYWjvAQMGJJchy1J58TzksEyWnYRWqotHGxMZhLsmi+zN15SOx/xBAO2JYTiafwhwWMY/bZXySCHYbdu2Dd88TXmBLIAESCBlBNhzTxla/znu1KmT4EMjARLwPwH23P3fhqwBCZAACcQQoLjHIOEOEiABEvA/AYq7/9uQNSABEiCBGAIU9xgk3EECJEAC/idAcfd/G7IGJEACJBBDgOIeg8SbO/CiTryXdaL3R2/Hq01taWo7Hs8n95EACXiLAMXdW+2RMJqpU6fqeqiRi2Qg8ZQpU3S/OTsj5gDBdqJXxbEfx5EukX322WeaZvv27YmScD8JkIDHCfA5d483kNXwMMEX5uE2J/iymp/pSYAEgkGA4h6MdgzXAtP17tmzR9q0aaMTemEOGMwXs3//fsGkXt26dYupMdIvW7ZM54MpLi6OO/yDNVcx9wwW9sBiHlhXFXONwGpbmzWmQO4gARJIOQGKe8oRu1sAVh2KnIwrehz+9OnT1dY4/eCDD+TgwYMq9FhgAxNARRrmC5k7d64ewwUBa6dGz+QIYUe5mGsGF4ht27bJyZMn5ZZbblFXWEMV5e7evVvn/MZ3zAiJ2SEvu+wydwHQGwmQQFIEKO5JYfJOorKysqSDwbS8EHbMGYO5uDEv94IFC1ScTYMIQ9ghwqWlpTqm/9prr4WX3sPFY926dXpBue2227S3jvH6rVu3yt69e6V9+/bqCot33HzzzTokhPT4JRC9NmvSgTMhCZCAYwIUd8cI0+vg2muvrbZgwrx58+IOoyAqc5UkDKNA2GH4Hinu6IHDsFYqDIsxQKAh3DAM1UC4CwoKZM2aNboPQz0wiLcp7smszaqZajGr66FyDdXqQHHxxeRvWPuUlt0EKO4+a//OnTtXE/ea5pE21zmNHMbJz8+vVmMzjSn+OBidBvvQgzd74vDXoUOH8CLaOG51bVafYU95uInmxbdaMNpo0aJFctVVVwkWVqFlLwGKe4Db3lzU+MiRI+FaRq6Pip3m2qiHDx8OzwgZmaZRo0aaBuPwY8aM0V8AuDmLRy/Rw3fbuIaqc6L9+/fXdU/Re8d9FFp2EqC4B7jd8Y+NRyJxwxPj5OiR44mXSMOjkxs2bJC1a9dq7xzPwWPF+0jD0AvWSsUQEKYEXrVqlY7TT5w4sVrvPcAofVU1XNQh8Bhao7j7qulcDZYvMbmK01vO8FMfY/T4Z8cNULyUhEcYIw29uxEjRuguLHoNge/Tp0+1NFjkGsNBEAu84IQbtFdffXW1tVO9VXNGYz4GSxLZS4BrqGZJ22M91JqWzUNPHD32mpbPQxrcXDWfb/cCupruOXghvkzFgCeW8Jhr9MXcbjxu+7Mbh1fzefE8ZM/dq2eLy3HVJOwoCjdJaxJ2M42XhN1lRHRHAoEiQHEPVHOyMiRAAiTwNQGKO88EEiABEgggAYp7ABuVVSIBEiABijvPARIgARIIIAGKewAblVUiARIgAYo7zwESIAESCCABinsAG5VVIgESIAGKO88BEiABEgggAYp7ABuVVSIBEiABijvPARIgARIIIAGKewAblVUiARIgAYo7zwESIAESCCABinsAG5VVIgESIAGKO88BEiABEgggAYp7ABuVVSIBEiABijvPARIgARIIIAGKewAblVUiARIgAS6QzXOABAJGYOHChXLs2DG5cOGC7NixQ4qLix3V0G1/joJh5qQJcA3VpFExoRcJeHHtykxyKisrk5kzZ1YLYfLkybZDMv1hmcbc3Fxdl9WJP9uBeDyjF89D9tw9ftIwPBKwQqBnz56Sl5cnFy9e1L8jRoywkj0mrekPC6zDX2lpaUwa7vAmAY65e7NdGBUJ2CJQt25d6dq1q+ZFb7Jv3762/JiZ3PbnKBhmtkSA4m4JFxOTgPcJDBo0SPLz86Vx48bSsmVLxwG77c9xQHSQFAGKe1KYmIgE/EOgpKREKisrpXv37q4E7bY/V4Kik1oJ8IZqrYiYwMsEvHgjy8u8GFtqCHjxPGTPPTVtTa8kQAIkkFECFPeM4mfhJEACJJAaAhT31HClVxIgARLIKAGKe0bxs3ASIAESSA0BintquNIrCTgmgOkD8PGShUIhjamqqspLYTGWOAQo7nGgcBcJZJrAu+++q8+q44O5XaINAvvXv/5VFixYED60b98+efTRR/XtVLcs2udbb72lMT388MNuFUE/KSJAcU8RWLolAScEpkyZEs7+t7/9LcbVz3/+c3nggQdk//794WMjR46UF154QdC7dsuiffbr10+ef/55ue2229wqgn5SRIDiniKwdEsCdgmUl5cLeu433HCDDBw4UCcCO3ToUNjdtGnT5I033tDtp59+Wh5//HH5zne+I7t27dJ9Q4YMkblz5+p39PqHDRsmzZs3lyuvvFI+/vhj3Q/7yU9+IgMGDJAlS5bImDFjpHXr1nLttdfKli1b9Hg8n5hl8rXXXtM8ps2fP19uvvlmadu2rUD8//SnP4UvMLjQoIy7775bY8bxdu3ayUMPPaQvWtFSR4Dinjq29EwCtgj885//1DHt22+/Xe644w4VQewzDccuXbqkmxiCwTb+mj12DNng+IYNG+S6666TVatWyfDhw2Xt2rUyatQo2bhxo+bds2ePrFmzRm699VbBHDKYqgAXg0ceeSTsO9rniRMnNA+Ga2CLFy+WCRMmyOzZs/XisH79ennsscfkiSee0OPIj/Rz5szRixDedj137py8/PLLepGgpZCAAZ9GAr4l8LV++Db8uIH36tUrVK9evdDx48dDRk8ZYyyh3r17V0s7adIk3W8IZHh/x44ddZ9xMdB999xzj27/+c9/1u23335bt++//37dnjhxom4boqvb27Zt021j/nfdhkX7fPPNNzXNgw8+qMevueYa3X7xxRd127hwhHJyckLGDJKhvXv3howLjx7HZ+nSpZrmueee023j/oBuB8FQH68Ze+5Gq9BIwCsEPvroI/niiy+kf//+2tPeuXOnGMKuve14N1Zriht+YBhCQW963rx5um3uN/NiKAbWpUsX/YvpfZMx/EJYvny5zvOOYReYcWESjNPjlwR67KY1adJEh4dgZjmnT58OH+cX9wlwPnf3mdIjCdgm8I9//EPzGr1cufrqq6v5wY1Vo6ectG+jJ6lpcYE4cOCAfh87dqwUFRVV84GFOEzDnO1mvmqJ4mxg6KeiokJnn4z00bRpU019/vz5cK5GjRqFv2MIiJZ6AhT31DNmCSSQFAFjGEbeeecdadiwoXz3u98N54HY4ukZ88Zqq1atxBj60OPm2Du+R+/DwhroWePmJcbvjWES7cVjCt9Iw6RXiSzaZ2S6goIC/YWxcuVK+eSTT3Q8H2Jv3rS94oorwslrKiNR2dzvjACHZZzxY24ScI3A9OnT5cyZM3LjjTfKK6+8Ev785S9/kfHjx+uNVTwpAzN7wrjR+tJLL+k+XBRgeNZ90aJFMnr0aN1+8skn9RHJ733veyryH374oe5PxqJ9RucxxvV111133aUXETwNc/LkSb0R3KNHj+jk3E4jAYp7GmGzKBKoicDUqVP1MIQx2syePMQdPXk8oVJYWKgvMc2aNUuTQ2BhuDCsW7dOh2B+//vfC34RQPA3bdqkT8Lcd9990e4Tbkf7jE4IQf/DH/6gFxY8AbN161a9iOAFK1pmCXA+98zyZ+kOCXhxHm2HVUo6O4ZADh48KMYTLeE8hw8f1uEZPNduGi4GGJJp3769Lr1n1eL5jOcDZWDICG+wZpt58TykuGfbWRiw+nrxnypgiFmdJAh48TzksEwSDcckJEACJOA3AhR3v7UY4yUBEiCBJAhQ3JOAxCQkQAIk4DcCFHe/tRjjJQESIIEkCFDck4DEJCRAAiTgNwIUd7+1GOMNLIEZM2YIptS1Y5h2N3rOmGT94A3TFStWJJu8Wjo8O4+y7RimRUCdaakhQHFPDVd6JQFLBDZv3qzT7hozMlrKZybG9L2Rz7vbcmIjU4cOHXTqYDvWuXNnrTPqTnOfAMXdfab0SAKWCOAlI8wBY86aaCmzkfjo0aP64lDk5FxWfdhNjzJRNmKwY5hnHnVPdrIyO2Vkax6Ke7a2POvtGQIYTsGUuHiD1I6h52w3r53yovOgbLu9d6zKhFkkzQVEon1z2z4Birt9dsxJAo4JYBUljHnb7bUjAHNqAcfB2HQAcUcMdg11x2pRYEFzjwDF3T2W9EQClglgWTosT4ePHcNwBpa8w9h3pgxlIwa7QyuYj6ZNmzZSVlaWqSoEslyKeyCblZXyAwGsVrR69WoZOnSo7XAxcRiGdIxl+Wz7cJoRZSMGxGLX0HvHyk1Y3YnmDgGKuzsc6YUELBOAmOEJl8gZHK06yfR4uxmvk3F3+GjWrJl06tSp2tJ8VlkwfXUCFHeeESSQAQKYrhdzrjvptSPsTI+3m+icjrvDz5AhQ3RoBmxozglQ3J0zpAcSsEzg888/l+7du+v6o3YNNyAxFJLJJ2XM2BEDYnFyUxQsSkpK9OYqzTkBirtzhvRAApYInD17Vt8mHTx4sKV80YlxE7Nly5aCRa0zbYgBsSAmJwYmeOsVjGjOCFDcnfFjbhKwTACPPvbq1UsaNGhgOW9kBq8MyZgxuTE0U79+fendu7ft6RAcAQ1YZop7wBqU1fE2ASwejXVGBw4c6DhQiHsmH4GMrgBicfK8u+kPbLZt26YLbdPsE6C422fHnCRgmQAm6Orbt68UFBRYzhuZobKyUo4dO6bPh3vFEAtiQmxODNMZgBGmJaDZJ0Bxt8+OOUnAEgHMv7J7927p16+fpXzxEuMRyKKiIl0M2yuGWBCT3akIIusBRvBjd84arzDJZBzeOTMySYFlk0AaCKAnOmDAAFdugHptvN3E58a4O3zhBi2GZ5YtW5aGlglmERT3YLYra+UxAocPH5ZDhw7pcIMb5rXxdrNObo27w1+fPn0E3PChWSdAcbfOjDlIwDIBzCEDsapTp47lvNEZMKZ95swZffTQa4aYEJvTcXfUC6zADOxo1glQ3K0zYw4SsEwAKyx169bNcr54GTAOXVhYGO+Q7X1uXHTMwhHbkSNHbMcSmRHM7K5O5UoAPnZCcfdx4zF0fxCAGGNyLSdvo0bW9NSpUzoHulcNsSFGNwzMwI43Vq3TpLhbZ8YcJGCJAMaMMa2tW4a3N52+AOVWLPH8ILZz587FO2RrH9hx3N06Ooq7dWbMQQKWCECM8ealW4Zpcd2ecsDuXOzx6oR1Ud2cuhfsOB1BPNI176O418yHR0nAMQHM244Xc7LJ3LxY4IUvNy8W2dIOFPdsaWnWM6ME3BS7jFYkA4WTnT3oFHd73JiLBEiABDxNgOLu6eZhcCRAAiRgjwDF3R435iIBEiABTxOguHu6eRgcCZAACdgjQHG3x425SIAESMDTBCjunm4eBkcCJEAC9ghkfvFFe3EzFwn4gsDChQulvLxcY8WblsXFxY7ipj9n/BzB91nmOsYzpCGfxcxwSSBMABNeefUULisrk5kzZ1ZrrcmTJ9tuPfoTccLPNvgkMnrxPOSwTBINxyQkYIdAz549w9ME5ObmSmlpqR034Tz054yfI/g+zExx92GjMWR/EMAcK127dg0H63ShDvpzZ6ETf5w9zqOkuDtnSA8kkJDAoEGDBL12TFvrxuIa9JcQNQ9EEaC485QggRQSKCkpkaqqKtem/KW/FDZWwFzzhmrAGjTbquPFG1nRbYBZIXHTF8Mqbhj9uUHRXR9ePA8p7u62Mb2lmYAX/6nSjIDFeYCAF89DDst44MRgCCRAAiTgNgGKu9tE6Y8ESIAEPECA4u6BRmAIJEACJOA2AU4/4DZR+stKAufPn5djx47JpUuXkq5/Tk6OFBYW6mOS0bZ//35Zt26dwG+yBj94lr5t27YxWebMmSOTJk2S7du3xxxLtKNLly7y4osvyvjx42OSuB2f2/xiAs7CHbyhmoWNHqQqe+VGFuaPsSLsZhtA4IuKimKa5IMPPrAk7KYDCPyYMWNi/OFlKivCbjqAwG/bti3Gn9vxuc0vJuAU7/DKeRhZTQ7LpLjR6T47CNgRdpBJlM9Kjz2ScKJ8doQdfhPlS1ROba2dKF8iDrX5s5uvNr9BOE5xD0Irsg4kQAIkEEWA4s5TggRIgAQCSIDiHsBGZZVIgARIgOLOc4AESIAEAkiA4h7ARmWVSIAESIDiznOABEiABAJIgOIewEZllUiABEiA4s5zgARIgAQCSIDiHsBGZZVIgARIgOLOc4AESIAEAkiA4h7ARmWV0k8Ac8TYsUT54k0mloz/RPkwR4wdS5QvUTm1lZEoXyIOtfmzm682v0E4bu+MDELNWQcScJEAZne0KjTmrJDxwsDsjomEMF567DNnhYx3HLM7JhLqeOmxz5wVMt5xt+Nzm1+8mLNtH2eFzLYWD1h9vTgbX8AQszpJEPDiecieexINxyQkQAIk4DcCFHe/tRjjJQESIIEkCFDck4DEJCRAAiTgNwIUd7+1GOMlARIggSQIUNyTgMQkJEACJOA3AhR3v7UY4yUBEiCBJAhQ3JOAxCQkQAIk4DcCFHe/tRjjJQGXCJw9e1YeffRRef31113ySDdeIkBx91JrMBYSSAOBqqoqLaWgoEBeeOEFWb58eRpKZRHpJkBxTzdxlkcCGSbwxhtvyMiRI2XevHnSrl07adq0qfzxj3+UQYMGSUVFRYajY/FuEchzyxH9kAAJ+IPAvn37ZPPmzTJu3DgN+Fe/+pX+hdCvX79eRZ7mfwKcW8b/bZjVNfDinB5+aJBLly7J3XffrePtubm58t///leuu+46P4TuyRi9eB5yWMaTpwqDIoHUEnj22WdV2J944gnp0KGDPPTQQ7J///7UFkrvaSVAcU8rbhZGApknEAqF5MCBA9KnTx+ZPHmyQOixb9euXZkPjhG4RoDDMq6hpKNMEPDiz+FMcLBT5tGjR6V58+aaFY9FNmjQwI4b5jEIePE8pLjz1PQ1AS/+U/kaKIO3RcCL5yGHZWw1JTORAAmQgLcJUNy93T6MjgRIgARsEaC428LGTCRAAiTgbQIUd2+3D6MjARIgAVsEKO62sDETCZAACXibAMXd2+3D6EiABEjAFgGKuy1szEQCJEAC3iZAcfd2+zA6EiABErBFgLNC2sLGTCRQncCZ8oVyaMX/ysVz+5JGk1e/nbQa8mtpWHRNTJ6y7edlxoJjcuLUxZhjiXY0bZwn3x5VKH261ItJsnX+eVn67BE5b8FVNtXBAAAT7ElEQVRfPcPf8P9pId1Gx/o7XrFFdpz4r1RWnYwpK9GO/NwmUtx0nDQr6B6TZPv782Xtr56SyjPlMccS7chvWCT9nn5Gulw/OlGSrN7PnntWNz8r7xYBq8KOcnEhQL54ZlXY4QMXAuSLZ1aFHT5wIUC+eGZV2OEDFwLki2dWhV39GRcC5KPFJ5BycceERIk+8UNK314zrvSVyJJSTWDHjh06GdaHH34ohw8fTnVxYf9WeuyRQSXKZ6XHHukvUT4rPfZIf4nyWemxR/pLlM9Kj72aPws9/bSdDB4pKOXDMlOmTBHMHR3Phg8frjPTZcpee+01OX/+vPzoRz/KVAgpK/fcuXOyZs0aAWPMe+HUVqxY4dRFSvJ/61vfksjYsAgF7LPPPtMPVhnq3r273HDDDSkpn05JwKsEUi7uZsWvvPJKycmp/kOhdevWXuXi+7jeeecdOXPmjIq7G+bGBSIyjkh/+AVl15A30pf53Vwn9NSpU7pGKMXdLmHm8yuBtIn7ZZddpiu+xLOlS5fK3r175aqrrpKVK1fKoUOHpEWLFnL11VdL48aNNcvFixdl2bJlsnPnTv1n7tSpk/Tr108aNWqkx9FTRQ8OS4jhl0L79u1V2LAIsGnw/eWXX2ocAwYMCO83v6AXv2jRIvVRr1496dGjh/Tv318Pb9u2TVavXi29e/eWjRs3CsQDgmGWH+ls7dq1guGB48ePaz2GDh0q5oUM8SOOkpIS6du3r2ZbsmSJlon6FhYWyqxZszR9y5YtpaysTMu6/PLLw+lr84E84AF7++23ZdiwYcoD5SCuCxcuSJs2bbRHi08yNnjw4GSSpT3Nu+++K7Nnzw6Xe/r0aW3jvLw86dq1qy4ZB9Y0Esg2AmkTdwh4dM8dogehxT8k5paeO3eutGrVSurXry/l5eX6s/r666/XNsEYKkQNc043bNhQBfbEiRMqsBD+999/X8dYcRzi/tVXX+lF4tZbb9Vy161bp+KM8oqKilTEo3uMWGoMPhADhN78uQ+BxzZiRD1gdevW1TiiDcKNclBmkyZNtB4QIAwfwG9lZaX6wfzZppn1Rz0QE45jH+oAgUc9cGEDFwhVbT4ih8HwHT63b98uGzZs0FV3MFSBbVxQMZ+3Oad3dF38uP3Nb35TL6g9e/bUNqKRQLYSSJu4Q4yjbeDAgdV68+gpo5cJYfvXv/6lIgdDD9gU9jvvvFPzLFy4UHu0EEn0RiHKHTt21HUgIWYQaiwbhl5cr1699GIAGzNmjAocxG3+/PnhkLAKDXygh4sLBny/+uqr2nPGLwTT8Evgjjvu0AtI9FAFLgAQdvQab7/9du3VY9wbFwkMDYwfPz7sp7YvEPCxY8fqLxSI/Mcff6yLFyfTCx01apRMnz5d2UycOFHjXLBggRZZXFysPvBLCsM28S5QtcXm9ePR93FwfkybNk1KS0v11w8umDQSCDqBtIk7RDV6WCY/P78aX6y+DoMoQpAwfAAzRR5DCaaPa675/88Gm2s/4me4ebxLly4q7gcPHlQhwwUDomuWgb8ow+y9Hzv29SNkKNPsnSM+CKA5xIFYcAGBn3hmxgHf5nANyoa4o/edyKJ/QSAdep24CME6d+6sseKXSiKL5yMyLWLC0BJ+sSxevFg54GIaOWyVyHei/V64yRp9QzVerLzJGo8K9wWdQHyVSkGtIVTR4h5dTKRoRvaKzZtjiYTIHIaIPG5+R14Inyl+5tAQyooUdzOWiooKMYUe49/4mOUjTaIYcCxenCgHZZrDI2Y5kWKc6Gkik4EZa3S6ZHyY5eHXC/x88cUXeqHZs2ePfmDdunUzk1n6G/3LxVLmOIkj/dV2sTKzI11tcZjHzfbhTdY48LkrcATSJu5OyGHsGhb53PKnn36qIjxy5Ej9mY1hlt27d2svF4bvMIwn46KCsXgMU6D3izFnLBAcKZZmjx7jtRjWgG3dulXHzc2butgXfd9AE/6fmTdNIZqm6GBcG+XAL0TGHAfGsItpEJtowy8I/OrArxX8hY9mzZppsmR8mIJmxoEbtigTQ0MQOQzxrFq1SutoV9y9cJM1+oZqNEds8yZrPCrcF3QCaRP3OXPmxPSwML6NcffaDAIHkYa448kIfMc4NETaFG/cMN20aZMOoUC8IO544gU9VhjGmfEUC8aecQFA2sieO252Ij3G9jE+DlGETwzDmDd14aemXiIuArhIQEjfeustvXFrDgmYT92YAo2LEQQfwp1ouAX3BPA0CwTYrAP+JuPDvABgCAY+UC8IOi5qGLIyywTDoBtvsga9hVm/eARS/oaqWShEBWPSkZ+TJ5Ofl2L06NH6eCD84CZp27ZttdcOg0CNGzdOhR4iBmGHcGKfOYyCRx9xM/HIkSN6kxOCF31jDTcwMVaOiwCeLIFQ4yacFYMPiCfG6jEEgqEQxIn7ATAIM2744QKEsX08IYNx+WjDjU7cTMUNXfziQLzmjcJkfJiPOCIG3LMYMmSI+sCFBxcNXFTweGUyF9fo2Py4DXaRT8/gJuvkyel/k9WP7BizPwnUMXqo9t8gyUCdMbQQObwRHQKGM1Cl6Ju1ZjqMqWOYJtFNUaRLJk10udHbiAG/IjAcFM/Mxx6jH9fD/qlTp+pQEJ4Mqqm+iXxE1hWsolkgLjxWmQpL903WZ555Rp56yvr8IvhFhV9/5n0gp2+y7pg90tKkYSZ7TB5W/K1FMU3x1N/LLU0aZjrA5GHP/LAoxt/0UXstTRpmOsDkYd9Z0D7G35qDL1qaNMx0gMnD+reeFONv1ojhliYNC/szJg+bsPjrx5NjnKZxR+QoQBqLrbGotPXca4zCwkEIVbQgRmbHsWgxizyOnnxNwo60yaSpLWQ0diJhR17EUFM9TP811bc2H6hHPBapEnbEjHq7+cE9DvMTz695TyHesdr2IV78gsLHvMlaW7smOo7ZHSHUVsycFTJeHszuCKG2YuaskPHyYHZHCLUVM2eFjJcHsztCqK2YOStkvDyY3RGzPFoxc1ZIK3myKa3veu5BbxwIzXvvvacXBvPGbtDr7KR+dntMH330keCDC2Tkm6w13TB3EifzBpuA3fMwlVQo7qmkS98pJ+Dknwr3M/gma8qbKCsKcHIepgoQxT1VZOk3LQS8+E+VloqzEE8R8OJ56Lsxd0+1KIMhARIgAY8SoLh7tGEYFgmQAAk4IUBxd0KPeUmABEjAowQo7h5tGIYVHAJ4aQ4ft4z+3CIZbD/WHnwNNgvWjgRSQgAvm7lp9OcmzeD6Ys89uG3LmpEACWQxAYp7Fjc+q04CJBBcAhT34LYta0YCJJDFBCjuWdz4rDoJkEBwCVDcg9u2rBkJkEAWE6C4Z3Hjs+okQALBJUBxD27bsmYkQAJZTIDinsWNz6qTAAkElwDFPbhty5qRAAlkMQGKexY3PqtOAiQQXAIU9+C2LWtGAiSQxQQo7lnc+Kw6CZBAcAlw4rDgti1r5gECCxculPLyco2kZcuWUlxc7Cgq+nPGzxF8n2XmMns+azCGW52AF5c3MyPEGq0zZ86sFvDkyZNtNyH9iTjhZxt8Ehm9eB5yWCaJhmMSErBDAItv5+V9/eMYf0tLS+24CeehP2f8HMH3YWaKuw8bjSH7g0DdunWla9euGix6dn379nUUOP054+cIvg8zU9x92GgM2T8EBg0aJPn5+dK4cWMdc3dq9OeUYPbkp7hnT1uzphkgUFJSIpWVldK9e3dXSqc/VzBmhRPeUM2KZg5uJb14Iyu4tFmzRAS8eB6y556otbifBEiABHxMgOLu48Zj6CRAAiSQiADFPREZ7icBEiABHxPgG6o+bjyG7h0CoapKqbpwQiR0Kfmg6uRIbt2mUic3PybP0ZNV8tXeCqm4kLy/gro50qN9gTRvkhvjb+v887L02SNy/tTFmGOJdtRrnCfD/6eFdBtdLyZJRdUJOVW5Ry6FKmKOJdqRU6dAGud3kILcpjFJLp6vkPPHTxj4kq9vnZwcqdesqeTVK4jxxx0i7LnzLCABFwhYFnaUaVwINF8csyrscIELAfLFM6vCDh+4ECBfPLMq7PCBCwHyxTOrwg4fuBAgHy0+AYp7fC7cSwLWCFjpsUd6TpDPSo890l2ifFZ67JH+EuWz0mOP9Jcon5Uee3V8yff0rTWo/1NT3P3fhqwBCZAACcQQoLjHIOEOEiABEvA/AYq7/9uQNSABEiCBGAIU9xgk3EECJEAC/idAcfd/G7IGJEACJBBDgOIeg4Q7SIAESMD/BCju/m9D1oAESIAEYghQ3GOQcAcJkAAJ+J8Axd3/bcgakAAJkEAMAYp7DBLuIAESIAH/E6C4+78NWQMvEDAmAbNlCfJhEjA7ligfJgGzY4nyYRIwO5YoHyYBs2N289kpy2957BH1Wy0ZLwmkmABmd5QEQp2w6P+bFTLecczumEio46XHPnNWyHjHMbtjIqGOlx77zFkh4x3H7I6JhDpeeuwzZ4WMdxyzO1oVanNWyHj+uM84HUOGEQQJ+JWAF5c38ytLxm2fgBfPQ/bc7bcnc5IACZCAZwlQ3D3bNAyMBEiABOwToLjbZ8ecJEACJOBZAhR3zzYNAyMBEiAB+wQo7vbZMScJkAAJeJYAxd2zTcPASIAESMA+AYq7fXbMSQIkQAKeJUBx92zTMDASIAESsE+A4m6fHXOSQFIEdu7cKTNmzEgqbTKJNm3aJPPnz08madJpVq5cKStWrEg6fU0JEdsXX3xRUxJLx8Bux44dlvIwsfFGMCGQAAmklkDnzp2lbt26snnzZlcK6tChg+zZs8cVX6lwgtg6duzoimswA7vi4mJX/GWTE4p7NrU265oxAsOHD5fly5eLG7N9NGrUSPLz8+Xo0aMZq0+ighETYkOMTg2swAzsaNYJUNytM2MOErBMoF27dtK0aVPZuHGj5bzxMrRv396TvXf02hGbG4ahnSZNmgjY0awToLhbZ8YcJGCLwLBhw2TVqlVSVVVlK39kJgjo3r17Hftx2wFickPcwQj3AcCMZo8Axd0eN+YiAcsEWrVqJW3atJGysjLLeaMzYNx93759rgzzRPu2u41hFMSE2Jza+vXrpXXr1vqh2SNAcbfHjblIwBYB9ETXrFkjFy5csJXfzFSvXj0dsjh48KAjP25mRiyICbE5sYsXL8rq1atl6NChTtxkfV6Ke9afAgSQTgLNmjWTTp06qcA7Na+Nu7s13g42eNqmefPmThFldX6Ke1Y3v/8rP378+JhKfP7554JPtHll/5AhQ3RoBs+VO4nTHHd3q14HDhxwFI853u4knoqKClm3bp322p34iWz7dPh5/PHHo0+3jG9zJaaMNwEDyEYCn376qeTm5sqIESNsVx/DF9OmTZN7771XfTkx3LzEmDkuPHYMN0CnTp0q99xzj+Tl2VuvFeUuWbJEh6xKS0vthME8EQTYc+fpQAIZIDB48GDBm6Znz561XTpEtGXLlnoTM9OGGBCLE2EHCzz+CDY05wQo7s4Z0gMJWCZQv3596d27t+NX/r3ySKQbj0Di10OvXr2kQYMGlnkyQywBinssE+4hgbQQGDhwoGzbtk1Onjxpuzw8duiF590Rg5NHIMFg69atAiY0dwhQ3N3hSC8kYJkAXtPv27evvmJv1/Dc/LFjx6SystKuC8f5UDZiQCx2DTeXwaKgoMCuC+aLIkBx5ylBAhkk0K9fP51GwO48MTk5OVJUVJTRqQgQP2JALHYMdd+9e7eABc09AvZaw73y6YkEspoAbkBiKGLZsmW2OWR63N3peDt+uQwYMMDRzVjb8AKckeIe4MZl1fxBoE+fPnL48GH92LFMj7s7GW9HnQ8dOqRDMjR3CVDc3eVJbyRgmUCdOnUEAo/5VOwYHkE8c+ZMRsbdMd6OshGDHUOdUXcwoLlLgOLuLk96IwFbBLp16+ZotaHCwkI5cuSIrbLNTHYEFuPlKNuuYYUl1J3mPgGKu/tM6ZEELBNo3LixTrhl98Yq5oo/deqU5XKdZkCZKNuOoa6oM+pOc58Axd19pvRIArYIYEpgu+PuePHn3Llztsp1kglvldp96Qh1RZ1pqSFAcU8NV3olAcsE8Naq3ekIsM6o02mE7SwBiPlt7E45gLqizrTUEKC4p4YrvZKAZQJ4gceJQNsRZ8tBRmVwUiYuDHiRi5YaAhT31HClVxKwTMCJUFouzCMZsrHO6UJPcU8XaZZDAiRAAmkkQHFPI2wWRQIkQALpIkBxTxdplkMCJEACaSRAcU8jbBZFAiRAAukiQHFPF2mWQwIkQAJpJEBxTyNsFkUCJEAC6SJgfyXbdEXIckggCwgsXLhQysvLtaZ4a7O4uDjpWjvNi4JQdosWLZIuEwmdlmu3vpaCzOLEFPcsbnxW3RsEysrK5OOPPw4H89VXX8nkyZOTCs7NvChw7NixaS/XSn2TCo6JlACHZXgikECGCfTs2TP8Cn9ubq6UlpYmHZGbeUtKSjJSrpX6Jh0gE1LceQ6QQKYJYF6Yrl27hsOwsnCFm3mxolOy5ma5VuqbbHxMx547zwES8ASBQYMGCXrtmALX6sIXTvNifheU27BhQ0ssnJZrt76WgszixByWyeLGZ9W9QwBDIlVVVbamwHWaF6sptW7d2jIMp+Xara/lQLM0Qx1j4p5Qltad1SYBTxHALIn4d8SQh1Vzkhdl2c1vN5+TMq2yydb0FPdsbXnWmwRIINAEOCwT6OZl5UiABLKVAMU9W1ue9SYBEgg0AYp7oJuXlSMBEshWAhT3bG151psESCDQBCjugW5eVo4ESCBbCVDcs7XlWW8SIIFAE6C4B7p5WTkSIIFsJfD/AHe9CdD546ZbAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어텐션 가중치 계산은 디코더의 입력 및 은닉 상태를 입력으로\n",
    "사용하는 다른 feed-forwad 계층인 ``attn`` 으로 수행됩니다.\n",
    "학습 데이터에는 모든 크기의 문장이 있기 때문에 이 계층을 실제로\n",
    "만들고 학습시키려면 적용 할 수 있는 최대 문장 길이 (인코더 출력을 위한 입력 길이)를\n",
    "선택해야 합니다. 최대 길이의 문장은 모든 Attention 가중치를 사용하지만\n",
    "더 짧은 문장은 처음 몇 개만 사용합니다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        # prev_hidden(hidden_size) + embedded(hidden_size) = hidden_size * 2\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),    # 0번째 차원(batch)를 만듦\n",
    "                                 encoder_outputs.unsqueeze(0)) # 0번째 차원(batch)를 만듦 \n",
    "        # bmm : batch matrix-matrix product\n",
    "        # (b x n x m) @ (b x m x p) -> (b x n x p) 목표\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "학습\n",
    "========\n",
    "\n",
    "학습 데이터 준비\n",
    "-----------------------\n",
    "\n",
    "학습을 위해서, 각 쌍마다 입력 Tensor(입력 문장의 단어 주소)와\n",
    "목표 Tensor(목표 문장의 단어 주소)가 필요합니다. 이 벡터들을\n",
    "생성하는 동안 두 시퀀스에 EOS 토큰을 추가 합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습\n",
    "------------------\n",
    "\n",
    "학습을 위해서 인코더에 입력 문장을 넣고 모든 출력과 최신 은닉 상태를\n",
    "추적합니다. 그런 다음 디코더에 첫 번째 입력으로 ``<SOS>`` 토큰과\n",
    "인코더의 마지막 은닉 상태가 첫번쩨 은닉 상태로 제공됩니다.\n",
    "\n",
    "\"Teacher forcing\"은 다음 입력으로 디코더의 예측을 사용하는 대신\n",
    "실제 목표 출력을 다음 입력으로 사용하는 컨셉입니다.\n",
    "\"Teacher forcing\"을 사용하면 수렴이 빨리되지만 학습된 네트워크가\n",
    "잘못 사용될 때 불안정성을 보입니다.\n",
    "\n",
    "Teacher-forced 네트워크의 출력이 일관된 문법으로 읽지만 정확한\n",
    "번역과는 거리가 멀다는 것을 볼 수 있습니다. 직관적으로 출력 문법을\n",
    "표현하는 법을 배우고 교사가 처음 몇 단어를 말하면 의미를 \"선택\" 할 수 있지만,\n",
    "번역에서 처음으로 문장을 만드는 법은 잘 배우지 못합니다.\n",
    "\n",
    "PyTorch의 autograd 가 제공하는 자유 덕분에 간단한 If 문으로\n",
    "Teacher Forcing을 사용할지 아니면 사용하지 않을지를 선택할 수 있습니다.\n",
    "더 많이 사용하려면 ``teacher_forcing_ratio`` 를 확인하십시오.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing 포함: 목표를 다음 입력으로 전달\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # 입력으로 사용할 부분을 히스토리에서 분리 \n",
    "            print(criterion)\n",
    "            print(decoder_output, target_tensor[di])\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것은 현재 시간과 진행률%을 고려해 경과된 시간과 남은 예상\n",
    "시간을 출력하는 헬퍼 함수입니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 학습 과정은 다음과 같습니다:\n",
    "\n",
    "-  타이머 시작\n",
    "-  optimizers와 criterion 초기화\n",
    "-  학습 쌍의 세트 생성\n",
    "-  도식화를 위한 빈 손실 배열 시작\n",
    "\n",
    "그런 다음 우리는 여러 번 ``train`` 을 호출하며 때로는 진행률\n",
    "(예제의 %, 현재까지의 예상 시간)과 평균 손실을 출력합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # print_every 마다 초기화\n",
    "    plot_loss_total = 0   # plot_every 마다 초기화\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과 도식화\n",
    "----------------\n",
    "\n",
    "matplotlib로 학습 중에 저장된 손실 값 ``plot_losses`` 의 배열을\n",
    "사용하여 도식화합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # 주기적인 간격에 이 locator가 tick을 설정\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가\n",
    "==========\n",
    "\n",
    "평가는 대부분 학습과 동일하지만 목표가 없으므로 각 단계마다 디코더의\n",
    "예측을 되돌려 전달합니다.\n",
    "단어를 예측할 때마다 그 단어를 출력 문자열에 추가합니다.\n",
    "만약 EOS 토큰을 예측하면 거기에서 멈춥니다.\n",
    "나중에 도식화를 위해서 디코더의 Attention 출력을 저장합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 세트에 있는 임의의 문장을 평가하고\n",
    "입력, 목표 및 출력을 출력하여 주관적인 품질 판단을 내릴 수 있습니다:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습과 평가\n",
    "\n",
    "\n",
    "이러한 모든 헬퍼 함수를 이용해서 (추가 작업처럼 보이지만 여러 실험을\n",
    "더 쉽게 수행 할 수 있음) 실제로 네트워크를 초기화하고 학습을\n",
    "시작할 수 있습니다.\n",
    "\n",
    "입력 문장이 많이 필터링되었음을 기억하십시오. 이 작은 데이터 세트의\n",
    "경우 256 크기의 은닉 노드(hidden node)와 단일 GRU 계층 같은 상대적으로 작은\n",
    "네트워크를 사용할 수 있습니다. MacBook CPU에서 약 40분 후에\n",
    "합리적인 결과를 얻을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-8.1201, -7.8644, -7.6255,  ..., -7.7666, -8.0949, -7.8769]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([75], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9832, -7.8048, -7.6457,  ..., -7.8936, -8.0692, -7.8981]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9197, -7.7971, -7.6701,  ..., -7.9334, -8.0608, -7.8644]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9078, -7.7815, -7.6777,  ..., -7.9582, -8.0618, -7.8569]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([189], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9157, -7.7658, -7.6913,  ..., -7.9580, -8.0396, -7.8615]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1253], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9126, -7.7256, -7.7105,  ..., -7.9594, -8.0295, -7.8559]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.8975, -7.7324, -7.7287,  ..., -7.9714, -8.0537, -7.8878]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([307], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.8901, -7.7224, -7.7283,  ..., -7.9833, -8.0449, -7.8822]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.8898, -7.7301, -7.7182,  ..., -7.9635, -8.0336, -7.8782]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1146, -7.6762, -7.4501,  ..., -7.8402, -7.9852, -7.9015]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0572, -7.6546, -7.6259,  ..., -7.8737, -7.9703, -7.9753]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0205, -7.6191, -7.6579,  ..., -7.8741, -8.0223, -8.0157]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([784], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0990, -7.6595, -7.1892,  ..., -7.8709, -8.0254, -7.9008]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0460, -7.6507, -7.4238,  ..., -7.8928, -7.9807, -7.9588]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0127, -7.6141, -7.5473,  ..., -7.8573, -8.0467, -7.9966]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9715, -7.6093, -7.6316,  ..., -7.8978, -8.0133, -8.0121]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([358], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9572, -7.5788, -7.6468,  ..., -7.8350, -8.0604, -8.0459]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1157, -7.6558, -7.2302,  ..., -7.7985, -7.9780, -7.8581]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0544, -7.6657, -7.4334,  ..., -7.8932, -7.9528, -7.9494]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9850, -7.6273, -7.5166,  ..., -7.8804, -8.0228, -7.9875]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([824], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9675, -7.5974, -7.5933,  ..., -7.8840, -7.9749, -8.0119]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2739], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9575, -7.3246, -7.5776,  ..., -7.8803, -7.9943, -8.0101]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1342, -7.3800, -7.2096,  ..., -7.8592, -7.9408, -7.9258]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0963, -7.2512, -7.3554,  ..., -7.9708, -7.9229, -7.9585]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0926, -7.1864, -7.4442,  ..., -8.0380, -7.9062, -7.9810]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([237], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0543, -6.7930, -7.4893,  ..., -8.0130, -7.9893, -8.0684]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1306, -7.4605, -6.9171,  ..., -7.8094, -7.9528, -7.8997]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0855, -7.4258, -7.3149,  ..., -7.8745, -7.9915, -7.9964]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0406, -7.3595, -7.4350,  ..., -7.8622, -7.9985, -8.0424]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([61], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0101, -6.9064, -7.4399,  ..., -7.8968, -8.0504, -8.1020]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0683, -7.2561, -6.9529,  ..., -7.8199, -8.0119, -7.9059]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0552, -7.1430, -7.1617,  ..., -7.9624, -7.9452, -7.9340]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0538, -7.0442, -7.3471,  ..., -8.0121, -7.9042, -7.9716]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([61], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0304, -6.6570, -7.4021,  ..., -7.9967, -7.9946, -8.0583]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1424, -7.2457, -6.8117,  ..., -7.8046, -7.9140, -7.8291]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0642, -7.1150, -7.0219,  ..., -7.9640, -7.8840, -7.8974]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0053, -7.1149, -7.2391,  ..., -7.9096, -7.9386, -8.0302]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([64], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1290, -7.2296, -6.6286,  ..., -7.8106, -7.9865, -7.9024]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0957, -7.0890, -6.8967,  ..., -7.9879, -7.9235, -7.9740]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0863, -6.9599, -7.0647,  ..., -8.0751, -7.8989, -8.0068]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([11], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0217, -7.0091, -7.2755,  ..., -7.9738, -7.9273, -8.0410]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0104, -6.4991, -7.3216,  ..., -7.9716, -8.0148, -8.1200]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1534, -6.6672, -6.5261,  ..., -7.8496, -7.8929, -7.9751]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1129, -6.3272, -6.7723,  ..., -8.0471, -7.8525, -8.0435]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1383, -6.1202, -6.9104,  ..., -8.1430, -7.8429, -8.0732]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0730, -5.3663, -7.0633,  ..., -8.1030, -7.9795, -8.1578]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([360], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2103, -6.6441, -6.2743,  ..., -7.8639, -7.9686, -7.9583]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1518, -6.3451, -6.5325,  ..., -8.0420, -7.9212, -8.0488]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1208, -6.1536, -6.6858,  ..., -8.1072, -7.9075, -8.0880]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([104], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0850, -5.5027, -6.9111,  ..., -8.0536, -7.9949, -8.1481]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([9], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2014, -6.4805, -6.0053,  ..., -7.8778, -7.9590, -8.0285]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1336, -6.1404, -6.2999,  ..., -8.0370, -7.9263, -8.0809]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1179, -6.0019, -6.4694,  ..., -8.1228, -7.8942, -8.1256]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0464, -6.1505, -6.9108,  ..., -7.9932, -8.0230, -8.2024]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([389], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1544, -6.5247, -5.5245,  ..., -7.8625, -7.9106, -7.9853]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0984, -6.2503, -5.9298,  ..., -8.0799, -7.8913, -8.0944]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0064, -6.3484, -6.5686,  ..., -7.9846, -7.9902, -8.1895]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9830, -6.4118, -6.9033,  ..., -7.9511, -8.0165, -8.2161]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([431], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9822, -5.6006, -6.8828,  ..., -8.0037, -8.0136, -8.2206]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1863, -6.4894, -5.5885,  ..., -7.8550, -7.9147, -8.0058]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1433, -6.0789, -5.8642,  ..., -8.0518, -7.8705, -8.0974]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0830, -6.1818, -6.4871,  ..., -7.9575, -7.9855, -8.1784]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0420, -6.3021, -6.8517,  ..., -7.9316, -8.0215, -8.2006]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([71], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0308, -5.4967, -6.8538,  ..., -7.9912, -8.0142, -8.2035]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-8.1484, -5.7632, -5.3972,  ..., -7.9200, -8.0067, -7.9907]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1014, -5.5691, -6.1753,  ..., -7.9701, -8.0506, -8.1391]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0608, -5.5009, -6.5363,  ..., -7.9758, -8.0609, -8.1810]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0656, -4.3916, -6.5533,  ..., -8.0778, -8.0070, -8.2057]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1281], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1439, -5.7079, -5.3551,  ..., -7.9123, -8.0677, -8.0600]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0372, -5.5279, -6.0461,  ..., -7.9521, -8.0590, -8.1546]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9830, -5.3944, -6.4258,  ..., -8.0018, -8.0645, -8.2168]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([61], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9722, -5.2990, -6.5992,  ..., -8.0448, -8.0274, -8.2344]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9948, -5.2955, -6.7920,  ..., -8.0489, -8.0148, -8.2375]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1191], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9996, -4.3245, -6.7197,  ..., -8.1185, -8.0034, -8.2566]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([309], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2098, -5.6686, -4.6463,  ..., -7.8987, -8.0293, -8.0447]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0878, -5.2572, -5.4011,  ..., -7.9934, -8.0025, -8.1638]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0207, -5.0975, -5.7960,  ..., -8.0895, -7.9881, -8.2148]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([110], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9613, -5.0109, -5.9888,  ..., -8.1220, -8.0000, -8.2383]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-7.9459, -5.0007, -6.1606,  ..., -8.1205, -7.9865, -8.2478]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1884, -5.2464, -4.0691,  ..., -7.9401, -8.0002, -8.1301]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0814, -4.5312, -4.8760,  ..., -8.0812, -7.9837, -8.2856]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0184, -4.1102, -5.2321,  ..., -8.1831, -7.9938, -8.3426]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([522], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0369, -3.4996, -5.4802,  ..., -8.2266, -8.0355, -8.3626]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([367], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2702, -4.8276, -3.4218,  ..., -8.0373, -8.1459, -8.0450]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1276, -5.0215, -4.5859,  ..., -8.0484, -8.0364, -8.1508]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0956, -4.1226, -4.7124,  ..., -8.1282, -8.0515, -8.2538]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([61], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1314, -3.0308, -5.0271,  ..., -8.2707, -8.0963, -8.3445]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2755, -4.8971, -2.6398,  ..., -8.0811, -8.1615, -8.1442]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1086, -4.9344, -3.9200,  ..., -8.0939, -8.1000, -8.2217]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0375, -4.8739, -4.7500,  ..., -8.0264, -8.0498, -8.2378]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([237], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0284, -4.9016, -5.3034,  ..., -7.9996, -8.0385, -8.2355]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0783, -3.4652, -5.0626,  ..., -8.1530, -8.0749, -8.3025]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3430, -4.9096, -2.7155,  ..., -8.1037, -8.1796, -8.1026]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1542, -5.0159, -3.8970,  ..., -8.1128, -8.0185, -8.1685]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0502, -4.9463, -4.7798,  ..., -8.0607, -7.9937, -8.2420]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([384], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0328, -4.9234, -5.2698,  ..., -7.9973, -8.0072, -8.2895]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0648, -3.5930, -5.1166,  ..., -8.1387, -8.0592, -8.3273]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4399, -4.4203, -1.9884,  ..., -8.2340, -8.2745, -8.2499]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2458, -4.2869, -3.1259,  ..., -8.1992, -8.0812, -8.2798]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1294, -3.8815, -3.8635,  ..., -8.1413, -8.0667, -8.3060]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([61], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0682, -3.8112, -4.4540,  ..., -8.1019, -8.0469, -8.3524]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1745, -2.5377, -4.4437,  ..., -8.3037, -8.1280, -8.4344]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1888], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5699, -4.1398, -1.8018,  ..., -8.3252, -8.3789, -8.3810]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3305, -3.8897, -2.7758,  ..., -8.3278, -8.1775, -8.3997]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2084, -3.3838, -3.5537,  ..., -8.2422, -8.1399, -8.4056]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([46], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3577, -1.9990, -3.8023,  ..., -8.4554, -8.2724, -8.6094]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6166, -3.5219, -1.7883,  ..., -8.5063, -8.6089, -8.4524]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4695, -3.1328, -2.8390,  ..., -8.5123, -8.3983, -8.5629]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3619, -2.5155, -3.6340,  ..., -8.4440, -8.3374, -8.5575]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([5], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7850, -1.0870, -4.1656,  ..., -8.9266, -8.7058, -9.0099]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0178, -4.0018, -1.1918,  ..., -8.7942, -8.8439, -8.7713]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7641, -3.5289, -2.2398,  ..., -8.7551, -8.6028, -8.8319]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5020, -2.9368, -3.1631,  ..., -8.5354, -8.4354, -8.7312]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8019, -1.5499, -3.6981,  ..., -8.9087, -8.7055, -9.0310]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([61], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5668, -3.8718, -0.6411,  ..., -9.3657, -9.4704, -9.2563]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0787, -3.0418, -1.6607,  ..., -9.0778, -8.9534, -9.0994]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6940, -2.3293, -2.6556,  ..., -8.7792, -8.6657, -8.8764]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([61], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3564, -0.8045, -3.4765,  ..., -9.5341, -9.2646, -9.5751]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1410], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1980, -4.1566, -1.0285,  ..., -9.0180, -9.0748, -8.9409]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([75], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8881, -3.4670, -2.1725,  ..., -8.9326, -8.7693, -8.9739]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6075, -2.5790, -3.0932,  ..., -8.7347, -8.5907, -8.8593]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([953], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-9.0637, -1.0937, -3.7329,  ..., -9.2496, -9.0307, -9.3186]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8273, -4.2822, -1.4100,  ..., -8.6825, -8.8283, -8.6590]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5975, -3.7658, -2.6765,  ..., -8.6418, -8.5197, -8.6825]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3914, -3.0024, -3.6177,  ..., -8.4794, -8.3911, -8.5689]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([215], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7324, -1.3825, -4.0443,  ..., -8.9036, -8.6903, -8.9617]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([739], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6809, -4.6989, -0.6034,  ..., -9.4338, -9.4980, -9.4373]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2959, -3.7913, -1.8246,  ..., -9.3039, -9.0986, -9.3879]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6730, -2.7880, -2.8503,  ..., -8.7668, -8.5739, -8.8590]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([360], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4708, -2.5093, -3.5944,  ..., -8.6134, -8.4431, -8.7755]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1027, -0.9027, -4.1286,  ..., -9.2914, -8.9919, -9.3958]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1028], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.7829, -5.3434, -0.5033,  ..., -9.6674, -9.8005, -9.6208]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2861, -4.4161, -1.7913,  ..., -9.3355, -9.1949, -9.3941]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5573, -3.3405, -2.7735,  ..., -8.6452, -8.5116, -8.7911]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2108], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3721, -2.9567, -3.5518,  ..., -8.4263, -8.3670, -8.6419]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1166], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8219, -1.2344, -3.7738,  ..., -8.9835, -8.7514, -9.1193]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2739, -5.1283, -0.7985,  ..., -9.1268, -9.2005, -9.0010]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([75], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8298, -4.3809, -2.2878,  ..., -8.8713, -8.6472, -8.8405]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3027, -3.7566, -3.5814,  ..., -8.4112, -8.2487, -8.4634]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([890], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1793, -3.5920, -4.2609,  ..., -8.2931, -8.2140, -8.4378]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([136], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5231, -1.6598, -4.4361,  ..., -8.6542, -8.4317, -8.8060]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([890], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9427, -5.0036, -1.1914,  ..., -8.7129, -8.8336, -8.6989]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6451, -4.3747, -2.7094,  ..., -8.6688, -8.5041, -8.7263]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2215, -4.0145, -4.0550,  ..., -8.3049, -8.2082, -8.4521]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1139, -3.9474, -4.9004,  ..., -8.2151, -8.1682, -8.3917]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([743], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4217, -1.8255, -4.8900,  ..., -8.5628, -8.3678, -8.6836]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([744], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8357, -5.0656, -1.4671,  ..., -8.5988, -8.7577, -8.5249]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5646, -4.5027, -3.1308,  ..., -8.5980, -8.4155, -8.5812]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2049, -4.1930, -4.3674,  ..., -8.2648, -8.1963, -8.3708]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([182], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.0795, -4.2249, -5.1403,  ..., -8.1531, -8.1485, -8.2886]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3234, -2.1097, -5.0656,  ..., -8.4722, -8.2981, -8.5644]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3807, -4.7541, -0.6332,  ..., -9.1687, -9.3284, -9.1017]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7658, -3.7134, -2.1365,  ..., -8.7791, -8.6260, -8.8537]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3795, -3.1867, -3.7024,  ..., -8.4499, -8.3317, -8.5880]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9078, -1.0654, -4.3897,  ..., -9.0350, -8.7920, -9.1338]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([98], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2479, -4.5642, -1.0471,  ..., -9.0311, -9.2154, -8.9318]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9006, -3.6333, -2.7418,  ..., -8.9036, -8.7658, -8.9304]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4185, -2.9489, -4.0697,  ..., -8.4824, -8.4078, -8.6448]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([255], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2165, -0.7384, -5.0360,  ..., -9.3264, -9.1433, -9.4499]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4019, -4.9735, -1.1104,  ..., -9.1877, -9.3498, -9.0598]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0081, -4.1500, -2.8788,  ..., -8.9995, -8.8933, -9.0449]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5178, -3.3143, -4.1505,  ..., -8.5150, -8.5165, -8.6949]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1886, -0.9625, -5.1012,  ..., -9.2867, -9.1285, -9.3995]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([429], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6218, -5.3202, -0.8998,  ..., -9.4370, -9.6384, -9.2651]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2830, -4.5337, -2.6675,  ..., -9.2979, -9.1678, -9.3289]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5458, -3.6247, -3.8291,  ..., -8.6418, -8.5665, -8.7736]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0610, -1.1294, -4.6242,  ..., -9.1998, -9.0019, -9.2705]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([33], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.9227, -6.0804, -0.6223,  ..., -9.6659, -9.8681, -9.5424]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6075, -5.1754, -2.3431,  ..., -9.5900, -9.4769, -9.6376]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6540, -3.9724, -3.4542,  ..., -8.6865, -8.6627, -8.8732]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([66], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4158, -3.5744, -4.3075,  ..., -8.4756, -8.4937, -8.7328]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9224, -1.1921, -4.7783,  ..., -9.0559, -8.8954, -9.2036]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1325], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.2977,  -6.2297,  -0.3253,  ..., -10.1009, -10.2627,  -9.8981]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3198, -4.6317, -2.0231,  ..., -9.3471, -9.2010, -9.3617]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6102, -3.5188, -3.3195,  ..., -8.6622, -8.6489, -8.8314]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([700], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1829, -1.0182, -4.3339,  ..., -9.3059, -9.1373, -9.4263]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4622, -5.3662, -1.1889,  ..., -9.2939, -9.5082, -9.0905]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2310, -4.4369, -3.2825,  ..., -9.2591, -9.2043, -9.3054]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6654, -3.4926, -4.5030,  ..., -8.6997, -8.7356, -8.8927]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([23], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4899, -0.8632, -5.5637,  ..., -9.5991, -9.4473, -9.7263]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5235, -5.6442, -1.4822,  ..., -9.2752, -9.4572, -9.1701]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.2671, -4.9017, -3.6485,  ..., -9.2640, -9.1397, -9.3606]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7245, -3.9938, -4.7477,  ..., -8.7883, -8.7427, -8.9698]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([105], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4144, -1.3483, -5.8288,  ..., -9.5356, -9.3147, -9.6489]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1799,  -0.6339,  -6.7631,  ..., -10.3526, -10.0542, -10.4036]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6909, -5.6006, -1.9443,  ..., -9.4338, -9.5864, -9.2938]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5716, -4.2231, -3.6130,  ..., -9.5416, -9.4396, -9.5624]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8522,  -3.6198,  -4.6311,  ...,  -9.9912,  -9.7000, -10.0288]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1206], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1544,  -1.2879,  -6.0280,  ..., -10.2765,  -9.9872, -10.3417]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([366], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7435,  -0.5989,  -7.1269,  ..., -10.9312, -10.5506, -10.9505]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1166], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8569, -5.8523, -1.6359,  ..., -9.6119, -9.7810, -9.4270]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2849, -4.3081, -3.2039,  ..., -9.2926, -9.1752, -9.2374]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2673, -3.5345, -4.1349,  ..., -9.4183, -9.1344, -9.3793]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.7090, -0.8999, -5.5435,  ..., -9.8630, -9.5395, -9.8695]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([445], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.3451,  -6.5223,  -0.5743,  ..., -10.1118, -10.2716,  -9.8083]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2649, -4.9659, -2.5064,  ..., -9.2923, -9.0982, -9.2328]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5158, -3.6536, -4.0041,  ..., -8.5910, -8.5215, -8.6863]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2369], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5309, -0.6111, -5.5638,  ..., -9.6758, -9.3848, -9.7391]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.4024,  -7.1288,  -0.3976,  ..., -10.2173, -10.3596,  -9.9759]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4756, -5.7405, -2.5098,  ..., -9.5301, -9.2816, -9.4868]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4616, -4.3192, -3.7644,  ..., -8.5540, -8.4782, -8.6838]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2869, -3.7324, -4.8105,  ..., -8.3510, -8.3959, -8.5915]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([24], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1212, -0.9217, -5.5498,  ..., -9.2353, -9.0751, -9.3931]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.4816,  -7.0630,  -0.4167,  ..., -10.2629, -10.3255,  -9.9624]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2725, -5.4292, -2.3395,  ..., -9.3102, -9.0880, -9.2667]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5071, -4.0756, -3.7948,  ..., -8.5421, -8.4804, -8.6658]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([58], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3272, -0.8202, -5.1599,  ..., -9.4510, -9.2016, -9.5361]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8122, -6.5351, -1.3418,  ..., -9.5852, -9.6852, -9.3330]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3245, -5.6535, -3.6722,  ..., -9.3625, -9.1377, -9.3085]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1471, -3.6999, -4.6703,  ..., -9.3351, -8.9907, -9.3858]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3304, -2.6837, -5.5401,  ..., -9.6374, -9.1350, -9.6955]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1209], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.3149,  -0.4836,  -6.9714,  ..., -10.5850, -10.0522, -10.6085]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0663,  -7.5794,  -0.7067,  ...,  -9.8793, -10.0286,  -9.5733]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4856, -6.6312, -3.1012,  ..., -9.5079, -9.2882, -9.4391]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5174, -4.9541, -4.3047,  ..., -8.5113, -8.4875, -8.6335]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([183], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5387, -3.5336, -4.7996,  ..., -8.5540, -8.4645, -8.6989]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([517], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2458, -1.0125, -5.5950,  ..., -9.3682, -9.0894, -9.4611]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([435], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.3365,  -8.0461,  -0.4822,  ..., -10.0845, -10.2105,  -9.8627]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6123, -7.1662, -2.9268,  ..., -9.6174, -9.3650, -9.5618]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5046, -5.4465, -3.9394,  ..., -8.5223, -8.4608, -8.6413]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([186], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2625, -4.8942, -4.9880,  ..., -8.2819, -8.3263, -8.4907]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([350], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6898, -1.8127, -5.1680,  ..., -8.7684, -8.5757, -8.9116]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([736], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6270,  -8.6496,  -0.3363,  ..., -10.3863, -10.5381, -10.0617]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([75], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8844, -7.6295, -2.8823,  ..., -9.8959, -9.6285, -9.7949]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4375, -5.7599, -3.9636,  ..., -8.4676, -8.4190, -8.5650]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([255], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1893, -5.2281, -5.0352,  ..., -8.2322, -8.2758, -8.4366]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([158], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5740, -1.9054, -5.2479,  ..., -8.7065, -8.4894, -8.8329]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1739], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.9445, -7.9689, -0.6388,  ..., -9.7776, -9.9540, -9.5018]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3741, -7.1196, -3.2575,  ..., -9.4256, -9.1613, -9.3117]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3775, -5.8573, -4.4475,  ..., -8.4140, -8.3868, -8.4759]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1695, -5.3680, -5.5709,  ..., -8.1872, -8.2590, -8.3439]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([266], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5661, -1.9126, -5.6227,  ..., -8.6638, -8.4502, -8.8105]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-10.1538,  -6.9215,  -0.7103,  ...,  -9.9360, -10.0471,  -9.6495]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5639, -5.7726, -3.4175,  ..., -9.6083, -9.2682, -9.4972]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4311, -4.2446, -4.6628,  ..., -8.4761, -8.3972, -8.5491]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([418], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7101, -3.1778, -4.7089,  ..., -8.9094, -8.5455, -8.8809]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8019, -0.4878, -6.1857,  ..., -9.9673, -9.5669, -9.9705]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.2011,  -6.7949,  -1.2971,  ...,  -9.9376, -10.0851,  -9.6812]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5289, -4.5945, -3.3489,  ..., -9.4808, -9.2672, -9.3456]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4428, -3.4807, -4.4713,  ..., -9.5717, -9.1463, -9.4765]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3823, -2.2467, -5.5235,  ..., -9.5969, -9.1112, -9.6230]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([703], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6751,  -0.2921,  -7.3802,  ..., -10.8356, -10.3443, -10.8847]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([517], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1369,  -7.2779,  -1.1942,  ...,  -9.8348, -10.0242,  -9.6301]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3671, -5.2609, -3.4199,  ..., -9.3316, -9.0964, -9.1983]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0022, -3.7011, -4.8731,  ..., -9.1053, -8.7482, -9.1769]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([158], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0372, -2.8673, -5.7147,  ..., -9.2381, -8.8144, -9.3473]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.9264,  -0.5934,  -6.8912,  ..., -10.1057,  -9.6533, -10.1947]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1490], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.2595,  -7.4042,  -0.8392,  ..., -10.0243, -10.1636,  -9.7492]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.7088, -6.4445, -4.0582,  ..., -9.7371, -9.4228, -9.6629]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4263, -4.5895, -5.2487,  ..., -8.4915, -8.4109, -8.5951]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([246], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2785, -0.8114, -6.4375,  ..., -9.3970, -9.1026, -9.4734]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([466], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0159,  -7.5086,  -1.3448,  ...,  -9.7140,  -9.8414,  -9.5295]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2355, -6.3977, -4.2946,  ..., -9.2321, -8.8806, -9.1826]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3562, -4.9825, -5.4483,  ..., -8.3828, -8.3285, -8.5388]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1291], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9842, -1.1237, -6.4556,  ..., -9.0633, -8.8078, -9.1920]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6918, -6.6719, -1.6959,  ..., -9.4601, -9.5929, -9.1906]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6918, -4.4174, -4.5957,  ..., -8.6681, -8.4555, -8.5506]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6800, -0.5394, -6.7652,  ..., -9.7817, -9.3891, -9.7758]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([982], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0452,  -7.5398,  -0.9401,  ...,  -9.6982,  -9.8658,  -9.5229]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6441, -6.7521, -4.3464,  ..., -9.6612, -9.2908, -9.5879]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5019, -4.8528, -5.4753,  ..., -8.5381, -8.4284, -8.6630]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([296], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3994, -0.7874, -6.7115,  ..., -9.5062, -9.1731, -9.6470]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([606], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.3772,  -8.2801,  -0.5456,  ..., -10.0898, -10.2855,  -9.8447]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.9257, -7.5783, -3.9499,  ..., -9.9811, -9.6756, -9.8995]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4205, -5.3841, -5.0371,  ..., -8.4862, -8.4268, -8.5948]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([619], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9552, -1.2416, -5.9270,  ..., -9.0973, -8.8279, -9.2205]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1349], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.5337,  -8.6860,  -0.3755,  ..., -10.2990, -10.4472, -10.0527]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.9794,  -7.8875,  -3.8500,  ..., -10.0808,  -9.7184,  -9.9781]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3469, -5.6997, -4.9082,  ..., -8.4434, -8.3898, -8.5437]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([246], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.1801, -5.0941, -6.0459,  ..., -8.2424, -8.3283, -8.4748]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([720], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8355, -1.2245, -6.3547,  ..., -8.9581, -8.7831, -9.1472]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.3241,  -8.5719,  -0.7878,  ..., -10.0392, -10.1195,  -9.7364]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5160, -7.5208, -3.9389,  ..., -9.5534, -9.1892, -9.4631]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3716, -5.7623, -5.3359,  ..., -8.4368, -8.3662, -8.5513]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([41], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8765, -1.7690, -6.1653,  ..., -9.0449, -8.7557, -9.1424]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([515], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8213,  -0.6535,  -7.3107,  ..., -10.0491,  -9.6768, -10.1013]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6472,  -8.8200,  -0.6121,  ..., -10.3749, -10.4600, -10.0920]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.7305, -7.6088, -3.8492,  ..., -9.7853, -9.3875, -9.6799]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4112, -5.6534, -5.1845,  ..., -8.4963, -8.3634, -8.6141]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9139, -1.6494, -5.9490,  ..., -9.0335, -8.7416, -9.1604]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1693], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1924,  -8.7123,  -0.9811,  ...,  -9.9668, -10.1067,  -9.7221]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([75], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5569, -7.7512, -4.1413,  ..., -9.6359, -9.2929, -9.5618]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3688, -6.0584, -5.3070,  ..., -8.4488, -8.3996, -8.5614]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6685, -2.2495, -6.0163,  ..., -8.7787, -8.5906, -8.9006]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4095, -0.8266, -7.0297,  ..., -9.5451, -9.2900, -9.6340]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([130], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0356,  -8.7126,  -1.2991,  ...,  -9.7746,  -9.9216,  -9.5458]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3760, -7.8543, -4.3445,  ..., -9.3977, -9.0487, -9.3499]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3545, -6.3729, -5.6531,  ..., -8.4043, -8.3487, -8.5691]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([525], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6439, -2.4359, -6.2142,  ..., -8.7093, -8.4688, -8.8888]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1254], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1871, -1.0652, -6.8117,  ..., -9.3024, -9.0082, -9.4174]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1787,  -8.5438,  -0.8334,  ...,  -9.9267, -10.0627,  -9.6780]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5811, -7.7297, -4.2331,  ..., -9.6154, -9.2671, -9.5772]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4561, -5.9679, -5.4765,  ..., -8.5266, -8.4438, -8.6734]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([155], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8692, -2.1106, -6.1715,  ..., -9.0123, -8.7231, -9.1460]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1093], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6298, -0.9122, -7.1291,  ..., -9.8016, -9.4365, -9.8782]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0229,  -8.7836,  -1.2954,  ...,  -9.7759,  -9.9268,  -9.5354]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8607, -8.4222, -4.7452,  ..., -9.9111, -9.5701, -9.8531]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0947, -6.2532, -5.5741,  ..., -9.2869, -8.8973, -9.3383]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2544, -2.9092, -6.4206,  ..., -9.4371, -9.0438, -9.5093]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8321,  -1.7017,  -7.3880,  ..., -10.0249,  -9.6182, -10.0867]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([44], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.2582,  -1.2541,  -8.0284,  ..., -10.4745, -10.0314, -10.5121]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([794], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.4670,  -1.0999,  -8.3084,  ..., -10.6917, -10.2602, -10.7089]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7682,  -0.9197,  -8.5817,  ..., -11.0027, -10.5482, -10.9809]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.3666,  -9.3458,  -0.6316,  ..., -10.0428, -10.2499,  -9.8574]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8753, -8.8194, -3.9664,  ..., -9.8712, -9.5941, -9.8604]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3889, -6.7840, -5.0963,  ..., -8.4574, -8.4525, -8.6610]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([189], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3738, -5.0504, -5.6768,  ..., -8.4653, -8.3759, -8.6579]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1253], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6575, -2.1612, -6.1937,  ..., -8.7431, -8.5568, -8.9845]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([744], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6016,  -9.2105,  -0.5864,  ..., -10.2556, -10.4552, -10.0399]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0358,  -8.3880,  -3.9600,  ..., -10.0097,  -9.7161, -10.0075]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3826, -6.0986, -5.0791,  ..., -8.4769, -8.4410, -8.6081]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3489, -4.3821, -5.8795,  ..., -8.4076, -8.3321, -8.6199]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([158], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7284, -1.5267, -6.3787,  ..., -8.8271, -8.6405, -9.0752]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([155], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-11.2250,  -9.0259,  -0.2265,  ..., -10.9372, -11.1806, -10.7612]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.8293,  -8.2484,  -4.2487,  ..., -10.8446, -10.5522, -10.8993]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5811, -4.8399, -4.6738,  ..., -8.6708, -8.5972, -8.8844]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6144, -3.0476, -5.4965,  ..., -8.6960, -8.5564, -8.9425]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([350], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.7151,  -0.4794,  -6.9107,  ...,  -9.8309,  -9.5937, -10.0944]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([714], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6812,  -8.8457,  -0.5847,  ..., -10.4319, -10.6412, -10.2063]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0584,  -7.8503,  -4.1885,  ..., -10.0980,  -9.7565, -10.0587]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5515, -5.5038, -5.3792,  ..., -8.6535, -8.5832, -8.7917]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5058, -3.7486, -6.0590,  ..., -8.5875, -8.4896, -8.7851]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([49], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2591, -0.7655, -7.0106,  ..., -9.3532, -9.1657, -9.5719]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9787,  -8.6356,  -0.3866,  ..., -10.6514, -10.8769, -10.4376]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.4951,  -7.8187,  -4.3439,  ..., -10.4769, -10.1282, -10.4764]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5728, -4.6714, -5.0868,  ..., -8.5986, -8.5394, -8.7930]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([681], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5999, -2.9491, -5.9916,  ..., -8.6633, -8.5409, -8.8907]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.9691,  -0.3800,  -7.6673,  ..., -10.0667,  -9.8211, -10.3056]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9066,  -8.7681,  -0.6091,  ..., -10.6269, -10.8404, -10.3794]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1646,  -7.7378,  -4.2965,  ..., -10.1659,  -9.8204, -10.1852]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5670, -5.1993, -5.4600,  ..., -8.6088, -8.5602, -8.8177]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([54], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5791, -3.3039, -6.1166,  ..., -8.6648, -8.5498, -8.8520]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([606], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.7818,  -0.4674,  -7.5859,  ...,  -9.8821,  -9.6448, -10.0761]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1048], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6068,  -8.8966,  -1.0836,  ..., -10.3140, -10.4969, -10.0873]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8722, -7.9593, -4.5804,  ..., -9.8566, -9.5069, -9.8644]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4883, -5.8197, -5.8492,  ..., -8.5304, -8.5124, -8.7362]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2648], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4260, -4.3833, -6.5340,  ..., -8.4962, -8.4140, -8.6886]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([677], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1380, -0.9186, -7.3476,  ..., -9.2435, -9.0257, -9.4648]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9688,  -9.2542,  -0.8518,  ..., -10.5977, -10.8231, -10.4121]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8684, -7.9466, -3.9167,  ..., -9.8054, -9.4348, -9.7981]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4190, -5.6548, -5.0686,  ..., -8.4056, -8.3728, -8.6140]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([151], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3968, -4.1450, -5.6084,  ..., -8.3841, -8.3434, -8.5775]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([41], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3929, -0.6132, -6.8079,  ..., -9.4072, -9.1811, -9.6456]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([739], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3519, -10.0229,  -0.3906,  ..., -11.0273, -11.2959, -10.8046]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.4032,  -9.0149,  -3.7432,  ..., -10.3021, -10.0154, -10.3327]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4345, -6.3939, -4.5574,  ..., -8.3739, -8.3812, -8.6312]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3442, -4.8904, -5.3558,  ..., -8.2972, -8.2889, -8.5599]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([598], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9685, -1.0469, -6.0838,  ..., -8.9573, -8.7765, -9.2362]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5102, -10.3026,  -0.2715,  ..., -11.1903, -11.3479, -10.9798]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8959, -8.5391, -3.1755,  ..., -9.8318, -9.4272, -9.8563]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4187, -6.3603, -4.5473,  ..., -8.4037, -8.3155, -8.6814]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([570], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3593, -5.0715, -5.5164,  ..., -8.3458, -8.2970, -8.6550]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8828, -1.5737, -6.0182,  ..., -8.9355, -8.7031, -9.1725]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3969,  -9.5257,  -1.6099,  ..., -11.0520, -11.2294, -10.8238]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5802, -6.2937, -3.7847,  ..., -9.4891, -9.1499, -9.3205]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8909, -4.2127, -5.2808,  ..., -8.9308, -8.5268, -8.9825]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6999, -0.5899, -6.7278,  ..., -9.7758, -9.3664, -9.9105]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([511], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3885,  -9.7238,  -0.3335,  ..., -11.1004, -11.2228, -10.8515]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.9915, -8.0853, -3.5394,  ..., -9.9623, -9.5108, -9.9632]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7534, -5.2567, -4.0628,  ..., -8.7576, -8.4572, -8.8943]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([368], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6191, -4.0065, -5.0438,  ..., -8.6646, -8.4043, -8.8203]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([695], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6756, -0.5440, -6.5658,  ..., -9.7687, -9.4094, -9.9688]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7176, -10.5319,  -0.2621,  ..., -11.3970, -11.5291, -11.0532]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.2497,  -8.8903,  -3.4643,  ..., -10.1920,  -9.7209, -10.0657]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4570, -6.1093, -4.6370,  ..., -8.4496, -8.3129, -8.5997]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4600, -4.3131, -5.2429,  ..., -8.5055, -8.3375, -8.6587]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([397], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1441, -0.9839, -5.9115,  ..., -9.2129, -8.9587, -9.4194]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([380], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9905,  -9.5565,  -0.5468,  ..., -10.6763, -10.8150, -10.4677]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.5295,  -8.8888,  -4.6459,  ..., -10.4845, -10.0368, -10.4906]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4726, -5.8928, -5.2710,  ..., -8.4851, -8.3334, -8.7101]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([72], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9896, -1.2932, -5.9412,  ..., -9.0158, -8.7230, -9.2765]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1072,  -9.8859,  -0.3589,  ..., -10.8310, -10.9093, -10.6144]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6353,  -9.2935,  -4.4723,  ..., -10.6270, -10.1317, -10.6227]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4453, -6.1384, -5.0237,  ..., -8.4620, -8.2697, -8.7110]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8220, -1.6121, -5.5764,  ..., -8.8665, -8.5725, -9.1470]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([182], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7970,  -9.7431,  -0.7760,  ..., -10.4919, -10.6401, -10.2826]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.2271,  -8.9583,  -4.6895,  ..., -10.1908,  -9.7566, -10.2162]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4886, -6.4853, -5.5907,  ..., -8.4987, -8.4015, -8.7762]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([151], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4027, -4.8795, -6.2222,  ..., -8.4741, -8.3314, -8.7519]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([877], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0269, -1.1985, -6.5842,  ..., -9.0692, -8.8118, -9.3668]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9178,  -9.8441,  -1.3390,  ..., -10.5927, -10.6913, -10.3662]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5115, -7.5264, -4.3097,  ..., -9.4683, -9.0362, -9.3581]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8701, -5.8472, -5.7639,  ..., -8.9228, -8.5228, -9.0501]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1119], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1744, -1.8754, -6.4954,  ..., -9.2413, -8.8242, -9.4573]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0100,  -0.7080,  -7.4600,  ..., -10.1078,  -9.6763, -10.2830]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0024,  -9.7257,  -2.0297,  ..., -10.7385, -10.9092, -10.5144]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.7536, -7.3678, -4.7021,  ..., -9.7236, -9.3476, -9.5941]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9838, -5.3564, -6.0494,  ..., -9.0463, -8.6406, -9.1657]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([110], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5075, -1.4946, -6.9446,  ..., -9.5820, -9.1529, -9.7565]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.5834,  -0.5055,  -8.1904,  ..., -10.7096, -10.2519, -10.8305]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-11.8773, -10.3349,  -0.3119,  ..., -11.4715, -11.6523, -11.2007]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7153,  -9.1654,  -3.5538,  ..., -10.5320, -10.1554, -10.5565]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4544, -6.0242, -4.1528,  ..., -8.3585, -8.3004, -8.6101]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([61], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3835, -4.0569, -4.7644,  ..., -8.3782, -8.2273, -8.6080]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1410], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6054, -0.4722, -6.0360,  ..., -9.6479, -9.3311, -9.8695]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1263], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1455, -11.0784,  -0.1907,  ..., -11.8228, -11.9523, -11.5154]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1235, -10.0212,  -3.7649,  ..., -11.0039, -10.5914, -10.9948]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4630, -6.5272, -3.9965,  ..., -8.3938, -8.2750, -8.6295]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([206], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3416, -4.8064, -4.7625,  ..., -8.3063, -8.1907, -8.5674]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([186], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1079, -0.8890, -5.4868,  ..., -9.1410, -8.8322, -9.3873]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.3480, -11.1960,  -0.1307,  ..., -12.0529, -12.1747, -11.8395]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4591, -10.2060,  -4.1223,  ..., -11.3819, -10.8822, -11.3801]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4043, -6.2760, -4.1986,  ..., -8.4309, -8.2532, -8.6747]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([890], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2216, -5.2697, -5.5362,  ..., -8.2467, -8.2075, -8.6044]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([198], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0100, -1.0093, -5.9242,  ..., -9.0838, -8.7481, -9.3548]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([890], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6186, -10.2790,  -0.6129,  ..., -11.2419, -11.4168, -11.0280]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([75], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7077,  -9.3201,  -4.3287,  ..., -10.5925, -10.1519, -10.6311]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4927, -6.1615, -4.7545,  ..., -8.4856, -8.3611, -8.7331]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([857], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3948, -4.5714, -5.8318,  ..., -8.4647, -8.3022, -8.7140]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([744], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3769, -0.7481, -6.5177,  ..., -9.4927, -9.1439, -9.6800]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([84], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1556,  -9.6341,  -1.8125,  ..., -10.8350, -10.9835, -10.5628]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.9278, -7.1571, -4.7289,  ..., -9.8971, -9.4360, -9.6709]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8506, -4.6614, -5.8035,  ..., -8.9196, -8.4986, -8.9854]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([151], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.7804, -0.6120, -6.9742,  ..., -9.8985, -9.4504, -9.9803]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([116], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.2889, -10.0479,  -2.3230,  ..., -10.9760, -11.0873, -10.7555]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0990,  -7.9402,  -5.0819,  ..., -10.0685,  -9.5916,  -9.8954]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7236, -5.5440, -6.0208,  ..., -8.7918, -8.3857, -8.8858]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([237], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7304, -4.3764, -6.7898,  ..., -8.8091, -8.4156, -8.9832]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5707, -0.7872, -7.3232,  ..., -9.6942, -9.2725, -9.8119]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([432], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1924, -10.4203,  -2.1152,  ..., -10.8698, -11.0148, -10.5111]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.9057, -8.1733, -4.7205,  ..., -9.8244, -9.3995, -9.5764]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7138, -5.9560, -5.7651,  ..., -8.7319, -8.3488, -8.8081]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6179, -4.8658, -6.6091,  ..., -8.6746, -8.3103, -8.8657]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([151], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1597, -1.1803, -6.9527,  ..., -9.2435, -8.8705, -9.4252]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([28], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4385, -10.7120,  -2.5389,  ..., -11.0287, -11.2831, -10.8067]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.2562,  -8.7893,  -5.1335,  ..., -10.1570,  -9.8008,  -9.9900]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7801, -6.5534, -5.8758,  ..., -8.7880, -8.4698, -8.9212]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([198], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4862, -5.2324, -6.5526,  ..., -8.5671, -8.2754, -8.7128]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8902, -1.6426, -6.7484,  ..., -8.9750, -8.6293, -9.1493]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4713, -10.0379,  -2.7682,  ..., -11.1514, -11.3008, -10.8677]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.5100,  -7.9781,  -5.9335,  ..., -10.5392,  -9.9874, -10.2520]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8176, -5.2497, -6.3275,  ..., -8.9398, -8.4612, -8.9908]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7889, -4.0865, -7.2226,  ..., -8.9103, -8.4640, -9.0755]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([19], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8468,  -0.5788,  -7.9663,  ...,  -9.9815,  -9.5176, -10.1298]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6848, -10.5280,  -3.0843,  ..., -11.3072, -11.4876, -11.0462]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6495,  -8.4025,  -6.0596,  ..., -10.6185, -10.0657, -10.3545]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9859, -5.8225, -6.3592,  ..., -9.0828, -8.5858, -9.1039]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([270], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9520, -4.9240, -7.2641,  ..., -9.1042, -8.6616, -9.2340]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([558], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6391, -1.2940, -7.7169,  ..., -9.8207, -9.3686, -9.9327]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7259,  -0.4516,  -8.6512,  ..., -10.8993, -10.4586, -10.9614]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4929, -10.4851,  -2.1619,  ..., -11.1542, -11.3500, -10.8208]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0769,  -7.5566,  -4.4392,  ...,  -9.9236,  -9.7207,  -9.8068]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6653, -5.4820, -5.8898,  ..., -8.6434, -8.3641, -8.7647]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([64], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4878, -4.5617, -6.9839,  ..., -8.5576, -8.3012, -8.7561]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5809, -0.5636, -7.6515,  ..., -9.7232, -9.3283, -9.8296]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6556, -10.2988,  -2.5952,  ..., -11.2374, -11.4173, -10.9379]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.2503,  -7.9036,  -5.4398,  ..., -10.2169,  -9.7229,  -9.8924]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7630, -5.1798, -6.5213,  ..., -8.8202, -8.3773, -8.8052]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.8295, -0.5311, -7.6212,  ..., -9.9615, -9.5041, -9.9775]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([31], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5473, -10.4265,  -1.8249,  ..., -11.1981, -11.3788, -10.8740]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.4774,  -8.6862,  -5.1662,  ..., -10.4335,  -9.9466, -10.1276]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7566, -5.6856, -6.2680,  ..., -8.7548, -8.3996, -8.8483]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([151], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7159, -4.1442, -7.0772,  ..., -8.7460, -8.4632, -8.8769]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([41], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0847,  -0.4647,  -8.0860,  ..., -10.1688,  -9.7876, -10.2931]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([739], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.0745, -11.2737,  -2.3606,  ..., -11.7192, -11.9057, -11.3627]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.8381,  -9.4773,  -5.5563,  ..., -10.7935, -10.2727, -10.4623]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7698, -6.3743, -6.1179,  ..., -8.7895, -8.3980, -8.8804]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6301, -4.6693, -6.7671,  ..., -8.6145, -8.3561, -8.7852]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([695], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5437, -0.7635, -7.4166,  ..., -9.5929, -9.2410, -9.7522]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([41], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.2533, -11.6812,  -2.6984,  ..., -11.9189, -12.1529, -11.6215]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9913,  -9.9248,  -5.7383,  ..., -10.9914, -10.4925, -10.6863]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9055, -6.9896, -6.2616,  ..., -8.9462, -8.5633, -9.0265]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([33], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6588, -5.2181, -6.6967,  ..., -8.6947, -8.3882, -8.7999]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2462, -1.1749, -7.0879,  ..., -9.3286, -8.9552, -9.4769]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.0998, -11.0225,  -0.2678,  ..., -11.8211, -11.9524, -11.4930]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6439, -10.6686,  -5.0917,  ..., -11.6343, -11.1326, -11.5097]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7395, -6.2787, -5.2221,  ..., -8.7410, -8.5769, -8.9376]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([345], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6559, -4.4424, -6.1721,  ..., -8.7043, -8.4331, -8.8944]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1002,  -0.3897,  -7.3706,  ..., -10.1941,  -9.7760, -10.3846]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-11.5562, -10.5113,  -1.2374,  ..., -11.2151, -11.4149, -10.8753]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3425, -6.9282, -4.2076,  ..., -9.2588, -8.9038, -9.0854]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6988, -4.5970, -5.4572,  ..., -8.7827, -8.4401, -8.7605]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([525], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7403, -3.4194, -6.6791,  ..., -8.8540, -8.5548, -8.9538]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([182], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7500,  -0.1860,  -8.4240,  ..., -10.8662, -10.4343, -10.9985]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3269, -10.5146,  -1.1191,  ..., -11.0128, -11.1919, -10.6705]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4224, -7.5745, -4.4239,  ..., -9.3855, -9.0254, -9.2023]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3474, -5.7777, -6.1533,  ..., -8.4874, -8.3524, -8.6010]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1688], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3682, -4.3273, -7.0929,  ..., -8.5205, -8.3536, -8.7088]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1255,  -0.2862,  -8.3713,  ..., -10.2902,  -9.8837, -10.4725]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([430], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6703, -10.9066,  -0.8018,  ..., -11.3228, -11.5736, -10.9916]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6135, -10.0240,  -5.1333,  ..., -10.5890, -10.1352, -10.4636]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4538, -6.8120, -5.8519,  ..., -8.4987, -8.3791, -8.6864]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([67], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3584, -5.2285, -6.7765,  ..., -8.4762, -8.2668, -8.6716]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([486], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4850, -0.6324, -7.5505,  ..., -9.6300, -9.2143, -9.8151]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1781, -10.7748,  -1.0520,  ..., -10.9126, -11.1369, -10.5544]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6197, -10.5128,  -5.5228,  ..., -10.6181, -10.1505, -10.4953]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5856, -6.9090, -6.0502,  ..., -8.6545, -8.3026, -8.8513]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([388], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4588, -5.4729, -6.6776,  ..., -8.5573, -8.2347, -8.7507]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3143, -0.8754, -6.9647,  ..., -9.4115, -8.9996, -9.5930]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([33], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4148, -11.2037,  -0.5240,  ..., -11.1158, -11.2676, -10.8269]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.8110, -10.8846,  -5.1360,  ..., -10.7757, -10.3029, -10.6772]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4846, -7.7039, -5.7835,  ..., -8.5283, -8.3987, -8.7537]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([172], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3461, -6.2773, -6.3800,  ..., -8.4023, -8.2679, -8.6460]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9401, -1.4086, -6.4915,  ..., -9.0073, -8.6704, -9.2260]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5116, -10.4727,  -1.7809,  ..., -11.1822, -11.4218, -10.8077]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7794,  -9.1751,  -5.9887,  ..., -10.8063, -10.3070, -10.4777]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7940, -5.5665, -6.5863,  ..., -8.8636, -8.4910, -8.9492]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.7725, -0.6711, -7.3253,  ..., -9.8324, -9.4118, -9.9587]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([522], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5945, -10.9262,  -0.7111,  ..., -11.2295, -11.5109, -10.9477]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9855, -10.6119,  -5.5484,  ..., -10.9351, -10.5168, -10.8804]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5649, -7.0982, -5.9706,  ..., -8.6112, -8.5126, -8.8036]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([824], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5450, -5.7285, -6.5254,  ..., -8.6255, -8.4679, -8.8315]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([380], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4441, -0.8805, -7.0440,  ..., -9.5039, -9.1531, -9.7293]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.2713, -10.7853,  -1.0760,  ..., -11.0478, -11.2419, -10.6273]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0736, -10.8352,  -6.0746,  ..., -11.1211, -10.6359, -10.9412]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7401, -7.1019, -6.3867,  ..., -8.8741, -8.5230, -9.0351]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1826], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7568, -5.7468, -7.1460,  ..., -8.9124, -8.5935, -9.0719]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([562], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6113, -1.3751, -7.4881,  ..., -9.7501, -9.3033, -9.9058]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([677], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9522,  -0.4033,  -8.6205,  ..., -11.0798, -10.5855, -11.1714]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([145], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4876, -11.6122,  -0.5098,  ..., -11.1199, -11.3798, -10.7925]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1751, -11.6628,  -5.5611,  ..., -11.0754, -10.6938, -10.9414]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4089, -8.1324, -5.7551,  ..., -8.4008, -8.3518, -8.5919]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3017, -6.8075, -6.4453,  ..., -8.3146, -8.2754, -8.6132]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7714, -2.3860, -6.2471,  ..., -8.7935, -8.5400, -9.0357]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([461], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4672, -0.9059, -6.8549,  ..., -9.5196, -9.1869, -9.6700]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7889, -12.0429,  -0.3126,  ..., -11.4558, -11.7205, -11.1475]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3360, -12.0165,  -5.3984,  ..., -11.2734, -10.8448, -11.1591]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5971, -8.4983, -5.6841,  ..., -8.6260, -8.5041, -8.8549]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([201], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4552, -7.2315, -6.4999,  ..., -8.5641, -8.3753, -8.8187]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([277], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9949, -3.2625, -6.3963,  ..., -9.0976, -8.7614, -9.3167]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6548, -1.6454, -6.8399,  ..., -9.7597, -9.3360, -9.9149]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5060, -11.2587,  -0.9644,  ..., -11.1598, -11.4026, -10.8770]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1467, -11.2820,  -5.9030,  ..., -11.0784, -10.6245, -10.9902]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6560, -7.7590, -6.1100,  ..., -8.6759, -8.4336, -8.9484]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([838], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5601, -6.3895, -6.8601,  ..., -8.6729, -8.4362, -8.9018]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2644, -2.0468, -7.0669,  ..., -9.3668, -8.9545, -9.5708]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-11.5595, -10.4251,  -2.7238,  ..., -11.1780, -11.4006, -10.8453]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9195,  -9.5472,  -6.5707,  ..., -10.9049, -10.4290, -10.6010]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5527, -6.0112, -6.9836,  ..., -8.6045, -8.3287, -8.7947]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4775, -4.6045, -7.4443,  ..., -8.5543, -8.3239, -8.7745]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([236], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.9989,  -0.3669,  -8.3896,  ..., -10.0407,  -9.7071, -10.2819]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([564], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.7438, -11.7124,  -3.3528,  ..., -12.3538, -12.6017, -12.0608]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6987, -10.3356,  -7.2076,  ..., -11.6780, -11.1648, -11.4046]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6025, -5.9127, -7.0749,  ..., -8.6564, -8.3635, -8.8690]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([151], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5621, -4.5831, -7.8246,  ..., -8.6478, -8.4497, -8.8974]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([451], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0078,  -0.4180,  -8.5436,  ..., -10.0556,  -9.7210, -10.2826]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-13.0837, -12.3625,  -3.6301,  ..., -12.7131, -12.9567, -12.4352]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.8156, -11.0089,  -7.3274,  ..., -11.8048, -11.2886, -11.5556]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5501, -6.6659, -6.8385,  ..., -8.6202, -8.3360, -8.8525]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4052, -5.4372, -7.3078,  ..., -8.4656, -8.3337, -8.7728]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([570], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3889, -0.8103, -7.6498,  ..., -9.4109, -9.1281, -9.6710]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5473, -11.0091,  -1.1843,  ..., -11.1771, -11.4651, -10.9002]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9236, -10.1504,  -5.7988,  ..., -10.9268, -10.4556, -10.6697]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5493, -6.6212, -6.6108,  ..., -8.6352, -8.3771, -8.8670]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([606], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4740, -5.5469, -7.4440,  ..., -8.5899, -8.3529, -8.8668]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([850], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4277, -0.9675, -7.7035,  ..., -9.5029, -9.1689, -9.7504]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1538, -11.6573,  -2.6024,  ..., -11.8360, -12.1482, -11.4119]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.9184, -8.4424, -5.2815,  ..., -9.7949, -9.5128, -9.5620]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4900, -5.9555, -5.7196,  ..., -8.5607, -8.3401, -8.5462]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3246, -4.5876, -6.3401,  ..., -8.4485, -8.2441, -8.5059]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([703], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.7775,  -0.4104,  -7.7778,  ...,  -9.8740,  -9.5465, -10.0080]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([517], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1002, -10.3487,  -1.3641,  ..., -10.8235, -11.0234, -10.4539]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1517, -10.7538,  -6.6745,  ..., -11.1561, -10.6823, -11.0361]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3787, -6.5534, -6.7823,  ..., -8.5387, -8.3614, -8.7047]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([558], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4316, -5.3918, -7.5416,  ..., -8.6069, -8.3835, -8.7988]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.7970,  -0.5541,  -8.1360,  ...,  -9.8927,  -9.5238, -10.0958]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3171, -10.3149,  -2.1750,  ..., -11.0368, -11.2884, -10.6702]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3876, -6.1012, -5.0653,  ..., -9.1933, -9.0029, -9.2706]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7619, -4.6238, -7.4175,  ..., -8.8045, -8.5418, -9.0746]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([525], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7906,  -0.2709,  -9.0361,  ..., -10.8822, -10.4462, -11.0467]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([208], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4987, -10.7152,  -0.8110,  ..., -11.1254, -11.3587, -10.7997]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3602, -10.8750,  -6.4069,  ..., -11.3209, -10.8111, -11.2128]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4907, -6.1469, -6.6221,  ..., -8.6585, -8.4793, -8.8629]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([327], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6628, -4.6563, -7.4572,  ..., -8.8330, -8.6454, -9.0713]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.4507,  -0.3028,  -8.6443,  ..., -10.5510, -10.1444, -10.7671]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6480, -11.0765,  -1.8032,  ..., -11.3072, -11.5880, -11.0371]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.7167, -8.3348, -5.0947,  ..., -9.6000, -9.2513, -9.4880]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4904, -5.6577, -5.5996,  ..., -8.5149, -8.3001, -8.5940]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3997, -4.4995, -6.4813,  ..., -8.4684, -8.2829, -8.6209]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([130], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1617,  -0.2843,  -8.1658,  ..., -10.1988,  -9.9008, -10.4024]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([878], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.8740, -11.4977,  -2.3842,  ..., -11.5194, -11.7771, -11.2435]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.7472, -8.4927, -5.3481,  ..., -9.6511, -9.2307, -9.5144]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6386, -5.4595, -6.3510,  ..., -8.6819, -8.4485, -8.6891]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6423, -3.9925, -7.1462,  ..., -8.7315, -8.5486, -8.8177]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([230], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1046,  -0.3960,  -8.3113,  ..., -10.1825,  -9.8158, -10.3282]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.9660, -11.6736,  -2.6681,  ..., -11.5330, -11.8230, -11.2871]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6251, -11.4178,  -7.2932,  ..., -11.6162, -11.0540, -11.3769]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-8.6034, -7.5774, -7.2268,  ..., -8.7103, -8.3914, -8.9763]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([406], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6747, -6.1213, -7.9416,  ..., -8.7583, -8.5034, -9.0579]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5003, -1.3541, -8.1375,  ..., -9.5908, -9.1717, -9.8533]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1192], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7344,  -0.3840,  -9.1405,  ..., -10.8283, -10.3878, -11.0306]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3819, -11.2220,  -1.5276,  ..., -11.0211, -11.2422, -10.7595]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([75], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.2627, -11.2199,  -6.4841,  ..., -11.2967, -10.7310, -10.9955]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4956, -7.5343, -6.6759,  ..., -8.5844, -8.3347, -8.8482]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4328, -6.3992, -7.4399,  ..., -8.5387, -8.3465, -8.8168]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1605, -1.5185, -7.1636,  ..., -9.1783, -8.8535, -9.4536]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1926], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4689, -11.4827,  -1.5706,  ..., -11.0706, -11.3931, -10.8261]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([75], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0467, -11.2023,  -6.3383,  ..., -11.0824, -10.5432, -10.8449]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5797, -7.8627, -6.7334,  ..., -8.6586, -8.3632, -8.9532]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1230], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4677, -6.4891, -7.1692,  ..., -8.5827, -8.3979, -8.8821]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1721], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0794, -1.8514, -6.9969,  ..., -9.0538, -8.8039, -9.3801]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7255, -11.2127,  -2.2651,  ..., -11.3344, -11.6086, -11.0756]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0717, -10.5156,  -6.8047,  ..., -11.1364, -10.5416, -10.8897]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5587, -6.8107, -7.1935,  ..., -8.7075, -8.3409, -8.9745]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([445], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8198, -5.4912, -7.7965,  ..., -8.9898, -8.6856, -9.2251]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8797,  -0.8027,  -7.9255,  ...,  -9.9357,  -9.4975, -10.1699]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.9168, -11.1535,  -2.6712,  ..., -11.5919, -11.8869, -11.3757]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1471, -10.1112,  -7.0098,  ..., -11.2494, -10.6733, -11.0383]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5716, -6.1075, -7.4090,  ..., -8.7662, -8.3800, -9.0308]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([522], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6707, -0.8328, -7.6030,  ..., -9.6674, -9.3118, -9.9442]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([618], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6903, -11.1995,  -1.2341,  ..., -11.3391, -11.6076, -11.0407]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0212, -10.5716,  -6.1926,  ..., -11.0864, -10.5214, -10.8416]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5011, -6.9676, -6.8383,  ..., -8.6264, -8.3104, -8.9090]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0754, -1.6401, -6.6668,  ..., -9.0753, -8.8148, -9.3625]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.2876, -10.8736,  -1.5591,  ..., -10.9647, -11.2128, -10.7446]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.9427, -8.8617, -5.1506,  ..., -9.8459, -9.4828, -9.7705]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4837, -6.4889, -5.6183,  ..., -8.5350, -8.3213, -8.6745]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4203, -5.2928, -6.2376,  ..., -8.4917, -8.3054, -8.6795]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([201], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3543, -0.9092, -6.8658,  ..., -9.3635, -9.1053, -9.5926]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([130], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.9061, -11.7773,  -2.3150,  ..., -11.5729, -11.8387, -11.3519]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.5677,  -9.7729,  -5.8049,  ..., -10.4072, -10.1371, -10.4957]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6208, -7.1611, -6.9554,  ..., -8.6907, -8.4257, -9.0638]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([11], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5518, -5.9034, -7.4527,  ..., -8.7026, -8.4474, -8.9969]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1224], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2986, -1.0899, -7.3954,  ..., -9.3278, -8.9834, -9.6304]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.8827, -11.8973,  -0.9657,  ..., -11.5672, -11.8620, -11.2202]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.8498, -12.3529,  -6.7357,  ..., -11.8296, -11.3393, -11.7397]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4879, -7.5691, -6.4647,  ..., -8.6891, -8.5070, -8.9181]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4879, -5.9125, -6.9158,  ..., -8.7243, -8.5386, -8.9849]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([165], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2953, -1.1596, -6.4864,  ..., -9.3549, -9.0385, -9.6414]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.9032, -11.3937,  -1.1180,  ..., -11.5747, -11.8160, -11.3140]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.2125, -10.6831,  -6.1472,  ..., -11.2821, -10.6778, -11.0471]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6400, -6.9105, -6.8007,  ..., -8.8103, -8.4045, -9.0749]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([871], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7120, -5.7383, -7.6615,  ..., -8.9241, -8.6307, -9.2136]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([483], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.6678,  -0.8962,  -7.3037,  ...,  -9.7217,  -9.3882, -10.0352]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7451, -11.5722,  -1.4578,  ..., -11.3659, -11.6315, -11.0473]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.9795, -9.5664, -4.9251,  ..., -9.8526, -9.4619, -9.6618]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6655, -6.7827, -5.9728,  ..., -8.7234, -8.4676, -8.7345]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([296], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5695, -5.3286, -6.8317,  ..., -8.6702, -8.4991, -8.7471]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4013, -1.0175, -6.7249,  ..., -9.4522, -9.1488, -9.6438]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([145], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.3730, -12.4534,  -0.5704,  ..., -12.0581, -12.2715, -11.6566]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0660, -11.6808,  -5.4597,  ..., -11.0229, -10.4937, -10.9099]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3939, -8.0827, -6.2239,  ..., -8.6123, -8.4195, -8.8125]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([769], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4361, -6.4436, -6.9548,  ..., -8.6413, -8.4302, -8.8985]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([350], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1271, -1.6443, -6.5046,  ..., -9.1626, -8.8558, -9.4741]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([736], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-11.7835, -11.5641,  -0.6397,  ..., -11.4371, -11.7113, -11.0767]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3574, -11.5660,  -6.1456,  ..., -11.3366, -10.8837, -11.2255]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4296, -7.5734, -6.2124,  ..., -8.6143, -8.4701, -8.8025]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([246], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2654, -6.1654, -7.0223,  ..., -8.4327, -8.2999, -8.7208]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([98], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0684, -1.1468, -6.6386,  ..., -9.0918, -8.8469, -9.3863]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([48], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.0033, -11.9405,  -1.2542,  ..., -11.6744, -11.9559, -11.2491]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1853,  -9.7397,  -4.9257,  ..., -10.1150,  -9.7115,  -9.8633]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5816, -7.1232, -5.4499,  ..., -8.7250, -8.3902, -8.7200]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([63], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4368, -5.2959, -6.5046,  ..., -8.6769, -8.3953, -8.8058]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4577, -0.8606, -6.7530,  ..., -9.4868, -9.1302, -9.6883]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6797, -11.2441,  -1.0000,  ..., -11.3739, -11.4964, -10.9577]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4496, -11.5224,  -6.5955,  ..., -11.4204, -10.8851, -11.2742]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3205, -7.5627, -6.6663,  ..., -8.5281, -8.4073, -8.7170]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1260], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2548, -6.0749, -7.5527,  ..., -8.4924, -8.3063, -8.7188]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([797], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1578, -0.9410, -7.1068,  ..., -9.2019, -8.9660, -9.4715]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2011], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.0760, -11.6488,  -0.7992,  ..., -11.7570, -12.0467, -11.4323]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.4921, -11.6644,  -6.2309,  ..., -11.4509, -11.0324, -11.4385]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3808, -7.3414, -6.1813,  ..., -8.5058, -8.4831, -8.8173]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1777], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2834, -5.7112, -7.1234,  ..., -8.4681, -8.4105, -8.7896]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([499], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.7839,  -0.4923,  -7.2750,  ...,  -9.7503,  -9.5508, -10.0640]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([816], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.9211, -11.7319,  -1.7090,  ..., -11.6163, -11.9047, -11.2782]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9960, -11.0884,  -6.2679,  ..., -11.1050, -10.5018, -10.7886]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5118, -7.6628, -6.9167,  ..., -8.6672, -8.3968, -8.9980]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3074, -6.2892, -7.5097,  ..., -8.4612, -8.2783, -8.8045]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([430], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1401, -1.1150, -7.0988,  ..., -9.1270, -8.9276, -9.4571]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1247, -11.6600,  -2.4114,  ..., -11.8419, -12.0641, -11.4922]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9603, -10.6462,  -6.2874,  ..., -11.0262, -10.4663, -10.7493]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([564], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8403, -6.5729, -6.3897,  ..., -8.9155, -8.6440, -8.9435]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([538], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5645, -4.8376, -7.1714,  ..., -8.6826, -8.5465, -8.8161]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([890], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.9227,  -0.4532,  -7.7525,  ...,  -9.9498,  -9.7274, -10.1749]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([394], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.3430, -11.8523,  -2.1108,  ..., -12.0057, -12.1655, -11.6714]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.5760, -10.1588,  -5.9385,  ..., -10.6393, -10.0006, -10.3601]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4670, -7.2648, -7.1542,  ..., -8.6796, -8.3103, -8.9939]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3377, -5.9152, -7.7377,  ..., -8.5503, -8.3689, -8.9077]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([44], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4452, -0.7420, -7.6634,  ..., -9.5178, -9.2512, -9.7965]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([878], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.6756, -12.3799,  -2.6035,  ..., -12.3536, -12.5238, -12.0455]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.8818, -10.8043,  -6.2419,  ..., -10.9712, -10.3061, -10.6641]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6382, -7.0321, -6.2838,  ..., -8.8774, -8.5143, -8.9079]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4679, -5.0780, -7.1571,  ..., -8.6407, -8.3899, -8.7277]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4421, -0.8017, -7.3905,  ..., -9.5166, -9.2265, -9.6894]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1162], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.2105, -12.2145,  -2.2771,  ..., -11.8478, -12.1120, -11.6018]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0316, -11.2295,  -6.5137,  ..., -11.0995, -10.4849, -10.8441]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8684, -7.4088, -6.7494,  ..., -8.9314, -8.6321, -9.0346]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6491, -5.5784, -7.5675,  ..., -8.7156, -8.5638, -8.9427]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([487], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6087, -4.6112, -7.7921,  ..., -8.6456, -8.5264, -8.8702]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([228], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5961, -0.7181, -7.8408,  ..., -9.6219, -9.3625, -9.8835]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.4517, -12.5321,  -2.7541,  ..., -12.1530, -12.3486, -11.8687]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0036, -11.3805,  -6.6110,  ..., -11.1186, -10.4605, -10.8337]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6772, -8.5511, -7.3354,  ..., -8.8747, -8.4738, -9.2113]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1551], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3945, -7.2331, -7.8627,  ..., -8.5927, -8.3595, -8.9819]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9340, -2.4491, -7.3661,  ..., -9.0434, -8.7551, -9.3720]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([505], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8766,  -0.7065,  -7.9253,  ...,  -9.9596,  -9.6133, -10.2092]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([145], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1773, -12.5925,  -1.1416,  ..., -11.8502, -12.0782, -11.5378]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9256, -11.7272,  -5.4254,  ..., -10.9630, -10.3905, -10.6960]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5699, -8.9522, -6.4703,  ..., -8.7396, -8.5408, -8.9516]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3828, -7.7526, -7.0775,  ..., -8.6021, -8.4451, -8.8955]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([155], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8827, -3.0221, -6.7512,  ..., -8.9893, -8.7126, -9.2905]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([695], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4500, -1.3128, -6.9255,  ..., -9.4934, -9.2141, -9.7325]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([19], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1152, -11.8007,  -0.3643,  ..., -11.7847, -11.9638, -11.3910]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.9137, -11.4867,  -5.3593,  ..., -10.9192, -10.3468, -10.8157]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4467, -8.5096, -6.3964,  ..., -8.6616, -8.5298, -8.9646]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([201], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2761, -7.1577, -6.8918,  ..., -8.5532, -8.4118, -8.8721]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([717], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8414, -2.3219, -6.5384,  ..., -8.9792, -8.7029, -9.2615]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-12.0376, -12.1114,  -1.0672,  ..., -11.7013, -11.8733, -11.3679]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.1868, -11.9492,  -6.2481,  ..., -11.1785, -10.6132, -11.1031]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6815, -8.7701, -6.8278,  ..., -8.8976, -8.7000, -9.2244]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3142, -7.2717, -7.3479,  ..., -8.5220, -8.3871, -8.9215]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([499], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2985, -6.3274, -7.8056,  ..., -8.5129, -8.3852, -8.9526]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([797], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0679, -1.3157, -7.4403,  ..., -9.1754, -8.8639, -9.4873]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1683], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.5033, -12.8042,  -0.4660,  ..., -12.1583, -12.4365, -11.7991]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5818, -12.6353,  -6.0066,  ..., -11.5619, -11.0310, -11.4487]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8786, -9.1731, -6.5654,  ..., -9.0792, -8.8981, -9.3445]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([64], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3018, -7.5927, -7.1462,  ..., -8.5248, -8.4235, -8.8984]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2174, -6.6213, -7.6097,  ..., -8.4368, -8.3259, -8.8561]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.7949, -12.6781,  -0.2780,  ..., -12.4699, -12.6938, -12.1422]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7148, -11.9042,  -5.9990,  ..., -11.7374, -11.1284, -11.6326]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7659, -7.1203, -6.7321,  ..., -9.0263, -8.7433, -9.2973]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([938], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7454, -4.8327, -7.3241,  ..., -9.0359, -8.7401, -9.3390]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.7416,  -0.7326,  -7.4638,  ...,  -9.9240,  -9.4500, -10.1218]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.0883, -11.6895,  -0.8357,  ..., -11.7601, -11.9913, -11.4728]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.2463, -11.1469,  -6.4809,  ..., -11.3032, -10.7006, -11.1963]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6687, -6.8274, -7.1396,  ..., -8.8658, -8.4948, -9.2340]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([439], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6340, -4.9796, -7.9005,  ..., -8.8787, -8.5771, -9.2004]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([739], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8055,  -0.5930,  -7.9927,  ...,  -9.9024,  -9.5490, -10.1679]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([722], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.5695, -12.3896,  -0.3791,  ..., -12.2850, -12.4754, -11.8920]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.8646, -12.0741,  -6.3743,  ..., -11.8938, -11.2990, -11.7543]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5730, -7.3651, -6.7051,  ..., -8.7418, -8.5612, -9.0437]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([26], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5245, -5.6460, -7.5032,  ..., -8.7388, -8.5181, -9.0536]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1537, -1.3828, -7.2532,  ..., -9.1526, -8.9125, -9.4979]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([727], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-13.1225, -13.1495,  -0.2446,  ..., -12.7562, -13.0288, -12.4239]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1338, -12.5481,  -6.1312,  ..., -12.0973, -11.5677, -12.0219]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5326, -7.8457, -6.0829,  ..., -8.6363, -8.4501, -8.9688]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1350], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3552, -6.1501, -6.8874,  ..., -8.4999, -8.3477, -8.8899]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0458, -1.3586, -6.7614,  ..., -9.0403, -8.7980, -9.4180]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([246], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.2816, -12.4377,  -0.8048,  ..., -11.9879, -12.1787, -11.5835]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5724, -12.1731,  -6.3505,  ..., -11.5620, -11.0096, -11.4474]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4781, -8.0405, -6.5246,  ..., -8.6181, -8.4878, -8.9691]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1805], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3310, -6.3021, -7.1581,  ..., -8.5348, -8.3749, -8.9111]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([61], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9337, -1.7101, -6.8517,  ..., -8.9778, -8.7484, -9.3084]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([54], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.2823, -12.2381,  -0.9667,  ..., -11.9862, -12.2284, -11.6626]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6497, -11.9887,  -6.6069,  ..., -11.6516, -11.1331, -11.5815]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5274, -7.1864, -6.7879,  ..., -8.7111, -8.5458, -9.0597]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([388], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6284, -5.2173, -7.4105,  ..., -8.8966, -8.6556, -9.1985]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([487], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5389, -0.8781, -7.4761,  ..., -9.6612, -9.3054, -9.9239]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([98], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.6252, -12.7722,  -0.4319,  ..., -12.2574, -12.4782, -11.9527]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.8922, -12.5637,  -6.1531,  ..., -11.8099, -11.3183, -11.7875]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4211, -8.0353, -6.2253,  ..., -8.5473, -8.4681, -8.9647]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([493], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3479, -6.2372, -6.9300,  ..., -8.5498, -8.4378, -8.9663]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([39], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9313, -1.7356, -6.7260,  ..., -8.9712, -8.8034, -9.3403]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1252, -11.7557,  -1.6408,  ..., -11.7541, -12.0405, -11.4951]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7790, -11.3057,  -7.0257,  ..., -11.8062, -11.2380, -11.6020]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5305, -6.8189, -7.4349,  ..., -8.6600, -8.3679, -9.0855]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6089, -5.3855, -8.0593,  ..., -8.7904, -8.6028, -9.2168]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([663], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4165, -1.0829, -8.1033,  ..., -9.4848, -9.2285, -9.8411]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([769], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.0202, -11.9518,  -1.7718,  ..., -11.6728, -11.8824, -11.3533]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1635,  -9.6529,  -5.5740,  ..., -10.0910,  -9.6182,  -9.9285]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4595, -6.9453, -6.0300,  ..., -8.5746, -8.2888, -8.7477]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4632, -5.0150, -7.2724,  ..., -8.6530, -8.3792, -8.7686]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([696], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2120, -1.0403, -7.3961,  ..., -9.3111, -9.0759, -9.5339]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.9994, -12.0287,  -1.8295,  ..., -11.7181, -11.9321, -11.3977]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6066, -10.2116,  -6.0232,  ..., -10.5590, -10.0856, -10.4066]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5943, -7.3803, -7.3543,  ..., -8.8301, -8.4073, -9.1346]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([59], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7465, -5.9720, -8.0746,  ..., -9.0508, -8.7553, -9.3494]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5048, -1.7702, -8.0588,  ..., -9.6815, -9.2997, -9.9323]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.2680, -11.9697,  -2.2608,  ..., -11.9240, -12.1787, -11.6198]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.4368, -12.1299,  -8.0828,  ..., -12.4709, -11.8653, -12.2456]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6872, -6.8572, -7.6211,  ..., -8.8896, -8.4926, -9.2494]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8288, -5.2089, -8.1200,  ..., -9.0103, -8.7694, -9.3857]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([158], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8067,  -0.9112,  -8.3729,  ...,  -9.8881,  -9.5770, -10.1944]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([155], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.0140, -11.9427,  -1.0333,  ..., -11.6400, -11.8559, -11.3541]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7105, -12.0298,  -7.0052,  ..., -11.6366, -11.1151, -11.5953]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5393, -7.8138, -7.0692,  ..., -8.7030, -8.6101, -9.0606]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([709], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4357, -5.8982, -7.4448,  ..., -8.6644, -8.5751, -9.0676]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1417, -1.4083, -7.4053,  ..., -9.2322, -9.0254, -9.6080]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-12.3007, -11.8949,  -1.7122,  ..., -12.0229, -12.2390, -11.7091]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1471, -11.6195,  -7.3073,  ..., -12.2458, -11.6227, -12.0000]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7636, -6.7776, -7.1303,  ..., -8.9560, -8.6405, -9.3119]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([69], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8981, -4.8908, -7.7091,  ..., -9.1317, -8.9358, -9.4739]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([981], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8869,  -0.7475,  -7.9991,  ..., -10.0181,  -9.7467, -10.3066]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.9012, -12.7420,  -0.4518,  ..., -12.5520, -12.8648, -12.2371]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6893, -11.9172,  -5.7256,  ..., -11.6534, -11.1464, -11.5566]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7880, -7.6675, -6.0421,  ..., -8.9790, -8.6759, -9.3507]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2195], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4400, -5.6803, -6.1008,  ..., -8.6654, -8.5126, -9.0279]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2599], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.2889, -0.9450, -5.8109,  ..., -9.3597, -9.1851, -9.6959]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-13.6967, -13.7299,  -0.1301,  ..., -13.3998, -13.6821, -13.0124]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.4809, -13.1934,  -5.5786,  ..., -12.4373, -11.9956, -12.3428]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4003, -8.0656, -5.0727,  ..., -8.5197, -8.5296, -8.8693]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([796], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2518, -6.2963, -5.2606,  ..., -8.3965, -8.3585, -8.7721]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.2877, -5.0880, -5.6599,  ..., -8.3858, -8.3455, -8.8163]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([889], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4742, -0.7073, -5.2759,  ..., -9.3551, -9.2489, -9.7261]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1837, -11.5093,  -0.5830,  ..., -11.8277, -12.0705, -11.4042]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6807, -11.9093,  -6.1625,  ..., -11.6227, -11.1818, -11.5351]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3732, -7.5819, -5.9707,  ..., -8.4760, -8.5136, -8.8247]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([653], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3463, -6.0662, -6.2727,  ..., -8.4581, -8.4465, -8.8207]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1907, -1.1968, -5.5954,  ..., -9.1331, -9.0326, -9.4585]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1581], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.7254, -12.8174,  -1.4037,  ..., -12.4230, -12.6506, -12.0503]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.3250, -11.6627,  -5.7338,  ..., -11.3843, -10.7693, -11.0834]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5882, -8.1240, -6.2215,  ..., -8.7230, -8.4075, -9.0646]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1848], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3735, -6.4671, -6.5849,  ..., -8.5262, -8.3118, -8.8498]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([532], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1160, -1.3276, -5.8693,  ..., -9.0891, -8.9164, -9.3986]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2222], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-13.1050, -13.2013,  -0.3008,  ..., -12.7409, -12.9331, -12.4426]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5502, -12.2882,  -5.3827,  ..., -11.5166, -10.9728, -11.4724]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5344, -7.1889, -5.6845,  ..., -8.7003, -8.5537, -9.0830]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7456, -5.4358, -5.8351,  ..., -8.8929, -8.6418, -9.1883]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([847], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8854,  -0.6751,  -5.8476,  ...,  -9.8814,  -9.5702, -10.1957]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-13.0204, -13.2096,  -1.0370,  ..., -12.6257, -12.8740, -12.3149]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.4803, -10.1873,  -4.7383,  ..., -10.4267,  -9.8783, -10.2348]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7703, -6.8632, -5.1541,  ..., -8.9041, -8.4452, -8.9912]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([333], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0466, -5.6743, -5.8902,  ..., -9.1332, -8.7694, -9.2873]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8933,  -1.0887,  -5.9926,  ...,  -9.9206,  -9.5335, -10.1301]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-13.1921, -12.7963,  -2.1186,  ..., -12.7980, -13.0242, -12.5039]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7657, -11.2820,  -6.4762,  ..., -11.7915, -11.1034, -11.5221]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6820, -6.9919, -6.7984,  ..., -8.8665, -8.4869, -9.2084]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([155], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.0675, -4.1685, -7.5059,  ..., -9.2380, -8.8619, -9.4046]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([49], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.7632,  -0.3401,  -7.7198,  ..., -10.7914, -10.4812, -10.9752]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-13.3053, -13.2468,  -2.5045,  ..., -12.9617, -13.2849, -12.6379]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7008, -11.8230,  -6.4968,  ..., -11.7361, -11.1316, -11.4566]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([40], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6847, -7.9610, -6.6379,  ..., -8.8200, -8.4675, -9.1347]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([246], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7903, -5.6880, -7.2945,  ..., -8.9265, -8.6943, -9.1288]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2093], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6700, -1.4848, -7.0224,  ..., -9.6809, -9.4796, -9.9530]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([186], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0178,  -0.4293,  -7.7711,  ..., -10.9506, -10.7716, -11.1486]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.3425, -12.4531,  -2.1908,  ..., -11.9382, -12.1999, -11.5852]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.4444, -10.2590,  -5.5125,  ..., -10.2725,  -9.8314, -10.0754]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.5223, -7.8126, -5.6407,  ..., -8.5739, -8.3364, -8.7166]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5743, -6.4257, -6.6088,  ..., -8.5596, -8.4056, -8.7224]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([44], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1710, -2.1138, -6.0919,  ..., -9.1539, -8.9525, -9.3471]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([148], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0532,  -0.8312,  -6.5400,  ..., -10.0248,  -9.8159, -10.1750]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([564], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-13.2841, -13.4191,  -2.9169,  ..., -12.9375, -13.1516, -12.6448]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([75], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7731, -12.0177,  -6.8319,  ..., -11.8302, -11.1217, -11.5296]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7595, -8.1202, -6.9742,  ..., -8.9324, -8.5422, -9.2520]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([42], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7834, -5.7242, -7.2774,  ..., -8.9150, -8.5997, -9.0926]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([44], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4106, -1.5673, -6.5333,  ..., -9.4060, -9.1740, -9.5953]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([87], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.6197, -12.8938,  -2.3743,  ..., -12.2727, -12.5127, -11.9535]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.5651, -10.5865,  -5.7108,  ..., -10.4458,  -9.9407, -10.2590]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7612, -7.4850, -6.1994,  ..., -8.7706, -8.5528, -8.8689]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([986], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5248, -5.7344, -6.9005,  ..., -8.6389, -8.4560, -8.7430]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5168, -4.5833, -7.3543,  ..., -8.6502, -8.4953, -8.7696]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1960], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4288, -0.8997, -6.8173,  ..., -9.3883, -9.2491, -9.5840]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([238], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.4186, -12.9456,  -1.0796,  ..., -12.1113, -12.3522, -11.8288]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.0292, -12.2609,  -5.8801,  ..., -11.0323, -10.5030, -10.9874]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8170, -8.1244, -5.4031,  ..., -8.8824, -8.4971, -9.0572]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2164], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6210, -6.1982, -6.6053,  ..., -8.7667, -8.4673, -8.8998]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([739], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5992, -5.2776, -7.1891,  ..., -8.6225, -8.4841, -8.7931]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2165], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3529, -1.1734, -6.4463,  ..., -9.3002, -9.1036, -9.5037]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.7835, -12.8474,  -1.4518,  ..., -12.3983, -12.6103, -12.1010]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.2822, -11.5847,  -5.8470,  ..., -11.2923, -10.6368, -11.0163]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6389, -8.2504, -6.5239,  ..., -8.6849, -8.4150, -9.0889]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1055], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4603, -5.9969, -6.9672,  ..., -8.5631, -8.3803, -8.7679]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1201], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5970, -4.9173, -6.8115,  ..., -8.6355, -8.4299, -8.7843]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4467, -0.8670, -6.4171,  ..., -9.3998, -9.2373, -9.5978]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-13.0884, -13.1145,  -0.4867,  ..., -12.7164, -13.0058, -12.3949]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.8178, -12.3885,  -5.9802,  ..., -11.7656, -11.2506, -11.6854]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4849, -7.6584, -5.9669,  ..., -8.6165, -8.5679, -9.0197]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4649, -5.0926, -6.8537,  ..., -8.6068, -8.5368, -8.9082]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([796], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.6310, -0.6481, -6.5251,  ..., -9.6515, -9.5613, -9.9172]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([518], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.7159, -12.7959,  -1.0327,  ..., -12.4096, -12.6152, -12.1143]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([14], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.1283, -10.0820,  -4.3894,  ..., -10.0137,  -9.5809,  -9.8656]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([15], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4921, -7.4688, -5.0567,  ..., -8.5439, -8.3115, -8.7202]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1062], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3262, -5.7695, -6.4383,  ..., -8.4547, -8.3275, -8.6425]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([186], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4597, -4.7276, -6.7359,  ..., -8.5377, -8.3305, -8.6561]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([643], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.5669, -0.6188, -6.4732,  ..., -9.5080, -9.3701, -9.7363]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.6147, -12.5674,  -1.5005,  ..., -12.2263, -12.4574, -11.8753]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.6156, -10.0636,  -5.4680,  ..., -10.5283,  -9.9203, -10.2983]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7486, -6.4922, -5.6267,  ..., -8.7938, -8.3348, -8.8831]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([44], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9109, -4.8851, -7.0199,  ..., -8.9237, -8.5528, -9.0462]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.2242,  -0.5264,  -7.2035,  ..., -10.2001,  -9.8315, -10.3745]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.5479, -12.3712,  -1.7894,  ..., -12.1510, -12.4213, -11.8703]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.2015, -11.1672,  -6.3203,  ..., -11.2027, -10.5820, -10.9972]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5766, -7.6513, -7.0320,  ..., -8.6792, -8.4269, -9.0695]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([102], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5324, -5.8885, -7.1490,  ..., -8.6895, -8.5049, -9.0377]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4647, -1.0819, -6.7962,  ..., -9.4577, -9.3056, -9.7494]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([782], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.9035, -12.9160,  -0.8847,  ..., -12.4565, -12.7489, -12.1354]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.9255, -12.8204,  -6.4346,  ..., -11.8373, -11.2707, -11.7580]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5841, -8.3375, -6.1727,  ..., -8.6330, -8.5424, -9.0142]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([294], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3693, -6.2715, -6.3087,  ..., -8.4775, -8.3662, -8.8316]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([561], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.4055, -4.8899, -6.7858,  ..., -8.5168, -8.3789, -8.8907]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([146], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.7811,  -0.4735,  -6.9768,  ...,  -9.7067,  -9.5560, -10.0609]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.5240, -12.7547,  -1.0980,  ..., -12.1566, -12.3984, -11.8044]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7166, -12.7203,  -6.5964,  ..., -11.6632, -11.0635, -11.5627]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6367, -8.3062, -6.6580,  ..., -8.7416, -8.5643, -9.0884]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([19], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5745, -5.9183, -6.8170,  ..., -8.8089, -8.5418, -9.0745]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([151], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.4834, -1.0532, -6.6749,  ..., -9.5166, -9.2429, -9.7997]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.6094, -12.7073,  -1.2235,  ..., -12.1799, -12.4142, -11.9454]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.5080, -11.4793,  -6.2507,  ..., -11.5770, -10.7683, -11.2859]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8318, -7.4338, -6.9816,  ..., -8.9834, -8.5216, -9.2509]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([399], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7307, -5.1221, -7.6285,  ..., -8.7265, -8.4450, -8.9846]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0003,  -0.5558,  -7.5229,  ...,  -9.9838,  -9.6321, -10.2301]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.4090, -12.2966,  -1.9550,  ..., -11.9987, -12.1940, -11.7464]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.0402, -12.0657,  -7.3500,  ..., -12.0024, -11.2818, -11.7768]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7436, -7.3391, -7.0411,  ..., -8.7721, -8.3947, -9.1175]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6933, -5.2819, -7.1794,  ..., -8.8464, -8.5695, -9.1669]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([510], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.0373,  -0.5894,  -7.3810,  ..., -10.0109,  -9.8327, -10.2844]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLLLoss()\n",
      "tensor([[-12.0023, -12.0568,  -1.9492,  ..., -11.6116, -11.8124, -11.3662]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([221], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.6080, -11.6701,  -7.1276,  ..., -11.6572, -10.9076, -11.4162]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8691, -7.3640, -7.5365,  ..., -8.9230, -8.5683, -9.2759]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([310], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.1568, -5.7758, -8.1948,  ..., -9.3504, -8.9958, -9.6417]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.5029,  -1.1695,  -8.2876,  ..., -10.5774, -10.1947, -10.7890]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.1973, -12.0744,  -2.0364,  ..., -11.7968, -12.0754, -11.5419]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.8448, -11.6984,  -7.2101,  ..., -11.8026, -11.1726, -11.6100]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([16], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8379, -7.0192, -7.1983,  ..., -8.8285, -8.5370, -9.2254]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([186], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.8476, -5.2793, -7.7813,  ..., -8.9170, -8.6815, -9.2867]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([187], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-10.3701,  -0.6161,  -8.2326,  ..., -10.3220, -10.0719, -10.6476]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([238], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.7772, -12.8699,  -0.4318,  ..., -12.4137, -12.7183, -12.1112]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.0051, -12.7730,  -6.4165,  ..., -11.9727, -11.4070, -11.9106]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([3], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7159, -8.0270, -6.6455,  ..., -8.8427, -8.6990, -9.1997]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([147], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.5875, -5.7943, -7.2035,  ..., -8.7835, -8.5769, -9.1177]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([1723], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.8604,  -0.7359,  -7.1988,  ...,  -9.8591,  -9.6619, -10.1765]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([279], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.9480, -13.0615,  -0.2866,  ..., -12.5684, -12.7965, -12.2560]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([129], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.2249, -12.9947,  -6.3584,  ..., -12.1848, -11.5849, -12.0978]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([78], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.9211, -8.1606, -6.7785,  ..., -9.0026, -8.8672, -9.3514]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([303], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.6130, -6.1185, -7.1724,  ..., -8.7546, -8.5988, -9.1214]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([329], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[ -9.7414,  -0.9065,  -7.0456,  ...,  -9.6768,  -9.4538, -10.0245]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([4], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-12.2952, -12.5962,  -1.2387,  ..., -11.9107, -12.1895, -11.5773]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([77], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-11.7813, -12.8977,  -6.9075,  ..., -11.7116, -11.1589, -11.6469]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([124], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.7343, -8.9423, -6.8421,  ..., -8.7780, -8.6788, -9.1881]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([367], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3249, -7.0638, -7.2094,  ..., -8.4282, -8.3577, -8.8487]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([606], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-8.3707, -5.6628, -7.5568,  ..., -8.4570, -8.3578, -8.8689]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([820], device='cuda:0')\n",
      "NLLLoss()\n",
      "tensor([[-9.3811, -0.8600, -7.1447,  ..., -9.2725, -9.1495, -9.6672]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>) tensor([2579], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7ea4b06f8a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-76e06a240aeb>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 19\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-aa4e39318476>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/long36v/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/long36v/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c est vous la plus vieille .\n",
      "= you re the oldest .\n",
      "< you re the oldest . <EOS>\n",
      "\n",
      "> tu es un puritain .\n",
      "= you re a prude .\n",
      "< you re a prude . <EOS>\n",
      "\n",
      "> il est indigne .\n",
      "= he s outraged .\n",
      "< he s outraged . <EOS>\n",
      "\n",
      "> il est juste derriere toi .\n",
      "= he s right behind you .\n",
      "< he s right behind you . <EOS>\n",
      "\n",
      "> je suis ravi de te voir .\n",
      "= i m pleased to see you .\n",
      "< i m pleased to see you . <EOS>\n",
      "\n",
      "> nous n y sommes pas habitues .\n",
      "= we re not used to it .\n",
      "< we re not upset with this . <EOS>\n",
      "\n",
      "> elles ne sont pas seules .\n",
      "= they re not alone .\n",
      "< they aren t here . <EOS>\n",
      "\n",
      "> vous etes incroyable .\n",
      "= you re incredible .\n",
      "< you re incredible . <EOS>\n",
      "\n",
      "> il n est jamais paresseux .\n",
      "= he is never lazy .\n",
      "< he is never lazy . <EOS>\n",
      "\n",
      "> je ne gobe pas votre histoire .\n",
      "= i m not buying your story .\n",
      "< i m not your story . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention 시각화\n",
    "---------------------\n",
    "\n",
    "Attention 메커니즘의 유용한 속성은 하나는 해석 가능성이 높은 출력입니다.\n",
    "입력 시퀀스의 특정 인코더 출력에 가중치를 부여하는 데 사용되므로\n",
    "각 시간 단계에서 네트워크가 가장 집중되는 위치를 파악할 수 있습니다.\n",
    "\n",
    "Attention 출력을 행렬로 표시하기 위해 ``plt.matshow(attentions)`` 를\n",
    "간단하게 실행할 수 있습니다. 열은 입력 단계와 행이 출력 단계입니다:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa00fd92d68>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "더 나은 보기를 위해 축과 라벨을 더하는 추가 작업을 수행합니다:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = elle a cinq ans de moins que moi .\n",
      "output = she is five years younger than i am . <EOS>\n",
      "input = elle est trop petit .\n",
      "output = she s too short . <EOS>\n",
      "input = je ne crains pas de mourir .\n",
      "output = i m not afraid to die . <EOS>\n",
      "input = c est un jeune directeur plein de talent .\n",
      "output = he s a talented great player . <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/long8v/anaconda3/envs/long36v/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/long8v/anaconda3/envs/long36v/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/long8v/anaconda3/envs/long36v/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # colorbar로 그림 설정\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # 축 설정\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # 매 틱마다 라벨 보여주기\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연습\n",
    "=========\n",
    "\n",
    "-  다른 데이터 셋을 시도해 보십시오\n",
    "\n",
    "   -  다른 언어쌍\n",
    "   -  사람 → 기계 (e.g. IOT 명령어)\n",
    "   -  채팅 → 응답\n",
    "   -  질문 → 답변\n",
    "\n",
    "-  word2vec 또는 GloVe 같은 미리 학습된 word embedding 으로\n",
    "   embedding 을 교체하십시오\n",
    "\n",
    "-  더 많은 레이어, 은닉 유닛, 더 많은 문장을 사용하십시오.\n",
    "   학습 시간과 결과를 비교해 보십시오\n",
    "-  만약 같은 구문 두개의 쌍으로 된 번역 파일을 이용한다면,\n",
    "   (``I am test \\t I am test``), 이것을 오토인코더로\n",
    "   사용할 수 있습니다.\n",
    "   이것을 시도해 보십시오:\n",
    "\n",
    "   -  오토인코더 학습\n",
    "   -  인코더 네트워크 저장하기\n",
    "   -  그 상태에서 번역을 위한 새로운 디코더 학습\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
