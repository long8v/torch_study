{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "long36v",
   "display_name": "long36v",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Korpora import Korpora\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from txt_cleaner.clean.master import MasterCleaner\n",
    "from txt_cleaner.utils import *"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.train.zip\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.train\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.test.zip\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.test\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.dev.zip\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.dev\n"
     ]
    }
   ],
   "source": [
    "Korpora.fetch('namuwikitext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : Hyunjoong Kim lovit@github\n",
      "    Repository : https://github.com/lovit/namuwikitext\n",
      "    References :\n",
      "\n",
      "    나무위키의 덤프 데이터를 바탕을 제작한 wikitext 형식의 텍스트 파일입니다.\n",
      "    학습 및 평가를 위하여 위키페이지 별로 train (99%), dev (0.5%), test (0.5%) 로 나뉘어져있습니다.\n",
      "\n",
      "\n",
      "    # License\n",
      "    CC BY-NC-SA 2.0 KR which Namuwiki dump dataset is licensed\n",
      "\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.train.zip\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.train\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.test.zip\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.test\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.dev.zip\n",
      "[Korpora] Corpus `namuwikitext` is already installed at /home/hscho/Korpora/namuwikitext/namuwikitext_20200302.dev\n"
     ]
    }
   ],
   "source": [
    "corpus = Korpora.load('namuwikitext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mecab\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = mecab.MeCab()\n",
    "\n",
    "def tokenize_pos(inp):\n",
    "    if type(inp) == str:\n",
    "        return pos.morphs(inp)\n",
    "    if type(inp) == list:\n",
    "        return [tokenize_pos(i) for i in inp]\n",
    "# pos.morphs(['안녕하세요'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['안녕', '하', '세요'], [['안녕', '하', '세요'], ['안녕', '?']])"
      ]
     },
     "metadata": {},
     "execution_count": 299
    }
   ],
   "source": [
    "tokenize_pos('안녕하세요'), tokenize_pos(['안녕하세요', '안녕?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "size 1 dictionary is read from ../txt_cleaner/cleaner_config.json\n"
     ]
    }
   ],
   "source": [
    "config = json_reader('../txt_cleaner/cleaner_config.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'minimum_space_count': 5}"
      ]
     },
     "metadata": {},
     "execution_count": 301
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "execution_count": 302
    }
   ],
   "source": [
    "cleaner = MasterCleaner(config)\n",
    "cleaner.cleaning('안녕하세요? 반갑습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['안녕', '하', '세요'], ['안녕']]"
      ]
     },
     "metadata": {},
     "execution_count": 303
    }
   ],
   "source": [
    "tokenize_pos(['안녕하세요', '안녕'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/hscho/anaconda3/envs/long36v/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "ko_field = Field(tokenize = lambda e: tokenize_pos(e),\n",
    "                init_token = '<sos>',\n",
    "                eos_token = '<eos>',\n",
    "                batch_first = True)\n",
    "ko_field = Field(tokenize = lambda e: e.split(),\n",
    "                init_token = '<sos>',\n",
    "                eos_token = '<eos>',\n",
    "                batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['안녕', '하', '세요']"
      ]
     },
     "metadata": {},
     "execution_count": 328
    }
   ],
   "source": [
    "pos.morphs('안녕하세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = corpus.train.texts\n",
    "ko_field.build_vocab([_ for _ in train if _])\n",
    "# ko_field.build_vocab('안녕하세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['羽衣', '小', '町', '《', '아이돌', '마스터', '신데렐라', '걸즈', '》', '에']"
      ]
     },
     "metadata": {},
     "execution_count": 330
    }
   ],
   "source": [
    "tokenize_pos(list(train)[3])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['안녕하세요', '안녕 반갑습니다']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[   2,  117, 1079,   13,  142,  175,    3,    1,    1,    1],\n",
       "        [   2,  117, 1079,    4,  149,  647,  274,   77,    7,    3]])"
      ]
     },
     "metadata": {},
     "execution_count": 334
    }
   ],
   "source": [
    "preprocess = ko_field.preprocess(['안녕하세요', '안녕 반갑습니다'])\n",
    "print(preprocess)\n",
    "process = ko_field.process(preprocess)\n",
    "process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}